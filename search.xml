<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[蓄水池抽样]]></title>
    <url>%2F2018%2F05%2F21%2F%E8%93%84%E6%B0%B4%E6%B1%A0%E6%8A%BD%E6%A0%B7%2F</url>
    <content type="text"><![CDATA[蓄水池抽样问题是从动态变化的N个元素中随机抽选出M个元素(N&gt;=M) 算法描述如下： 123456Init : a reservoir with the size： k for i= k+1 to N M=random(1, i); if( M &lt; k) SWAP the Mth value and ith value end for 由于N的个数是不确定的，这就意味着不论N的个数是多少，里面元素都要被等概率抽取,例如，先从10个元素中抽取2个出来，现在又往里面添加了10个元素，变成了从20个元素中抽取两个出来，如何保证这次变化后每个元素被抽取的概率还是一样的呢？ 问题，证明对于任意样本号n,n&gt;=k,每个样本作为取出样本的概率相等，即k/n 证明： 当n=k时，由我们把前k个数放入蓄水池可知，每个样本的取出概率均相等，即k/k=1。 设当前样本号为n，其每个取出样本概率均相等，即为k/n，我们要证明的是这种情况对于n+1也成立。 由于我们以k/(n+1)决定是否把n+1放入蓄水池，那么对于n+1其出现在蓄水池中的概率就是k/(n+1)，对于前n个元素中的任意元素m(k+1&lt;=m&lt;=n)，其出现在蓄水池中的概率为 m出现在蓄水池中的概率 [(m+1被选中的概率m没被m+1替换的概率 + m+1没被选中的概率)(m+2被选中的概率m没被m+2替换的概率 + m+2没被选中的概率)…(n+1被选中的概率*m没被n+1替换的概率 + n+1没被选中的概率)] 可见，对于n+1每个样本取出概率也相等，即为k/(n+1)。证毕。 面试题： 给你一个长度为N的链表。N很大，但你不知道N有多大。你的任务是从这N个元素中随机取出k个元素。你只能遍历这个链表一次。你的算法必须保证取出的元素恰好有k个，且它们是完全随机的（出现概率均等）。 此问题有个限制点： 1.元素个数不可知 2.只能遍历一边 解题思路如下： 1.遍历链表到第k个元素，构造一个数组A[K]存储这k个元素 2.从k+1开始遍历，与前面算法一样 12345for i= k+1 to N M=random(1, i); if( M &lt; k) SWAP the Mth value and ith value in array Aend for 3.最后得到的数组A[k]就是想要的。 在网上流传的这个算法有问题，wiki 上面的描述如下： 12345678910111213array R[k]; // resultinteger i, j;// fill the reservoir arrayfor each i in 1 to k do R[i] := S[i]done;// replace elements with gradually decreasing probabilityfor each i in k+1 to length(S) do j := random(1, i); // important: inclusive range if j &lt;= k then R[j] := S[i] fidone （ps:注意第10行的 j &lt;= k）]]></content>
  </entry>
  <entry>
    <title><![CDATA[Guava Cache内存缓存使用实践-定时异步刷新及简单抽象封装]]></title>
    <url>%2F2018%2F05%2F21%2FGuava-Cache%E5%86%85%E5%AD%98%E7%BC%93%E5%AD%98%E4%BD%BF%E7%94%A8%E5%AE%9E%E8%B7%B5-%E5%AE%9A%E6%97%B6%E5%BC%82%E6%AD%A5%E5%88%B7%E6%96%B0%E5%8F%8A%E7%AE%80%E5%8D%95%E6%8A%BD%E8%B1%A1%E5%B0%81%E8%A3%85%2F</url>
    <content type="text"><![CDATA[Guava Cache内存缓存使用实践-定时异步刷新及简单抽象封装2017年07月17日 16:53:05 阅读数：10099 缓存在应用中是必不可少的，经常用的如redis、memcache以及内存缓存等。Guava是Google出的一个工具包，它里面的cache即是对本地内存缓存的一种实现，支持多种缓存过期策略。Guava cache的缓存加载方式有两种： CacheLoader Callable callback 具体两种方式的介绍看官方文档：http://ifeve.com/google-guava-cachesexplained/ 接下来看看常见的一些使用方法。后面的示例实践都是以CacheLoader方式加载缓存值。 1.简单使用：定时过期1234567891011121314LoadingCache&lt;String, Object&gt; caches = CacheBuilder.newBuilder() .maximumSize(100) .expireAfterWrite(10, TimeUnit.MINUTES) .build(new CacheLoader&lt;String, Object&gt;() &#123; @Override public Object load(String key) throws Exception &#123; return generateValueByKey(key); &#125; &#125;);try &#123; System.out.println(caches.get(&quot;key-zorro&quot;));&#125; catch (ExecutionException e) &#123; e.printStackTrace();&#125;1234567891011121314 如代码所示新建了名为caches的一个缓存对象，maximumSize定义了缓存的容量大小，当缓存数量即将到达容量上线时，则会进行缓存回收，回收最近没有使用或总体上很少使用的缓存项。需要注意的是在接近这个容量上限时就会发生，所以在定义这个值的时候需要视情况适量地增大一点。另外通过expireAfterWrite这个方法定义了缓存的过期时间，写入十分钟之后过期。在build方法里，传入了一个CacheLoader对象，重写了其中的load方法。当获取的缓存值不存在或已过期时，则会调用此load方法，进行缓存值的计算。这就是最简单也是我们平常最常用的一种使用方法。定义了缓存大小、过期时间及缓存值生成方法。 如果用其他的缓存方式，如redis，我们知道上面这种“如果有缓存则返回；否则运算、缓存、然后返回”的缓存模式是有很大弊端的。当高并发条件下同时进行get操作，而此时缓存值已过期时，会导致大量线程都调用生成缓存值的方法，比如从数据库读取。这时候就容易造成数据库雪崩。这也就是我们常说的“缓存穿透”。而Guava cache则对此种情况有一定控制。当大量线程用相同的key获取缓存值时，只会有一个线程进入load方法，而其他线程则等待，直到缓存值被生成。这样也就避免了缓存穿透的危险。 2.进阶使用：定时刷新如上的使用方法，虽然不会有缓存穿透的情况，但是每当某个缓存值过期时，老是会导致大量的请求线程被阻塞。而Guava则提供了另一种缓存策略，缓存值定时刷新：更新线程调用load方法更新该缓存，其他请求线程返回该缓存的旧值。这样对于某个key的缓存来说，只会有一个线程被阻塞，用来生成缓存值，而其他的线程都返回旧的缓存值，不会被阻塞。这里就需要用到Guava cache的refreshAfterWrite方法。如下所示： 1234567891011121314LoadingCache&lt;String, Object&gt; caches = CacheBuilder.newBuilder() .maximumSize(100) .refreshAfterWrite(10, TimeUnit.MINUTES) .build(new CacheLoader&lt;String, Object&gt;() &#123; @Override public Object load(String key) throws Exception &#123; return generateValueByKey(key); &#125; &#125;);try &#123; System.out.println(caches.get(&quot;key-zorro&quot;));&#125; catch (ExecutionException e) &#123; e.printStackTrace();&#125;1234567891011121314 如代码所示，每隔十分钟缓存值则会被刷新。 此外需要注意一个点，这里的定时并不是真正意义上的定时。Guava cache的刷新需要依靠用户请求线程，让该线程去进行load方法的调用，所以如果一直没有用户尝试获取该缓存值，则该缓存也并不会刷新。 3.进阶使用：异步刷新如2中的使用方法，解决了同一个key的缓存过期时会让多个线程阻塞的问题，只会让用来执行刷新缓存操作的一个用户线程会被阻塞。由此可以想到另一个问题，当缓存的key很多时，高并发条件下大量线程同时获取不同key对应的缓存，此时依然会造成大量线程阻塞，并且给数据库带来很大压力。这个问题的解决办法就是将刷新缓存值的任务交给后台线程，所有的用户请求线程均返回旧的缓存值，这样就不会有用户线程被阻塞了。详细做法如下： 12345678910111213141516171819202122232425262728ListeningExecutorService backgroundRefreshPools = MoreExecutors.listeningDecorator(Executors.newFixedThreadPool(20)); LoadingCache&lt;String, Object&gt; caches = CacheBuilder.newBuilder() .maximumSize(100) .refreshAfterWrite(10, TimeUnit.MINUTES) .build(new CacheLoader&lt;String, Object&gt;() &#123; @Override public Object load(String key) throws Exception &#123; return generateValueByKey(key); &#125; @Override public ListenableFuture&lt;Object&gt; reload(String key, Object oldValue) throws Exception &#123; return backgroundRefreshPools.submit(new Callable&lt;Object&gt;() &#123; @Override public Object call() throws Exception &#123; return generateValueByKey(key); &#125; &#125;); &#125; &#125;);try &#123; System.out.println(caches.get(&quot;key-zorro&quot;));&#125; catch (ExecutionException e) &#123; e.printStackTrace();&#125;12345678910111213141516171819202122232425262728 在上面的代码中，我们新建了一个线程池，用来执行缓存刷新任务。并且重写了CacheLoader的reload方法，在该方法中建立缓存刷新的任务并提交到线程池。注意此时缓存的刷新依然需要靠用户线程来驱动，只不过和2不同之处在于该用户线程触发刷新操作之后，会立马返回旧的缓存值。 TIPS 可以看到防缓存穿透和防用户线程阻塞都是依靠返回旧值来完成的。所以如果没有旧值，同样会全部阻塞，因此应视情况尽量在系统启动时将缓存内容加载到内存中。 在刷新缓存时，如果generateValueByKey方法出现异常或者返回了null，此时旧值不会更新。 题外话：在使用内存缓存时，切记拿到缓存值之后不要在业务代码中对缓存直接做修改，因为此时拿到的对象引用是指向缓存真正的内容的。如果需要直接在该对象上进行修改，则在获取到缓存值后拷贝一份副本，然后传递该副本，进行修改操作。（我曾经就犯过这个低级错误 - -！） 4.简单抽象封装如下为基于Guava cache抽象出来的一个缓存工具类。（抽象得不好，勉强能用 - -！）。有改进意见麻烦多多指教。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109/** * @description: 利用guava实现的内存缓存。缓存加载之后永不过期，后台线程定时刷新缓存值。刷新失败时将继续返回旧缓存。 * 需要在子类中初始化refreshDuration、refreshTimeunitType、cacheMaximumSize三个参数 * 后台刷新线程池为该系统中所有子类共享，大小为20. * @author: luozhuo * @date: 2017年6月21日 上午10:03:45 * @version: V1.0.0 * @param &lt;K&gt; * @param &lt;V&gt; */public abstract class ZorroGuavaCache &lt;K, V&gt; &#123; /** * 缓存自动刷新周期 */ protected int refreshDuration; /** * 缓存刷新周期时间格式 */ protected TimeUnit refreshTimeunitType; /** * 缓存最大容量 */ protected int cacheMaximumSize; private LoadingCache&lt;K, V&gt; cache; private ListeningExecutorService backgroundRefreshPools = MoreExecutors.listeningDecorator(Executors.newFixedThreadPool(20)); /** * @description: 初始化所有protected字段： * refreshDuration、refreshTimeunitType、cacheMaximumSize * @author: luozhuo * @date: 2017年6月13日 下午2:49:19 */ protected abstract void initCacheFields(); /** * @description: 定义缓存值的计算方法 * @description: 新值计算失败时抛出异常，get操作时将继续返回旧的缓存 * @param key * @return * @author: luozhuo * @throws Exception * @date: 2017年6月14日 下午7:11:10 */ protected abstract V getValueWhenExpire(K key) throws Exception; /** * @description: 提供给外部使用的获取缓存方法，由实现类进行异常处理 * @param key * @return * @author: luozhuo * @date: 2017年6月15日 下午12:00:57 */ public abstract V getValue(K key); /** * @description: 获取cache实例 * @return * @author: luozhuo * @date: 2017年6月13日 下午2:50:11 */ private LoadingCache&lt;K, V&gt; getCache() &#123; if(cache == null)&#123; synchronized (this) &#123; if(cache == null)&#123; initCacheFields(); cache = CacheBuilder.newBuilder() .maximumSize(cacheMaximumSize) .refreshAfterWrite(refreshDuration, refreshTimeunitType) .build(new CacheLoader&lt;K, V&gt;() &#123; @Override public V load(K key) throws Exception &#123; return getValueWhenExpire(key); &#125; @Override public ListenableFuture&lt;V&gt; reload(final K key, V oldValue) throws Exception &#123; return backgroundRefreshPools.submit(new Callable&lt;V&gt;() &#123; public V call() throws Exception &#123; return getValueWhenExpire(key); &#125; &#125;); &#125; &#125;); &#125; &#125; &#125; return cache; &#125; /** * @description: 从cache中拿出数据的操作 * @param key * @return * @throws ExecutionException * @author: luozhuo * @date: 2017年6月13日 下午5:07:11 */ protected V fetchDataFromCache(K key) throws ExecutionException &#123; return getCache().get(key); &#125;&#125; 转载于 https://blog.csdn.net/u012859681/article/details/75220605]]></content>
  </entry>
  <entry>
    <title><![CDATA[Class对象的获取]]></title>
    <url>%2F2018%2F05%2F04%2FClass%E5%AF%B9%E8%B1%A1%E7%9A%84%E8%8E%B7%E5%8F%96%2F</url>
    <content type="text"><![CDATA[所有的引用数据类型（类-类型）的类名、基本数据类型都可以通过.class方式获取其 Class对象（对于基本数据类型的封装类还可以通过.TYPE 的方式获取其 Class 对象，但要注意。TYPE 实际上获取的封装类对应的基本类型的 Class 对象的引用，那么你可以判断出int.class==Integer.TYPE 返回 true，int.class==Integer.class 返回 false！），通过这种方式不会初始化静态域，使用.class、.TYPE 的方式获取 Class对象叫做类的字面常量； Class 的 forName(String name)传入一个类的完整类路径也可以获得 Class 对象，但由于使用的是字符串，必须强制转换才可以获取泛型的Class的 Class对象，并且你必须获取这个方法可能抛出的ClassNotFoundException异常。这种方法可以初始化静态域。 还可通过类的对象实例下的getClass()方法来获取Class对象，即 实例名.getClass()]]></content>
  </entry>
  <entry>
    <title><![CDATA[Java里面CompletableFuture详解]]></title>
    <url>%2F2018%2F04%2F28%2FJava%E9%87%8C%E9%9D%A2CompletableFuture%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[Future是Java 5添加的类，用来描述一个异步计算的结果。你可以使用isDone方法检查计算是否完成，或者使用get阻塞住调用线程，直到计算完成返回结果，你也可以使用cancel方法停止任务的执行。 1234567891011121314public class BasicFuture &#123; public static void main(String[] args) throws ExecutionException, InterruptedException &#123; ExecutorService es = Executors.newFixedThreadPool(10); Future&lt;Integer&gt; f = es.submit(() -&gt;&#123; // 长时间的异步计算 // …… // 然后返回结果 return 100; &#125;);// while(!f.isDone())// ; f.get(); &#125;&#125; 虽然Future以及相关使用方法提供了异步执行任务的能力，但是对于结果的获取却是很不方便，只能通过阻塞或者轮询的方式得到任务的结果。阻塞的方式显然和我们的异步编程的初衷相违背，轮询的方式又会耗费无谓的CPU资源，而且也不能及时地得到计算结果，为什么不能用观察者设计模式当计算结果完成及时通知监听者呢？ 很多语言，比如Node.js，采用回调的方式实现异步编程。Java的一些框架，比如Netty，自己扩展了Java的 Future接口，提供了addListener等多个扩展方法： 1234567891011121314ChannelFuture future = bootstrap.connect(new InetSocketAddress(host, port)); future.addListener(new ChannelFutureListener() &#123; @Override public void operationComplete(ChannelFuture future) throws Exception &#123; if (future.isSuccess()) &#123; // SUCCESS &#125; else &#123; // FAILURE &#125; &#125; &#125;); Google guava也提供了通用的扩展Future:ListenableFuture、SettableFuture 以及辅助类Futures等,方便异步编程。 1234567891011final String name = ...;inFlight.add(name);ListenableFuture&lt;Result&gt; future = service.query(name);future.addListener(new Runnable() &#123; public void run() &#123; processedCount.incrementAndGet(); inFlight.remove(name); lastProcessed.set(name); logger.info(&quot;Done with &#123;0&#125;&quot;, name); &#125;&#125;, executor); Scala也提供了简单易用且功能强大的Future/Promise异步编程模式。 作为正统的Java类库，是不是应该做点什么，加强一下自身库的功能呢？ 在Java 8中, 新增加了一个包含50个方法左右的类: CompletableFuture，提供了非常强大的Future的扩展功能，可以帮助我们简化异步编程的复杂性，提供了函数式编程的能力，可以通过回调的方式处理计算结果，并且提供了转换和组合CompletableFuture的方法。 下面我们就看一看它的功能吧。 主动完成计算CompletableFuture类实现了CompletionStage和Future接口，所以你还是可以像以前一样通过阻塞或者轮询的方式获得结果，尽管这种方式不推荐使用。 1234public T get()public T get(long timeout, TimeUnit unit)public T getNow(T valueIfAbsent)public T join() getNow有点特殊，如果结果已经计算完则返回结果或者抛出异常，否则返回给定的valueIfAbsent值。join返回计算的结果或者抛出一个unchecked异常(CompletionException)，它和get对抛出的异常的处理有些细微的区别，你可以运行下面的代码进行比较： 123456CompletableFuture&lt;Integer&gt; future = CompletableFuture.supplyAsync(() -&gt; &#123; int i = 1/0; return 100;&#125;);//future.join();future.get(); 尽管Future可以代表在另外的线程中执行的一段异步代码，但是你还是可以在本身线程中执行： 12345public static CompletableFuture&lt;Integer&gt; compute() &#123; final CompletableFuture&lt;Integer&gt; future = new CompletableFuture&lt;&gt;(); return future;&#125; 上面的代码中future没有关联任何的Callback、线程池、异步任务等，如果客户端调用future.get就会一致傻等下去。你可以通过下面的代码完成一个计算，触发客户端的等待： 1f.complete(100); 当然你也可以抛出一个异常，而不是一个成功的计算结果： 1f.completeExceptionally(new Exception()); 完整的代码如下： 1234567891011121314151617181920212223242526272829303132public class BasicMain &#123; public static CompletableFuture&lt;Integer&gt; compute() &#123; final CompletableFuture&lt;Integer&gt; future = new CompletableFuture&lt;&gt;(); return future; &#125; public static void main(String[] args) throws Exception &#123; final CompletableFuture&lt;Integer&gt; f = compute(); class Client extends Thread &#123; CompletableFuture&lt;Integer&gt; f; Client(String threadName, CompletableFuture&lt;Integer&gt; f) &#123; super(threadName); this.f = f; &#125; @Override public void run() &#123; try &#123; System.out.println(this.getName() + &quot;: &quot; + f.get()); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (ExecutionException e) &#123; e.printStackTrace(); &#125; &#125; &#125; new Client(&quot;Client1&quot;, f).start(); new Client(&quot;Client2&quot;, f).start(); System.out.println(&quot;waiting&quot;); f.complete(100); //f.completeExceptionally(new Exception()); System.in.read(); &#125;&#125; 可以看到我们并没有把f.complete(100);放在另外的线程中去执行，但是在大部分情况下我们可能会用一个线程池去执行这些异步任务。CompletableFuture.complete()、CompletableFuture.completeExceptionally只能被调用一次。但是我们有两个后门方法可以重设这个值:obtrudeValue、obtrudeException，但是使用的时候要小心，因为complete已经触发了客户端，有可能导致客户端会得到不期望的结果。 创建CompletableFuture对象。CompletableFuture.completedFuture是一个静态辅助方法，用来返回一个已经计算好的CompletableFuture。 1public static &lt;U&gt; CompletableFuture&lt;U&gt; completedFuture(U value) 而以下四个静态方法用来为一段异步执行的代码创建CompletableFuture对象： 1234public static CompletableFuture&lt;Void&gt; runAsync(Runnable runnable)public static CompletableFuture&lt;Void&gt; runAsync(Runnable runnable, Executor executor)public static &lt;U&gt; CompletableFuture&lt;U&gt; supplyAsync(Supplier&lt;U&gt; supplier)public static &lt;U&gt; CompletableFuture&lt;U&gt; supplyAsync(Supplier&lt;U&gt; supplier, Executor executor) 以Async结尾并且没有指定Executor的方法会使用ForkJoinPool.commonPool()作为它的线程池执行异步代码。 runAsync方法也好理解，它以Runnable函数式接口类型为参数，所以CompletableFuture的计算结果为空。supplyAsync方法以Supplier&lt;U&gt;函数式接口类型为参数,CompletableFuture的计算结果类型为U。 因为方法的参数类型都是函数式接口，所以可以使用lambda表达式实现异步任务，比如： 1234CompletableFuture&lt;String&gt; future = CompletableFuture.supplyAsync(() -&gt; &#123; //长时间的计算任务 return &quot;·00&quot;;&#125;); 计算结果完成时的处理当CompletableFuture的计算结果完成，或者抛出异常的时候，我们可以执行特定的Action。主要是下面的方法： 1234public CompletableFuture&lt;T&gt; whenComplete(BiConsumer&lt;? super T,? super Throwable&gt; action)public CompletableFuture&lt;T&gt; whenCompleteAsync(BiConsumer&lt;? super T,? super Throwable&gt; action)public CompletableFuture&lt;T&gt; whenCompleteAsync(BiConsumer&lt;? super T,? super Throwable&gt; action, Executor executor)public CompletableFuture&lt;T&gt; exceptionally(Function&lt;Throwable,? extends T&gt; fn) 可以看到Action的类型是BiConsumer&lt;? super T,? super Throwable&gt;，它可以处理正常的计算结果，或者异常情况。方法不以Async结尾，意味着Action使用相同的线程执行，而Async可能会使用其它的线程去执行(如果使用相同的线程池，也可能会被同一个线程选中执行)。 注意这几个方法都会返回CompletableFuture，当Action执行完毕后它的结果返回原始的CompletableFuture的计算结果或者返回异常。 1234567891011121314151617181920212223public class Main &#123; private static Random rand = new Random(); private static long t = System.currentTimeMillis(); static int getMoreData() &#123; System.out.println(&quot;begin to start compute&quot;); try &#123; Thread.sleep(10000); &#125; catch (InterruptedException e) &#123; throw new RuntimeException(e); &#125; System.out.println(&quot;end to start compute. passed &quot; + (System.currentTimeMillis() - t)/1000 + &quot; seconds&quot;); return rand.nextInt(1000); &#125; public static void main(String[] args) throws Exception &#123; CompletableFuture&lt;Integer&gt; future = CompletableFuture.supplyAsync(Main::getMoreData); Future&lt;Integer&gt; f = future.whenComplete((v, e) -&gt; &#123; System.out.println(v); System.out.println(e); &#125;); System.out.println(f.get()); System.in.read(); &#125;&#125; exceptionally方法返回一个新的CompletableFuture，当原始的CompletableFuture抛出异常的时候，就会触发这个CompletableFuture的计算，调用function计算值，否则如果原始的CompletableFuture正常计算完后，这个新的CompletableFuture也计算完成，它的值和原始的CompletableFuture的计算的值相同。也就是这个exceptionally方法用来处理异常的情况。 下面一组方法虽然也返回CompletableFuture对象，但是对象的值和原来的CompletableFuture计算的值不同。当原先的CompletableFuture的值计算完成或者抛出异常的时候，会触发这个CompletableFuture对象的计算，结果由BiFunction参数计算而得。因此这组方法兼有whenComplete和转换的两个功能。 123public &lt;U&gt; CompletableFuture&lt;U&gt; handle(BiFunction&lt;? super T,Throwable,? extends U&gt; fn)public &lt;U&gt; CompletableFuture&lt;U&gt; handleAsync(BiFunction&lt;? super T,Throwable,? extends U&gt; fn)public &lt;U&gt; CompletableFuture&lt;U&gt; handleAsync(BiFunction&lt;? super T,Throwable,? extends U&gt; fn, Executor executor) 同样，不以Async结尾的方法由原来的线程计算，以Async结尾的方法由默认的线程池ForkJoinPool.commonPool()或者指定的线程池executor运行。 转换CompletableFuture可以作为monad(单子)和functor。由于回调风格的实现，我们不必因为等待一个计算完成而阻塞着调用线程，而是告诉CompletableFuture当计算完成的时候请执行某个function。而且我们还可以将这些操作串联起来，或者将CompletableFuture组合起来。 123public &lt;U&gt; CompletableFuture&lt;U&gt; thenApply(Function&lt;? super T,? extends U&gt; fn)public &lt;U&gt; CompletableFuture&lt;U&gt; thenApplyAsync(Function&lt;? super T,? extends U&gt; fn)public &lt;U&gt; CompletableFuture&lt;U&gt; thenApplyAsync(Function&lt;? super T,? extends U&gt; fn, Executor executor) 这一组函数的功能是当原来的CompletableFuture计算完后，将结果传递给函数fn，将fn的结果作为新的CompletableFuture计算结果。因此它的功能相当于将CompletableFuture&lt;T&gt;转换成CompletableFuture&lt;U&gt;。 这三个函数的区别和上面介绍的一样，不以Async结尾的方法由原来的线程计算，以Async结尾的方法由默认的线程池ForkJoinPool.commonPool()或者指定的线程池executor运行。Java的CompletableFuture类总是遵循这样的原则，下面就不一一赘述了。 使用例子如下： 12345CompletableFuture&lt;Integer&gt; future = CompletableFuture.supplyAsync(() -&gt; &#123; return 100;&#125;);CompletableFuture&lt;String&gt; f = future.thenApplyAsync(i -&gt; i * 10).thenApply(i -&gt; i.toString());System.out.println(f.get()); //&quot;1000&quot; 需要注意的是，这些转换并不是马上执行的，也不会阻塞，而是在前一个stage完成后继续执行。 它们与handle方法的区别在于handle方法会处理正常计算值和异常，因此它可以屏蔽异常，避免异常继续抛出。而thenApply方法只是用来处理正常值，因此一旦有异常就会抛出。 纯消费(执行Action)上面的方法是当计算完成的时候，会生成新的计算结果(thenApply, handle)，或者返回同样的计算结果whenComplete，CompletableFuture还提供了一种处理结果的方法，只对结果执行Action,而不返回新的计算值，因此计算值为Void: 123public CompletableFuture&lt;Void&gt; thenAccept(Consumer&lt;? super T&gt; action)public CompletableFuture&lt;Void&gt; thenAcceptAsync(Consumer&lt;? super T&gt; action)public CompletableFuture&lt;Void&gt; thenAcceptAsync(Consumer&lt;? super T&gt; action, Executor executor) 看它的参数类型也就明白了，它们是函数式接口Consumer，这个接口只有输入，没有返回值。 12345CompletableFuture&lt;Integer&gt; future = CompletableFuture.supplyAsync(() -&gt; &#123; return 100;&#125;);CompletableFuture&lt;Void&gt; f = future.thenAccept(System.out::println);System.out.println(f.get()); thenAcceptBoth以及相关方法提供了类似的功能，当两个CompletionStage都正常完成计算的时候，就会执行提供的action，它用来组合另外一个异步的结果。runAfterBoth是当两个CompletionStage都正常完成计算的时候,执行一个Runnable，这个Runnable并不使用计算的结果。 1234public &lt;U&gt; CompletableFuture&lt;Void&gt; thenAcceptBoth(CompletionStage&lt;? extends U&gt; other, BiConsumer&lt;? super T,? super U&gt; action)public &lt;U&gt; CompletableFuture&lt;Void&gt; thenAcceptBothAsync(CompletionStage&lt;? extends U&gt; other, BiConsumer&lt;? super T,? super U&gt; action)public &lt;U&gt; CompletableFuture&lt;Void&gt; thenAcceptBothAsync(CompletionStage&lt;? extends U&gt; other, BiConsumer&lt;? super T,? super U&gt; action, Executor executor)public CompletableFuture&lt;Void&gt; runAfterBoth(CompletionStage&lt;?&gt; other, Runnable action) 例子如下： 12345CompletableFuture&lt;Integer&gt; future = CompletableFuture.supplyAsync(() -&gt; &#123; return 100;&#125;);CompletableFuture&lt;Void&gt; f = future.thenAcceptBoth(CompletableFuture.completedFuture(10), (x, y) -&gt; System.out.println(x * y));System.out.println(f.get()); 更彻底地，下面一组方法当计算完成的时候会执行一个Runnable,与thenAccept不同，Runnable并不使用CompletableFuture计算的结果。 123public CompletableFuture&lt;Void&gt; thenRun(Runnable action)public CompletableFuture&lt;Void&gt; thenRunAsync(Runnable action)public CompletableFuture&lt;Void&gt; thenRunAsync(Runnable action, Executor executor) 因此先前的CompletableFuture计算的结果被忽略了,这个方法返回CompletableFuture&lt;Void&gt;类型的对象。 12345CompletableFuture&lt;Integer&gt; future = CompletableFuture.supplyAsync(() -&gt; &#123; return 100;&#125;);CompletableFuture&lt;Void&gt; f = future.thenRun(() -&gt; System.out.println(&quot;finished&quot;));System.out.println(f.get()); 因此，你可以根据方法的参数的类型来加速你的记忆。Runnable类型的参数会忽略计算的结果，Consumer是纯消费计算结果，BiConsumer会组合另外一个CompletionStage纯消费，Function会对计算结果做转换，BiFunction会组合另外一个CompletionStage的计算结果做转换。 组合123public &lt;U&gt; CompletableFuture&lt;U&gt; thenCompose(Function&lt;? super T,? extends CompletionStage&lt;U&gt;&gt; fn)public &lt;U&gt; CompletableFuture&lt;U&gt; thenComposeAsync(Function&lt;? super T,? extends CompletionStage&lt;U&gt;&gt; fn)public &lt;U&gt; CompletableFuture&lt;U&gt; thenComposeAsync(Function&lt;? super T,? extends CompletionStage&lt;U&gt;&gt; fn, Executor executor) 这一组方法接受一个Function作为参数，这个Function的输入是当前的CompletableFuture的计算值，返回结果将是一个新的CompletableFuture，这个新的CompletableFuture会组合原来的CompletableFuture和函数返回的CompletableFuture。因此它的功能类似: 1A +--&gt; B +---&gt; C 记住，thenCompose返回的对象并不一是函数fn返回的对象，如果原来的CompletableFuture还没有计算出来，它就会生成一个新的组合后的CompletableFuture。 例子： 123456789CompletableFuture&lt;Integer&gt; future = CompletableFuture.supplyAsync(() -&gt; &#123; return 100;&#125;);CompletableFuture&lt;String&gt; f = future.thenCompose( i -&gt; &#123; return CompletableFuture.supplyAsync(() -&gt; &#123; return (i * 10) + &quot;&quot;; &#125;);&#125;);System.out.println(f.get()); //1000 而下面的一组方法thenCombine用来复合另外一个CompletionStage的结果。它的功能类似： 12345A + | +------&gt; C +------^B + 两个CompletionStage是并行执行的，它们之间并没有先后依赖顺序， 1other 并不会等待先前的 1CompletableFuture 执行完毕后再执行。 123public &lt;U,V&gt; CompletableFuture&lt;V&gt; thenCombine(CompletionStage&lt;? extends U&gt; other, BiFunction&lt;? super T,? super U,? extends V&gt; fn)public &lt;U,V&gt; CompletableFuture&lt;V&gt; thenCombineAsync(CompletionStage&lt;? extends U&gt; other, BiFunction&lt;? super T,? super U,? extends V&gt; fn)public &lt;U,V&gt; CompletableFuture&lt;V&gt; thenCombineAsync(CompletionStage&lt;? extends U&gt; other, BiFunction&lt;? super T,? super U,? extends V&gt; fn, Executor executor) 其实从功能上来讲,它们的功能更类似thenAcceptBoth，只不过thenAcceptBoth是纯消费，它的函数参数没有返回值，而thenCombine的函数参数fn有返回值。 12345678CompletableFuture&lt;Integer&gt; future = CompletableFuture.supplyAsync(() -&gt; &#123; return 100;&#125;);CompletableFuture&lt;String&gt; future2 = CompletableFuture.supplyAsync(() -&gt; &#123; return &quot;abc&quot;;&#125;);CompletableFuture&lt;String&gt; f = future.thenCombine(future2, (x,y) -&gt; y + &quot;-&quot; + x);System.out.println(f.get()); //abc-100 EitherthenAcceptBoth和runAfterBoth是当两个CompletableFuture都计算完成，而我们下面要了解的方法是当任意一个CompletableFuture计算完成的时候就会执行。 1234567public CompletableFuture&lt;Void&gt; acceptEither(CompletionStage&lt;? extends T&gt; other, Consumer&lt;? super T&gt; action)public CompletableFuture&lt;Void&gt; acceptEitherAsync(CompletionStage&lt;? extends T&gt; other, Consumer&lt;? super T&gt; action)public CompletableFuture&lt;Void&gt; acceptEitherAsync(CompletionStage&lt;? extends T&gt; other, Consumer&lt;? super T&gt; action, Executor executor)public &lt;U&gt; CompletableFuture&lt;U&gt; applyToEither(CompletionStage&lt;? extends T&gt; other, Function&lt;? super T,U&gt; fn)public &lt;U&gt; CompletableFuture&lt;U&gt; applyToEitherAsync(CompletionStage&lt;? extends T&gt; other, Function&lt;? super T,U&gt; fn)public &lt;U&gt; CompletableFuture&lt;U&gt; applyToEitherAsync(CompletionStage&lt;? extends T&gt; other, Function&lt;? super T,U&gt; fn, Executor executor) acceptEither方法是当任意一个CompletionStage完成的时候，action这个消费者就会被执行。这个方法返回CompletableFuture&lt;Void&gt;applyToEither方法是当任意一个CompletionStage完成的时候，fn会被执行，它的返回值会当作新的CompletableFuture&lt;U&gt;的计算结果。 下面这个例子有时会输出100,有时候会输出200,哪个Future先完成就会根据它的结果计算。 123456789101112131415161718Random rand = new Random();CompletableFuture&lt;Integer&gt; future = CompletableFuture.supplyAsync(() -&gt; &#123; try &#123; Thread.sleep(10000 + rand.nextInt(1000)); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; return 100;&#125;);CompletableFuture&lt;Integer&gt; future2 = CompletableFuture.supplyAsync(() -&gt; &#123; try &#123; Thread.sleep(10000 + rand.nextInt(1000)); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; return 200;&#125;);CompletableFuture&lt;String&gt; f = future.applyToEither(future2,i -&gt; i.toString()); 辅助方法 allOf 和 anyOf前面我们已经介绍了几个静态方法：completedFuture、runAsync、supplyAsync,下面介绍的这两个方法用来组合多个CompletableFuture。 12public static CompletableFuture&lt;Void&gt; allOf(CompletableFuture&lt;?&gt;... cfs)public static CompletableFuture&lt;Object&gt; anyOf(CompletableFuture&lt;?&gt;... cfs) allOf方法是当所有的CompletableFuture都执行完后执行计算。anyOf方法是当任意一个CompletableFuture执行完后就会执行计算，计算的结果相同。 下面的代码运行结果有时是100,有时是”abc”。但是anyOf和applyToEither不同。anyOf接受任意多的CompletableFuture但是applyToEither只是判断两个CompletableFuture,anyOf返回值的计算结果是参数中其中一个CompletableFuture的计算结果，applyToEither返回值的计算结果却是要经过fn处理的。当然还有静态方法的区别，线程池的选择等。 1234567891011121314151617181920Random rand = new Random();CompletableFuture&lt;Integer&gt; future1 = CompletableFuture.supplyAsync(() -&gt; &#123; try &#123; Thread.sleep(10000 + rand.nextInt(1000)); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; return 100;&#125;);CompletableFuture&lt;String&gt; future2 = CompletableFuture.supplyAsync(() -&gt; &#123; try &#123; Thread.sleep(10000 + rand.nextInt(1000)); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; return &quot;abc&quot;;&#125;);//CompletableFuture&lt;Void&gt; f = CompletableFuture.allOf(future1,future2);CompletableFuture&lt;Object&gt; f = CompletableFuture.anyOf(future1,future2);System.out.println(f.get()); 我想通过上面的介绍，应该把CompletableFuture的方法和功能介绍完了(cancel、isCompletedExceptionally()、isDone()以及继承于Object的方法无需介绍了， toCompletableFuture()返回CompletableFuture本身)，希望你能全面了解CompletableFuture强大的功能，并将它应用到Java的异步编程中。如果你有使用它的开源项目，可以留言分享一下。 更进一步如果你用过Guava的Future类，你就会知道它的Futures辅助类提供了很多便利方法，用来处理多个Future，而不像Java的CompletableFuture，只提供了allOf、anyOf两个方法。 比如有这样一个需求，将多个CompletableFuture组合成一个CompletableFuture，这个组合后的CompletableFuture的计算结果是个List,它包含前面所有的CompletableFuture的计算结果，guava的Futures.allAsList可以实现这样的功能，但是对于java CompletableFuture，我们需要一些辅助方法： 12345678 public static &lt;T&gt; CompletableFuture&lt;List&lt;T&gt;&gt; sequence(List&lt;CompletableFuture&lt;T&gt;&gt; futures) &#123; CompletableFuture&lt;Void&gt; allDoneFuture = CompletableFuture.allOf(futures.toArray(new CompletableFuture[futures.size()])); return allDoneFuture.thenApply(v -&gt; futures.stream().map(CompletableFuture::join).collect(Collectors.&lt;T&gt;toList())); &#125;public static &lt;T&gt; CompletableFuture&lt;Stream&lt;T&gt;&gt; sequence(Stream&lt;CompletableFuture&lt;T&gt;&gt; futures) &#123; List&lt;CompletableFuture&lt;T&gt;&gt; futureList = futures.filter(f -&gt; f != null).collect(Collectors.toList()); return sequence(futureList); &#125; 或者Java Future转CompletableFuture: 123456789public static &lt;T&gt; CompletableFuture&lt;T&gt; toCompletable(Future&lt;T&gt; future, Executor executor) &#123; return CompletableFuture.supplyAsync(() -&gt; &#123; try &#123; return future.get(); &#125; catch (InterruptedException | ExecutionException e) &#123; throw new RuntimeException(e); &#125; &#125;, executor);&#125; github有多个项目可以实现Java CompletableFuture与其它Future (如Guava ListenableFuture)之间的转换，如spotify/futures-extra、future-converter、scala/scala-java8-compat 等。 参考文档 Java 8: Definitive guide to CompletableFuture https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/CompletableFuture.html https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/CompletionStage.html]]></content>
  </entry>
  <entry>
    <title><![CDATA[Java 8中,Function,Consumer,Predicate,Supplier举例]]></title>
    <url>%2F2018%2F04%2F28%2FJava-8%E4%B8%AD-Function-Consumer-Predicate-Supplier%E4%B8%BE%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[本文仅仅作为科普,大牛请无视. (本文的所有例子都是写在junit里的, 不过贴代码的时候我把@Test去掉了) Function,Consumer,Predicate,Supplier这些接口有一个共性,就是都有一个@FunctionalInterface的注解, 有了这个注解,你就可以自定义lamda表达式了. 本文先介绍一些例子,然后自定义一个lamda表达式的接口. 先看一下Function接口定义: 12@FunctionalInterface public interface Function&lt;T, R&gt; 接口接受两个泛型类型&lt;T, R&gt;. 再看一下接口定义的方法(非静态,非default), 支持lamda表达式的接口只允许定义一个抽象方法(@FunctionalInterface注解的接口,只允许定义一个抽象方法),只要记住这一点,你就不会弄混了. 12345R apply(T t); /** * T 入参类型, t 输入参数 * R 返回值类型 */ OK, 现在明确了, 该接口的lamda表达式应该是接受一个入参,最后要有一个返回值, 写法应该是这样的: (x) -&gt; {return y;} 如果你的lamda表达式非常简单,只有一行,那么你可以不写return, 不加花括号{}, 返回值后面可以不加分号. 下面就可以写example了, 写一个简单的, 再写一个标准的. 1234567891011 public void testFunction()&#123; //简单的,只有一行 Function&lt;Integer, String&gt; function1 = (x) -&gt; &quot;test result: &quot; + x; //标准的,有花括号, return, 分号. Function&lt;String, String&gt; function2 = (x) -&gt; &#123; return &quot;after function1&quot;; &#125;; System.out.println(function1.apply(6)); System.out.println(function1.andThen(function2).apply(6));&#125; OK, Function的例子写完了,接下来写其他的,其实原理懂了,其他的就都简单了,然后就是熟能生巧了. 再看看Supplier的接口定义,这个接口定义比较简单,我就都贴上来了 12345678910@FunctionalInterfacepublic interface Supplier&lt;T&gt; &#123; /** * Gets a result. * * @return a result */ T get();&#125; 接口接受一个泛型, 接口方法是一个无参数的方法, 有一个类型为T的返回值. OK, 那么接口的lamda表达式应该是这样的: () -&gt; { return something; }, 好,下面来写一个example. 1234567891011 public void testSupplier()&#123; //简写 Supplier&lt;String&gt; supplier1 = () -&gt; &quot;Test supplier&quot;; System.out.println(supplier1.get()); //标准格式 Supplier&lt;Integer&gt; supplier2 = () -&gt; &#123; return 20; &#125;; System.out.println(supplier2.get() instanceof Integer);&#125; 到这里你或许有一点疑惑, 这Supplier到底能用在哪啊? Java 8里新增了一个异步线程的类,很牛逼,很强大的类: CompletableFuture, 里面的很多方法的入参都用到的Supplier, 例如: supplyAsync方法. 本文暂时不介绍CompletableFuture. 接下来是Consumer, 我们来看一下接口的定义: 12@FunctionalInterfacepublic interface Consumer&lt;T&gt; 然后再看一下里面的抽象方法: 1void accept(T t); 现在了解了: 接口接受一个泛型, 接口方法是入参类型为T, 无返回值的方法, OK,下面开始写example: 1234567 public void testConsumer()&#123; Consumer&lt;String&gt; consumer1 = (x) -&gt; System.out.print(x); Consumer&lt;String&gt; consumer2 = (x) -&gt; &#123; System.out.println(&quot; after consumer 1&quot;); &#125;; consumer1.andThen(consumer2).accept(&quot;test consumer1&quot;);&#125; 接下来看一下Predicate接口 接口定义: 12@FunctionalInterface public interface Predicate&lt;T&gt; 抽象方法: 1boolean test(T t); 接口接受一个泛型, 接口方法的入参类型是T, 返回值是一个布尔值, OK, 下面写example: 1234 public void testPredicate()&#123; Predicate&lt;String&gt; predicate = (x) -&gt; x.length() &gt; 0; System.out.println(predicate.test(&quot;String&quot;));&#125; Predicate接口在stream里面用的比较多, 感兴趣的可以去看看stream, java 8 里另一个新的东西,很好玩. 到这里基本明白这些lamda表达式的接口怎么用了,接下来自定义一个支持lamda表达式的接口玩玩, 123456789@FunctionalInterface public interface CustomLamda&lt;T&gt; &#123; T testCustomFunction(Consumer&lt;T&gt; cunsumer); /*如果把下面方法的注释放开, 那么接口就报错了. 验证了前面所说的:@FunctionalInterface注解的接口只允许 *有一个抽象方法 */ //T anErrorMethod();&#125; 下面是实现: 12345678910 public void testCustomLamda()&#123; Consumer&lt;String&gt; consumer = (x) -&gt; &#123; System.out.println(&quot;test&quot; + x); &#125;; CustomLamda&lt;String&gt; customLamda = (x) -&gt; &#123; x.accept(&quot;6&quot;); return &quot;6&quot;; &#125;; customLamda.testCustomFunction(consumer);&#125; 本文仅仅是抛砖引玉, 深入的东西还需要多读多看. 转载于 https://my.oschina.net/u/576554/blog/535010]]></content>
  </entry>
  <entry>
    <title><![CDATA[JAVA中@NotNull和@Nonnull有什么区别]]></title>
    <url>%2F2018%2F04%2F23%2FJAVA%E4%B8%AD-NotNull%E5%92%8C-Nonnull%E6%9C%89%E4%BB%80%E4%B9%88%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[@NotNull 是 JSR303（Bean的校验框架）的注解，用于运行时检查一个属性是否为空，如果为空则不合法。 @NonNull 是JSR 305（缺陷检查框架）的注解，是告诉编译器这个域不可能为空，当代码检查有空值时会给出一个风险警告，目前这个注解只有IDEA支持。]]></content>
  </entry>
  <entry>
    <title><![CDATA[Guava快速入门]]></title>
    <url>%2F2018%2F04%2F21%2FGuava%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[Guava工程包含了若干被Google的 Java项目广泛依赖 的核心库，例如：集合 [collections] 、缓存 [caching] 、原生类型支持 [primitives support] 、并发库 [concurrency libraries] 、通用注解 [common annotations] 、字符串处理 [string processing] 、I/O 等等。 guava类似Apache Commons工具集 基本工具包BaseOptionalguava的Optional类似于Java 8新增的Optional类，都是用来处理null的，不过guava的是抽象类，其实现类为Absent和Present，而java.util的是final类。其中一部分方法名是相同的。 Guava用Optional表示可能为null的T类型引用。一个Optional实例可能包含非null的引用（我们称之为引用存在），也可能什么也不包括（称之为引用缺失）。它从不说包含的是null值，而是用存在或缺失来表示。但Optional从不会包含null值引用。 12345678910111213141516171819202122public class OptionalDemo &#123; public static void main(String[] args) &#123; Integer value1=null; Integer value2=10; /*创建指定引用的Optional实例，若引用为null则快速失败返回absent() absent()创建引用缺失的Optional实例 */ Optional&lt;Integer&gt; a=Optional.fromNullable(value1); Optional&lt;Integer&gt; b=Optional.of(value2); //返回包含给定的非空引用Optional实例 System.out.println(sum(a,b)); &#125; private static Integer sum(Optional&lt;Integer&gt; a,Optional&lt;Integer&gt; b)&#123; //isPresent():如果Optional包含非null的引用（引用存在），返回true System.out.println(&quot;First param is present: &quot;+a.isPresent()); System.out.println(&quot;Second param is present: &quot;+b.isPresent()); Integer value1=a.or(0); //返回Optional所包含的引用,若引用缺失,返回指定的值 Integer value2=b.get(); //返回所包含的实例,它必须存在,通常在调用该方法时会调用isPresent()判断是否为null return value1+value2; &#125;&#125;1234567891011121314151617181920212223 Preconditions前置条件Preconditions提供静态方法来检查方法或构造函数，被调用是否给定适当的参数。它检查的先决条件。其方法失败抛出IllegalArgumentException。 1234567891011121314151617181920212223242526272829303132333435363738394041424344public class PreconditionsDemo &#123; public static void main(String[] args) &#123; try &#123; getValue(5); &#125; catch (IndexOutOfBoundsException e)&#123; System.out.println(e.getMessage()); &#125; try &#123; sum(4,null); &#125; catch (NullPointerException e)&#123; System.out.println(e.getMessage()); &#125; try &#123; sqrt(-1); &#125; catch (IllegalArgumentException e)&#123; System.out.println(e.getMessage()); &#125; &#125; private static double sqrt(double input)&#123; Preconditions.checkArgument(input&gt;0.0, &quot;Illegal Argument passed: Negative value %s.&quot;,input); return Math.sqrt(input); &#125; private static int sum(Integer a,Integer b)&#123; a=Preconditions.checkNotNull(a, &quot;Illegal Argument passed: First parameter is Null.&quot;); b=Preconditions.checkNotNull(b, &quot;Illegal Argument passed: First parameter is Null.&quot;); return a+b; &#125; private static int getValue(int input)&#123; int[] data=&#123;1,2,3,4,5&#125;; int index=Preconditions.checkElementIndex(input,data.length, &quot;Illegal Argument passed: Invalid index.&quot;); return data[index]; &#125;&#125;123456789101112131415161718192021222324252627282930313233343536373839404142434445 JoinerJoiner 提供了各种方法来处理字符串加入操作，对象等。 Joiner的实例不可变的，因此是线程安全的。 Warning: joiner instances are always immutable; a configuration method such as { useForNull} has no effect on the instance it is invoked on! You must store and use the new joiner instance returned by the method. This makes joiners thread-safe, and safe to store as {@code static final} constants. 12345678910&gt; &#123;@code &gt;&gt; // Bad! Do not do this! &gt;&gt; Joiner joiner = Joiner.on(‘,’); &gt;&gt; joiner.skipNulls(); // does nothing!分开写跳过null就不起作用了，因为实例不可改变 &gt;&gt; return joiner.join(“wrong”, null, “wrong”);&#125;&gt; 1234567891011121314151617181920public class JoinerDemo &#123; public static void main(String[] args) &#123; /* on:制定拼接符号，如：test1-test2-test3 中的 “-“ 符号 skipNulls()：忽略NULL,返回一个新的Joiner实例 useForNull(“Hello”)：NULL的地方都用字符串”Hello”来代替 */ StringBuilder sb=new StringBuilder(); Joiner.on(&quot;,&quot;).skipNulls().appendTo(sb,&quot;Hello&quot;,&quot;guava&quot;); System.out.println(sb); System.out.println(Joiner.on(&quot;,&quot;).useForNull(&quot;none&quot;).join(1,null,3)); System.out.println(Joiner.on(&quot;,&quot;).skipNulls().join(Arrays.asList(1,2,3,4,null,6))); Map&lt;String,String&gt;map=new HashMap&lt;&gt;(); map.put(&quot;key1&quot;,&quot;value1&quot;); map.put(&quot;key2&quot;,&quot;value2&quot;); map.put(&quot;key3&quot;,&quot;value3&quot;); System.out.println(Joiner.on(&quot;,&quot;).withKeyValueSeparator(&quot;=&quot;).join(map)); &#125;&#125;123456789101112131415161718192021 SplitterSplitter 能够将一个字符串按照指定的分隔符拆分成可迭代遍历的字符串集合，Iterable 12345678910111213141516171819public class SplitterDemo &#123; public static void main(String[] args) &#123; /* on():指定分隔符来分割字符串 limit():当分割的子字符串达到了limit个时则停止分割 fixedLength():根据长度来拆分字符串 trimResults():去掉子串中的空格 omitEmptyStrings():去掉空的子串 withKeyValueSeparator():要分割的字符串中key和value间的分隔符,分割后的子串中key和value间的分隔符默认是= */ System.out.println(Splitter.on(&quot;,&quot;).limit(3).trimResults().split(&quot; a, b, c, d&quot;));//[ a, b, c,d] System.out.println(Splitter.fixedLength(3).split(&quot;1 2 3&quot;));//[1 2, 3] System.out.println(Splitter.on(&quot; &quot;).omitEmptyStrings().splitToList(&quot;1 2 3&quot;)); System.out.println(Splitter.on(&quot;,&quot;).omitEmptyStrings().split(&quot;1,,,,2,,,3&quot;));//[1, 2, 3] System.out.println(Splitter.on(&quot; &quot;).trimResults().split(&quot;1 2 3&quot;)); //[1, 2, 3],默认的连接符是, System.out.println(Splitter.on(&quot;;&quot;).withKeyValueSeparator(&quot;:&quot;).split(&quot;a:1;b:2;c:3&quot;));//&#123;a=1, b=2, c=3&#125; &#125;&#125;1234567891011121314151617181920 Objectsjava7及以后的版本建议使用jdk中的Objects类 EventBusGuava为我们提供了事件总线EventBus库，它是事件发布-订阅模式的实现，让我们能在领域驱动设计(DDD)中以事件的弱引用本质对我们的模块和领域边界很好的解耦设计。 Guava为我们提供了同步事件EventBus和异步实现AsyncEventBus两个事件总线，他们都不是单例的。 Guava发布的事件默认不会处理线程安全的，但我们可以标注@AllowConcurrentEvents来保证其线程安全 如果Listener A监听Event A, 而Event A有一个子类Event B, 此时Listener A将同时接收Event A和B消息 事件 12345678910111213//Guava 发布-订阅模式中传递的事件,是一个普通的POJO类public class OrderEvent &#123; //事件 private String message; public OrderEvent(String message) &#123; this.message = message; &#125; public String getMessage() &#123; return message; &#125;&#125;1234567891011121314 订阅 123456789101112131415161718public class EventListener &#123; //订阅者 //@Subscribe保证有且只有一个输入参数,如果你需要订阅某种类型的消息,只需要在指定的方法上加上@Subscribe注解即可 @Subscribe public void listen(OrderEvent event)&#123; System.out.println(&quot;receive message: &quot;+event.getMessage()); &#125; /* 一个subscriber也可以同时订阅多个事件 Guava会通过事件类型来和订阅方法的形参来决定到底调用subscriber的哪个订阅方法 */ @Subscribe public void listen(String message)&#123; System.out.println(&quot;receive message: &quot;+message); &#125;&#125;12345678910111213141516171819 多个订阅者 12345678910111213public class MultiEventListener &#123; @Subscribe public void listen(OrderEvent event)&#123; System.out.println(&quot;receive msg: &quot;+event.getMessage()); &#125; @Subscribe public void listen(String message)&#123; System.out.println(&quot;receive msg: &quot;+message); &#125;&#125;1234567891011121314 123456789101112131415public class EventBusDemo &#123; public static void main(String[] args) &#123; EventBus eventBus=new EventBus(&quot;jack&quot;); /* 如果多个subscriber订阅了同一个事件,那么每个subscriber都将收到事件通知 并且收到事件通知的顺序跟注册的顺序保持一致 */ eventBus.register(new EventListener()); //注册订阅者 eventBus.register(new MultiEventListener()); eventBus.post(new OrderEvent(&quot;hello&quot;)); //发布事件 eventBus.post(new OrderEvent(&quot;world&quot;)); eventBus.post(&quot;!&quot;); &#125;&#125;12345678910111213141516 DeadEvent 如果EventBus发送的消息都不是订阅者关心的称之为Dead Event。 1234567891011121314public class DeadEventListener &#123; boolean isDelivered=true; @Subscribe public void listen(DeadEvent event)&#123; isDelivered=false; System.out.println(event.getSource().getClass()+&quot; &quot;+event.getEvent()); //source通常是EventBus &#125; public boolean isDelivered() &#123; return isDelivered; &#125;&#125;123456789101112131415 Collection不可变集合不可变对象有很多优点，包括： 当对象被不可信的库调用时，不可变形式是安全的； 不可变对象被多个线程调用时，不存在竞态条件问题 不可变集合不需要考虑变化，因此可以节省时间和空间。所有不可变的集合都比它们的可变形式有更好的内存利用率（分析和测试细节）； 不可变对象因为有固定不变，可以作为常量来安全使用。 JDK也提供了Collections.unmodifiableXXX方法把集合包装为不可变形式，但： 笨重而且累赘：不能舒适地用在所有想做防御性拷贝的场景； 不安全：要保证没人通过原集合的引用进行修改，返回的集合才是事实上不可变的； 低效：包装过的集合仍然保有可变集合的开销，比如并发修改的检查、散列表的额外空间，等等。 创建不可变集合方法： copyOf方法，如ImmutableSet.copyOf(set); of方法，如ImmutableSet.of(“a”, “b”, “c”)或 ImmutableMap.of(“a”, 1, “b”, 2); Builder工具 12345678910public class ImmutableDemo &#123; public static void main(String[] args) &#123; ImmutableSet&lt;String&gt; set=ImmutableSet.of(&quot;a&quot;,&quot;b&quot;,&quot;c&quot;,&quot;d&quot;); ImmutableSet&lt;String&gt; set1=ImmutableSet.copyOf(set); ImmutableSet&lt;String&gt; set2=ImmutableSet.&lt;String&gt;builder().addAll(set).add(&quot;e&quot;).build(); System.out.println(set); ImmutableList&lt;String&gt; list=set.asList(); &#125;&#125;1234567891011 新型集合类MultisetMultiset可统计一个词在文档中出现了多少次 123456789101112131415161718public class MultiSetDemo &#123; public static void main(String[] args) &#123; Multiset&lt;String&gt; set=LinkedHashMultiset.create(); set.add(&quot;a&quot;); set.add(&quot;a&quot;); set.add(&quot;a&quot;); set.add(&quot;a&quot;); set.setCount(&quot;a&quot;,5); //添加或删除指定元素使其在集合中的数量是count System.out.println(set.count(&quot;a&quot;)); //给定元素在Multiset中的计数 System.out.println(set); System.out.println(set.size()); //所有元素计数的总和,包括重复元素 System.out.println(set.elementSet().size()); //所有元素计数的总和,不包括重复元素 set.clear(); //清空集合 System.out.println(set); &#125;&#125;12345678910111213141516171819 MultimapMultimap可以很容易地把一个键映射到多个值。换句话说，Multimap是把键映射到任意多个值的一般方式。 1234567891011121314public class MultiMapDemo &#123; public static void main(String[] args) &#123; Multimap&lt;String,Integer&gt; map= HashMultimap.create(); //Multimap是把键映射到任意多个值的一般方式 map.put(&quot;a&quot;,1); //key相同时不会覆盖原value map.put(&quot;a&quot;,2); map.put(&quot;a&quot;,3); System.out.println(map); //&#123;a=[1, 2, 3]&#125; System.out.println(map.get(&quot;a&quot;)); //返回的是集合 System.out.println(map.size()); //返回所有”键-单个值映射”的个数,而非不同键的个数 System.out.println(map.keySet().size()); //返回不同key的个数 Map&lt;String,Collection&lt;Integer&gt;&gt; mapView=map.asMap(); &#125;&#125;123456789101112131415 BiMapBiMap 12345678910111213141516171819public class BitMapDemo &#123; public static void main(String[] args) &#123; BiMap&lt;String,String&gt; biMap= HashBiMap.create(); biMap.put(&quot;sina&quot;,&quot;sina.com&quot;); biMap.put(&quot;qq&quot;,&quot;qq.com&quot;); biMap.put(&quot;sina&quot;,&quot;sina.cn&quot;); //会覆盖原来的value /* 在BiMap中,如果你想把键映射到已经存在的值，会抛出IllegalArgumentException异常 如果对特定值,你想要强制替换它的键，请使用 BiMap.forcePut(key, value) */ biMap.put(&quot;tecent&quot;,&quot;qq.com&quot;); //抛出异常 biMap.forcePut(&quot;tecent&quot;,&quot;qq.com&quot;); //强制替换key System.out.println(biMap); System.out.println(biMap.inverse().get(&quot;sina.com&quot;)); //通过value找key System.out.println(biMap.inverse().inverse()==biMap); //true &#125;&#125;1234567891011121314151617181920 TableTable它有两个支持所有类型的键：”行”和”列”。 1234567891011121314151617181920public class TableDemo &#123; public static void main(String[] args) &#123; //记录学生在某门课上的成绩 Table&lt;String,String,Integer&gt; table= HashBasedTable.create(); table.put(&quot;jack&quot;,&quot;java&quot;,100); table.put(&quot;jack&quot;,&quot;c&quot;,90); table.put(&quot;mike&quot;,&quot;java&quot;,93); table.put(&quot;mike&quot;,&quot;c&quot;,100); Set&lt;Table.Cell&lt;String,String,Integer&gt;&gt; cells=table.cellSet(); for (Table.Cell&lt;String,String,Integer&gt; cell : cells) &#123; System.out.println(cell.getRowKey()+&quot; &quot;+cell.getColumnKey()+&quot; &quot;+cell.getValue()); &#125; System.out.println(table.row(&quot;jack&quot;)); System.out.println(table); System.out.println(table.rowKeySet()); System.out.println(table.columnKeySet()); System.out.println(table.values()); &#125;&#125;123456789101112131415161718192021 Collections2filter（）：只保留集合中满足特定要求的元素 12345678910public class FilterDemo &#123; public static void main(String[] args) &#123; List&lt;String&gt; list= Lists.newArrayList(&quot;moon&quot;,&quot;dad&quot;,&quot;refer&quot;,&quot;son&quot;); Collection&lt;String&gt; palindromeList= Collections2.filter(list, input -&gt; &#123; return new StringBuilder(input).reverse().toString().equals(input); //找回文串 &#125;); System.out.println(palindromeList); &#125;&#125;1234567891011 transform（）：类型转换 1234567891011121314151617public class TransformDemo &#123; public static void main(String[] args) &#123; Set&lt;Long&gt; times= Sets.newHashSet(); times.add(91299990701L); times.add(9320001010L); times.add(9920170621L); Collection&lt;String&gt; timeStrCol= Collections2.transform(times, new Function&lt;Long, String&gt;() &#123; @Nullable @Override public String apply(@Nullable Long input) &#123; return new SimpleDateFormat(&quot;yyyy-MM-dd&quot;).format(input); &#125; &#125;); System.out.println(timeStrCol); &#125;&#125;123456789101112131415161718 多个Function组合 12345678910111213141516171819202122232425public class TransformDemo &#123; public static void main(String[] args) &#123; List&lt;String&gt; list= Lists.newArrayList(&quot;abcde&quot;,&quot;good&quot;,&quot;happiness&quot;); //确保容器中的字符串长度不超过5 Function&lt;String,String&gt; f1=new Function&lt;String, String&gt;() &#123; @Nullable @Override public String apply(@Nullable String input) &#123; return input.length()&gt;5?input.substring(0,5):input; &#125; &#125;; //转成大写 Function&lt;String,String&gt; f2=new Function&lt;String, String&gt;() &#123; @Nullable @Override public String apply(@Nullable String input) &#123; return input.toUpperCase(); &#125; &#125;; Function&lt;String,String&gt; function=Functions.compose(f1,f2); Collection&lt;String&gt; results=Collections2.transform(list,function); System.out.println(results); &#125;&#125;1234567891011121314151617181920212223242526 集合操作：交集、差集、并集12345678910111213public class CollectionsDemo &#123; public static void main(String[] args) &#123; Set&lt;Integer&gt; set1= Sets.newHashSet(1,2,3,4,5); Set&lt;Integer&gt; set2=Sets.newHashSet(3,4,5,6); Sets.SetView&lt;Integer&gt; inter=Sets.intersection(set1,set2); //交集 System.out.println(inter); Sets.SetView&lt;Integer&gt; diff=Sets.difference(set1,set2); //差集,在A中不在B中 System.out.println(diff); Sets.SetView&lt;Integer&gt; union=Sets.union(set1,set2); //并集 System.out.println(union); &#125;&#125;1234567891011121314 Cache缓存在很多场景下都是相当有用的。例如，计算或检索一个值的代价很高，并且对同样的输入需要不止一次获取值的时候，就应当考虑使用缓存。 Guava Cache与ConcurrentMap很相似，但也不完全一样。最基本的区别是ConcurrentMap会一直保存所有添加的元素，直到显式地移除。相对地，Guava Cache为了限制内存占用，通常都设定为自动回收元素。在某些场景下，尽管LoadingCache 不回收元素，它也是很有用的，因为它会自动加载缓存。 Guava Cache是一个全内存的本地缓存实现，它提供了线程安全的实现机制。 通常来说，Guava Cache适用于： 你愿意消耗一些内存空间来提升速度。 你预料到某些键会被查询一次以上。 缓存中存放的数据总量不会超出内存容量。（Guava Cache是单个应用运行时的本地缓存。它不把数据存放到文件或外部服务器。 如果这不符合你的需求，请尝试Memcached这类工具） Guava Cache有两种创建方式： cacheLoader callable callback LoadingCache是附带CacheLoader构建而成的缓存实现 12345678910111213141516171819202122232425public class LoadingCacheDemo &#123; public static void main(String[] args) &#123; LoadingCache&lt;String,String&gt; cache= CacheBuilder.newBuilder() .maximumSize(100) //最大缓存数目 .expireAfterAccess(1, TimeUnit.SECONDS) //缓存1秒后过期 .build(new CacheLoader&lt;String, String&gt;() &#123; @Override public String load(String key) throws Exception &#123; return key; &#125; &#125;); cache.put(&quot;j&quot;,&quot;java&quot;); cache.put(&quot;c&quot;,&quot;cpp&quot;); cache.put(&quot;s&quot;,&quot;scala&quot;); cache.put(&quot;g&quot;,&quot;go&quot;); try &#123; System.out.println(cache.get(&quot;j&quot;)); TimeUnit.SECONDS.sleep(2); System.out.println(cache.get(&quot;s&quot;)); //输出s &#125; catch (ExecutionException | InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125;1234567891011121314151617181920212223242526 123456789101112131415public class CallbackDemo &#123; public static void main(String[] args) &#123; Cache&lt;String,String&gt; cache= CacheBuilder.newBuilder() .maximumSize(100) .expireAfterAccess(1, TimeUnit.SECONDS) .build(); try &#123; String result=cache.get(&quot;java&quot;, () -&gt; &quot;hello java&quot;); System.out.println(result); &#125; catch (ExecutionException e) &#123; e.printStackTrace(); &#125; &#125;&#125;12345678910111213141516 refresh机制：- LoadingCache.refresh(K) 在生成新的value的时候，旧的value依然会被使用。- CacheLoader.reload(K, V) 生成新的value过程中允许使用旧的value- CacheBuilder.refreshAfterWrite(long, TimeUnit) 自动刷新cache 并发ListenableFuture传统JDK中的Future通过异步的方式计算返回结果:在多线程运算中可能或者可能在没有结束返回结果，Future是运行中的多线程的一个引用句柄，确保在服务执行返回一个Result。 ListenableFuture可以允许你注册回调方法(callbacks)，在运算（多线程执行）完成的时候进行调用, 或者在运算（多线程执行）完成后立即执行。这样简单的改进，使得可以明显的支持更多的操作，这样的功能在JDK concurrent中的Future是不支持的。 1234567891011121314151617181920212223242526272829303132333435public class ListenableFutureDemo &#123; public static void main(String[] args) &#123; //将ExecutorService装饰成ListeningExecutorService ListeningExecutorService service= MoreExecutors.listeningDecorator( Executors.newCachedThreadPool()); //通过异步的方式计算返回结果 ListenableFuture&lt;String&gt; future=service.submit(() -&gt; &#123; System.out.println(&quot;call execute..&quot;); return &quot;task success!&quot;; &#125;); //有两种方法可以执行此Future并执行Future完成之后的回调函数 future.addListener(() -&gt; &#123; //该方法会在多线程运算完的时候,指定的Runnable参数传入的对象会被指定的Executor执行 try &#123; System.out.println(&quot;result: &quot;+future.get()); &#125; catch (InterruptedException | ExecutionException e) &#123; e.printStackTrace(); &#125; &#125;,service); Futures.addCallback(future, new FutureCallback&lt;String&gt;() &#123; @Override public void onSuccess(@Nullable String result) &#123; System.out.println(&quot;callback result: &quot;+result); &#125; @Override public void onFailure(Throwable t) &#123; System.out.println(t.getMessage()); &#125; &#125;,service); &#125;&#125;123456789101112131415161718192021222324252627282930313233343536 IO1234567891011121314151617181920212223242526272829303132333435public class FileDemo &#123; public static void main(String[] args) &#123; File file=new File(System.getProperty(&quot;user.dir&quot;)); &#125; //写文件 private void writeFile(String content,File file) throws IOException &#123; if (!file.exists())&#123; file.createNewFile(); &#125; Files.write(content.getBytes(Charsets.UTF_8),file); &#125; //读文件 private List&lt;String&gt; readFile(File file) throws IOException &#123; if (!file.exists())&#123; return ImmutableList.of(); //避免返回null &#125; return Files.readLines(file,Charsets.UTF_8); &#125; //文件复制 private void copyFile(File from,File to) throws IOException &#123; if (!from.exists())&#123; return; &#125; if (!to.exists())&#123; to.createNewFile(); &#125; Files.copy(from,to); &#125;&#125;123456789101112131415161718192021222324252627282930313233343536 Google Guava官方教程（中文版）guava-importnew 版权声明：转载请注明本文源地址 https://blog.csdn.net/dgeek/article/details/76221746]]></content>
  </entry>
  <entry>
    <title><![CDATA[Guava(瓜娃)学习笔记]]></title>
    <url>%2F2018%2F04%2F21%2FGuava-%E7%93%9C%E5%A8%83-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[Guava工程包含了若干被google的java项目广泛依赖的核心库，例如：集合 [collections] 、缓存 [caching] 、原生类型支持 [primitives support] 、并发库 [concurrency libraries] 、通用注解 [commonannotations] 、字符串处理 [string processing] 、I/O 等等。所有这些工具每天都在被Google的工程师应用在产品服务中。 这些高质量的API可以使你的java代码更加优雅，更加简洁，让你的工作更加轻松愉悦，下面我们来开启Java编程学习之旅。 源码包的简单说明： com.google.common.annotations：普通注解类型。 com.google.common.base：基本工具类库和接口。 com.google.common.cache：缓存工具包，非常简单易用且功能强大的JVM内缓存。 com.google.common.collect：带泛型的集合接口扩展和实现，以及工具类，这里你会发现很多好玩的集合。 com.google.common.eventbus：发布订阅风格的事件总线。 com.google.common.hash： 哈希工具包。 com.google.common.io：I/O工具包。 com.google.common.math：原始算术类型和超大数的运算工具包。 com.google.common.net：网络工具包。 com.google.common.primitives：八种原始类型和无符号类型的静态工具包。 com.google.common.reflect：反射工具包。 com.google.common.util.concurrent：多线程工具包。 1. 基本工具（Basic utilities）1) 使用和避免null（Optional）null会引起歧义，会造成让人迷惑的错误，有时也会让人感到不爽。Guava中的许多工具遇到null时，会拒绝或者马上报错，而不是盲目的接受。 鉴于此google的guava库中提供了Optional接口来使null快速失败，即在可能为null的对象上做了一层封装，在使用Optional静态方法of时，如果传入的参数为null就抛出NullPointerException异常。 在Guava中Optional类就是用来强制提醒程序员，注意对Null的判断。 Optional的另外几个方法 Optional.of(T) 为Optional赋值，当T为Null直接抛NullPointException,建议这个方法在调用的时候直接传常量，不要传变量 Optional.fromNullable(T) 为Optional赋值，当T为Null则使用默认值。建议与or方法一起用，风骚无比 Optional.absent() 为Optional赋值，采用默认值 T or(T) 当Optional的值为null时，使用or赋予的值返回。与fromNullable是一对好基友 T get() 当Optional的值为null时，抛出IllegalStateException，返回Optional的值 boolean isPresent() 如果Optional存在值，则返回True T orNull() 当Optional的值为null时，则返回Null。否则返回Optional的值 Set asSet() 将Optional中的值转为一个Set返回，当然只有一个值啦，或者为空，当值为null时。 使用Optional的意义？ 使用Optional除了赋予null语义，增加了可读性，最大的优点在于它一种傻瓜式的防护，Optional迫使你积极思考引用缺失的情况，因为你必须显式地从Optional获取引用。直接使用null很容易让人忘掉某些情形，尽管FindBugs可以帮助查找null相关的问题，但是我们还是认为它并不能准确地定位问题根源。 2) 前提条件（Preconditions）使方法的条件检查更简单。 Guava在Preconditions类中提供了若干前置条件判断的实用方法，我们强烈建议在Eclipse中静态导入这些方法。每个方法都有三个变种： a) 没有额外参数：抛出的异常中没有错误消息； b) 有一个Object对象作为额外参数：抛出的异常使用Object.toString() 作为错误消息； c) 有一个String对象作为额外参数，并且有一组任意数量的附加Object对象：这个变种处理异常消息的方式有点类似printf，但考虑GWT的兼容性和效率，只支持%s指示符。 例如：查看源代码打印帮助 checkArgument(i&gt;= 0, “Argument was %s but expected nonnegative”, i); checkArgument(i&lt; j, “Expected i &lt; j, but %s &gt; %s”, i, j); 方法声明（不包括额外参数） 描述 检查失败时抛出的异常 checkArgument(boolean) 检查boolean是否为true，用来检查传递给方法的参数。 IllegalArgumentException checkNotNull(T) 检查value是否为null，该方法直接返回value，因此可以内嵌使用checkNotNull。 NullPointerException checkState(boolean) 用来检查对象的某些状态。 IllegalStateException checkElementIndex(int index, int size) 检查index作为索引值对某个列表、字符串或数组是否有效。index&gt;=0 &amp;&amp; index&lt;size * IndexOutOfBoundsException checkPositionIndex(int index, int size) 检查index作为位置值对某个列表、字符串或数组是否有效。index&gt;=0 &amp;&amp; index&lt;=size * IndexOutOfBoundsException checkPositionIndexes(int start, int end, int size) 检查[start, end]表示的位置范围对某个列表、字符串或数组是否有效* IndexOutOfBoundsException 3) 常见的对象方法（Objects）简化Object方法实现，如hashCode()和toString()； a) equals 当一个对象中的字段可以为null时，实现Object.equals方法会很痛苦，因为不得不分别对它们进行null检查。使用Objects.equal帮助你执行null敏感的equals判断，从而避免抛出NullPointerException。 b) hashCode 用对象的所有字段作散列[hash]运算应当更简单。Guava的Objects.hashCode(Object…)会对传入的字段序列计算出合理的、顺序敏感的散列值。你可以使用Objects.hashCode(field1, field2, …, fieldn)来代替手动计算散列值。 c) toString 好的toString方法在调试时是无价之宝，但是编写toString方法有时候却很痛苦。使用 Objects.toStringHelper可以轻松编写有用的toString方法。 4) 排序Guava强大的”流畅风格比较器”,具体到下章会介绍到。 5) Throwable类简化了异常和错误的传播与检查； guava类库中的Throwables提供了一些异常处理的静态方法，这些方法的从功能上分为两类，一类是帮你抛出异常，另外一类是帮你处理异常。 RuntimeException propagate(Throwable) 如果Throwable是Error或RuntimeException，直接抛出；否则把Throwable包装成RuntimeException抛出。返回类型是RuntimeException，所以你可以像上面说的那样写成throw Throwables.propagate(t)，Java编译器会意识到这行代码保证抛出异常。 void propagateIfInstanceOf( Throwable, Class) throws X Throwable类型为X才抛出 void propagateIfPossible( Throwable) Throwable类型为Error或RuntimeException才抛出 void propagateIfPossible( Throwable, Class) throws X Throwable类型为X, Error或RuntimeException才抛出 2. 集合（Collections）介绍guava对jdk集合类的扩展，包括不可变集合，新集合类型: multisets, multimaps, tables, bidirectional maps等，强大的集合工具类: 提供java.util.Collections中没有的集合工具，扩展工具类：让实现和扩展集合类变得更容易，比如创建Collection的装饰器，或实现迭代器 集合API的使用, 可以简化集合的创建和初始化； guava API 提供了有用的新的集合类型，协同已经存在的java集合工作的很好。 分别是 MultiMap， MultiSet， Table， BiMap，ClassToInstanceMap 1) google guava的不可变集合不可变对象有很多优点： a) 当对象被不可信的库调用时，不可变形式是安全的。 b) 当不可变对象被对个线程调用时，不存在竞态条件问题； c) 不可变集合不需要考虑变化，因此可以节约时间和空间，所有不可变集合都比可变集合形式有更好的内存利用率（分析和测试细节）； d) 不可变对象因为有固定不变，可以用作常量来安全使用。 总结：数据不可变；不需要同步逻辑；线程安全；自由共享；容易设计和实现；内存和时间高效 创建对象的不可拷贝是一项很好的防御性编程技巧，Guava为所有JDK标准集合类型和Guava新集合类型都提供了简单易用的不可变版本。 JDK也提供了可以将集合变成不可变的方法，Collections.unmodifiableXXX，但是被认为是不好的。 a) 笨重而且累赘：不能舒适地用在所有想做防御性拷贝的场景； b) 不安全：要保证没人通过原集合的引用进行修改，返回的集合才是事实上不可变的； c) 低效：包装过的集合仍然保有可变集合的开销，比如并发修改的检查、散列表的额外空间，等等。 ​ 提示：guava不可变集合的实现都不接受null值，经过对google内部代码的研究发现，google内部只有不超过5%的情况下集合中允许了null值，其他情况下都不允许。如果我们相用null的不可变集合，那我们就用jdk中的集合类进行操作，然后进行集合工具类的处理Collections.unmodifiableXXX。 细节：关联可变集合和不可变集合 可变集合接口 属于jdk还是guava 不可变版本 Collection JDK ImmutableCollection List JDK ImmutableList Set JDK ImmutableSet SortedSet/NavigableSet JDK ImmutableSortedSet Map JDK ImmutableMap SortedMultiset Guava ImmutableSortedMultiset Multimap Guava ImmutableMultimap ListMultimap Guava ImmutableListMultimap SetMultimap Guava ImmutableSetMultimap BiMap Guava ImmutableBiMap ClassToInstanceMap Guava ImmutableClassToInstanceMap Table Guava ImmutableTable 2) google guava集合之MultisetMultiset看似是一个Set，但是实质上它不是一个Set，它没有继承Set接口，它继承的是Collection接口，你可以向Multiset中添加重复的元素，Multiset会对添加的元素做一个计数。 它本质上是一个Set加一个元素计数器。 显然计数不是问题，Multiset还提供了add和remove的重载方法，可以在add或这remove的同时指定计数的值。 常用实现 Multiset 接口的类有： HashMultiset: 元素存放于 HashMap LinkedHashMultiset:元素存放于 LinkedHashMap，即元素的排列顺序由第一次放入的顺序决定 TreeMultiset:元素被排序存放于TreeMap EnumMultiset: 元素必须是 enum 类型 ImmutableMultiset:不可修改的 Mutiset 看到这里你可能已经发现 GuavaCollections 都是以 create 或是 of 这样的静态方法来构造对象。这是因为这些集合类大多有多个参数的私有构造方法，由于参数数目很多，客户代码程序员使用起来就很不方便。而且以这种方式可以返回原类型的子类型对象。另外，对于创建范型对象来讲，这种方式更加简洁。 3) google guava的BiMap：双向Map我们知道Map是一种键值对映射，这个映射是键到值的映射，而BiMap首先也是一种Map，他的特别之处在于，既提供键到值的映射，也提供值到键的映射，所以它是双向Map. BiMap的常用实现有： HashBiMap: key 集合与 value 集合都有 HashMap 实现 EnumBiMap: key 与 value 都必须是 enum 类型 ImmutableBiMap: 不可修改的 BiMap 4) google guava的Multimaps：一键多值的Map有时候我们需要这样的数据类型Map&lt;String,Collection&gt;，guava中的Multimap就是为了解决这类问题的。 Multimap提供了丰富的实现，所以你可以用它来替代程序里的Map&lt;K, Collection&gt;，具体的实现如下： 实现 Key实现 Value实现 ArrayListMultimap HashMap ArrayList HashMultimap HashMap HashSet LinkedListMultimap LinkedHashMap LinkedList LinkedHashMultimap LinkedHashMap LinkedHashSet TreeMultimap TreeMap TreeSet ImmutableListMultimap ImmutableMap ImmutableList ImmutableSetMultimap ImmutableMap ImmutableSet 5) google guava集合之Table在guava库中还提供了一种二维表结构：Table。使用Table可以实现二维矩阵的数据结构，可以是稀溜矩阵。 通常来说，当你想使用多个键做索引的时候，你可能会用类似Map&lt;FirstName, Map&lt;LastName, Person&gt;&gt;的实现，这种方式很丑陋，使用上也不友好。Guava为此提供了新集合类型Table，它有两个支持所有类型的键：”行”和”列”。Table提供多种视图，以便你从各种角度使用它： rowMap()：用Map&lt;R, Map&lt;C, V&gt;&gt;表现Table&lt;R, C,V&gt;。同样的， rowKeySet()返回”行”的集合Set。 row(r) ：用Map&lt;C, V&gt;返回给定”行”的所有列，对这个map进行的写操作也将写入Table中。 类似的列访问方法：columnMap()、columnKeySet()、column(c)。（基于列的访问会比基于的行访问稍微低效点） cellSet()：用元素类型为Table.Cell&lt;R, C, V&gt;的Set表现Table&lt;R,C, V&gt;。Cell类似于Map.Entry，但它是用行和列两个键区分的。 6) Guava集合：使用Iterators简化Iterator操作Iterators是Guava中对Iterator迭代器操作的帮助类，这个类提供了很多有用的方法来简化Iterator的操作。 7) ClassToInstanceMap可以实现map的key值是多个类型有的时候，你的map的key并不是一种类型，他们是很多类型，你想通过映射他们得到这种类型，guava提供了ClassToInstanceMap满足了这个目的。 除了继承自Map接口，ClassToInstaceMap提供了方法 TgetInstance(Class) 和 T putInstance(Class, T),消除了强制类型转换。 8) Ordering犀利的比较器Ordering是Guava类库提供的一个犀利强大的比较器工具，Guava的Ordering和JDK Comparator相比功能更强。它非常容易扩展，可以轻松构造复杂的comparator，然后用在容器的比较、排序等操作中。 本质上来说，Ordering实例无非就是一个特殊的Comparator 实例。Ordering只是需要依赖于一个比较器（例如，Collections.max）的方法，并使其可作为实例方法。另外，Ordering提供了链式方法调用和加强现有的比较器。 常见的静态方法： natural()：使用Comparable类型的自然顺序，例如：整数从小到大，字符串是按字典顺序; usingToString() ：使用toString()返回的字符串按字典顺序进行排序； arbitrary() ：返回一个所有对象的任意顺序，即compare(a, b) == 0 就是 a == b (identity equality)。 本身的排序是没有任何含义， 但是在VM的生命周期是一个常量。 9) ComparisonChain比较实现一个比较器[Comparator]，或者直接实现Comparable接口有时也伤不起。考虑一下这种情况： class Studentimplements Comparable{ ​ private String lastName; ​ private String firstName; ​ private int zipCode; ​ //jdk ​ public int compareTo(Student other) { ​ int cmp =lastName.compareTo(other.lastName); ​ if (cmp != 0) { ​ return cmp; ​ } ​ cmp = firstName.compareTo(other.firstName); ​ if (cmp != 0) { ​ return cmp; ​ } ​ return Integer.compare(zipCode, other.zipCode); ​ } } 这部分代码太琐碎了，因此很容易搞乱，也很难调试。我们应该能把这种代码变得更优雅，为此，Guava提供了ComparisonChain。 ComparisonChain执行一种懒比较：它执行比较操作直至发现非零的结果，在那之后的比较输入将被忽略。 //guava比较优雅 ​ public int compareTo(Student other) { ​ returnComparisonChain.start() ​ .compare(this.lastName,other.lastName) ​ .compare(this.firstName,other.firstName) ​ .compare(this.zipCode,other.zipCode, Ordering.natural().nullsLast()) ​ .result(); ​ } 这种Fluent接口风格的可读性更高，发生错误编码的几率更小，并且能避免做不必要的工作。 3. 缓存（Caches）google guava框架提供了内存缓存的功能，可以很方便的缓存对象，设置生命周期, 及缓存对象的弱引用强应用 软引用等 1) 使用google guava做内存缓存google guava中有cache包，此包提供内存缓存功能。内存缓存需要考虑很多问题，包括并发问题，缓存失效机制，内存不够用时缓存释放，缓存的命中率，缓存的移除等等。当然这些东西guava都考虑到了。 guava的内存缓存非常强大，可以设置各种选项，而且很轻量，使用方便。另外还提供了下面一些方法，来方便各种需要： ImmutableMap&lt;K, V&gt; getAllPresent(Iterable&lt;?&gt; keys) 一次获得多个键的缓存值 put和putAll方法向缓存中添加一个或者多个缓存项 invalidate 和 invalidateAll方法从缓存中移除缓存项 asMap()方法获得缓存数据的ConcurrentMap&lt;K, V&gt;快照 cleanUp()清空缓存 refresh(Key) 刷新缓存，即重新取缓存数据，更新缓存 2) google guava缓存分析guava缓存过期时间分为两种，一种是从写入时开始计时，一种是从最后访问时间开始计时，而且guava缓存的过期时间是设置到整个一组缓存上的；这和EHCache，redis，memcached等不同，这些缓存系统设置都将缓存时间设置到了单个缓存上。 guava缓存设计成了一组对象一个缓存实例，这样做的好处是一组对象设置一组缓存策略，你可以根据不同的业务来设置不同的缓存策略，包括弱引用，软引用，过期时间，最大项数等。另外一点好处是你可以根据不同的组来统计缓存的命中率，这样更有意义一些。 这样做也是有缺点的，缺点是首先是每个缓存组都需要声明不同的缓存实例，具体到业务程序中可能就是每个业务对象一个缓存了。这样就把不同的业务缓存分散到不同的业务系统中了，不太好管理。 4. 函数式风格（Functional idioms）5. 并发（Concurrency）并发编程是一个难题，但是一个强大而简单的抽象可以显著的简化并发的编写。出于这样的考虑，Guava 定义了 ListenableFuture接口并继承了JDK concurrent包下的Future 接口。 1) Guava并发：ListenableFuture使用介绍以及示例ListenableFuture顾名思义就是可以监听的Future，它是对java原生Future的扩展增强，本文介绍ListenableFuture的用法和扩展实现 ListenableFuture顾名思义就是可以监听的Future，它是对java原生Future的扩展增强。我们知道Future表示一个异步计算任务，当任务完成时可以得到计算结果。如果我们希望一旦计算完成就拿到结果展示给用户或者做另外的计算，就必须使用另一个线程不断的查询计算状态。这样做，代码复杂，而且效率低下。使用ListenableFuture Guava帮我们检测Future是否完成了，如果完成就自动调用回调函数，这样可以减少并发程序的复杂度。 另外ListenableFuture还有其他几种内置实现： SettableFuture：不需要实现一个方法来计算返回值，而只需要返回一个固定值来做为返回值，可以通过程序设置此Future的返回值或者异常信息 CheckedFuture：这是一个继承自ListenableFuture接口，他提供了checkedGet()方法，此方法在Future执行发生异常时，可以抛出指定类型的异常。 2) Guava并发：RateLimiter限制资源的并发访问线程数RateLimiter类似于JDK的信号量Semphore，他用来限制对资源并发访问的线程数 RateLimiter类似于JDK的信号量Semphore，他用来限制对资源并发访问的线程数。 RateLimiterlimiter = RateLimiter.create(4.0);//每秒不超过4个任务被提交 limiter.acquire(); //请求RateLimiter,超过permits会被阻塞 executor.submit(runnable);//提交任务 也可以以非阻塞的形式来使用： 1If(limiter.tryAcquire())&#123; //未请求到limiter则立即返回false 1doSomething(); 1&#125;else&#123; 1doSomethingElse(); 1&#125; 3) Guava并发：使用Monitor控制并发Monitor就像java原生的synchronized,ReentrantLock一样，每次只允许一个线程执行代码块，且可重占用，每一次占用要对应一次退出占用。 /** 通过Monitor的Guard进行条件阻塞 */ public classMonitorSample { private List list = new ArrayList(); private static final int MAX_SIZE = 10; private Monitor monitor = new Monitor(); ​ private Monitor.Guard listBelowCapacity = new Monitor.Guard(monitor) { ​ @Override ​ public boolean isSatisfied() { ​ return list.size() &lt; MAX_SIZE; ​ } ​ }; public void addToList(String item) throws InterruptedException { ​ monitor.enterWhen(listBelowCapacity); //Guard(形如Condition)，不满足则阻塞，而且我们并没有在Guard进行任何通知操作 ​ try { ​ list.add(item); ​ } finally { ​ monitor.leave(); ​ } ​ } } 就如上面，我们通过if条件来判断是否可进入Monitor代码块，并再try/finally中释放： if(monitor.enterIf(guardCondition)) { ​ try { ​ doWork(); ​ }finally { ​ monitor.leave(); ​ } } 其他的Monitor访问方法： Monitor.enter //进入Monitor块，将阻塞其他线程直到Monitor.leave Monitor.tryEnter//尝试进入Monitor块，true表示可以进入, false表示不能，并且不会一直阻塞 Monitor.tryEnterIf//根据条件尝试进入Monitor块 这几个方法都有对应的超时设置版本。 6. 字符串处理（Strings）1) 连接器（Joiner）用分隔符把字符串序列连接起来也可能会遇上不必要的麻烦。如果字符串序列中含有null，那连接操作会更难。Fluent风格的Joiner让连接字符串更简单。 警告：joiner实例总是不可变的。用来定义joiner目标语义的配置方法总会返回一个新的joiner实例。这使得joiner实例都是线程安全的，你可以将其定义为staticfinal常量。 2) 拆分器（Splitter）JDK内建的字符串拆分工具有一些古怪的特性。比如，String.split悄悄丢弃了尾部的分隔符。例如： ”,a,,b,”.split(“,”) //””, “a”, “”, “b” 只有尾部的空字符串被忽略了 Splitter使用令人放心的、直白的流畅API模式对这些混乱的特性作了完全的掌控。 a) 拆分器工厂： 方法 描述 Splitter.on(char) 按单个字符拆分 Splitter.on(CharMatcher) 按字符匹配器拆分 Splitter.on(String) 按字符串拆分 Splitter.on(Pattern)Splitter.onPattern(String) 按正则表达式拆分 Splitter.fixedLength(int) 按固定长度拆分；最后一段可能比给定长度短，但不会为空。 b) 拆分器修饰符： 方法 描述 omitEmptyStrings() 从结果中自动忽略空字符串 trimResults() 移除结果字符串的前导空白和尾部空白 trimResults(CharMatcher) 给定匹配器，移除结果字符串的前导匹配字符和尾部匹配字符 limit(int) 限制拆分出的字符串数量 如果你想要拆分器返回List，只要使用Lists.newArrayList(splitter.split(string))或类似方法。 警告：splitter实例总是不可变的。用来定义splitter目标语义的配置方法总会返回一个新的splitter实例。这使得splitter实例都是线程安全的，你可以将其定义为static final常量。 3) 字符匹配器（CharMatcher）然而使用CharMatcher的好处更在于它提供了一系列方法，让你对字符作特定类型的操作：修剪[trim]、折叠[collapse]、移除[remove]、保留[retain]等等。CharMatcher实例首先代表概念1：怎么才算匹配字符？然后它还提供了很多操作概念2：如何处理这些匹配字符？这样的设计使得API复杂度的线性增加可以带来灵活性和功能两方面的增长。 注：CharMatcher只处理char类型代表的字符；它不能理解0x10000到0x10FFFF的Unicode增补字符。这些逻辑字符以代理对[surrogatepairs]的形式编码进字符串，而CharMatcher只能将这种逻辑字符看待成两个独立的字符。 4) 字符集（Charsets）Charsets针对所有Java平台都要保证支持的六种字符集提供了常量引用。尝试使用这些常量，而不是通过名称获取字符集实例。 5) 大小写格式（CaseFormat）CaseFormat被用来方便地在各种ASCII大小写规范间转换字符串——比如，编程语言的命名规范。CaseFormat支持的格式如下： 格式 范例 LOWER_CAMEL lowerCamel LOWER_HYPHEN lower-hyphen LOWER_UNDERSCORE lower_underscore UPPER_CAMEL UpperCamel UPPER_UNDERSCORE UPPER_UNDERSCORE CaseFormat的用法很直接： CaseFormat.UPPER_UNDERSCORE.to(CaseFormat.LOWER_CAMEL,”CONSTANT_NAME” )); // returns “constantName” 我们CaseFormat在某些时候尤其有用，比如编写代码生成器的时候。 7. 原生类型（Primitives）Java的原生类型也称原始类型，也是基本数据类型byte、short、int、long、float、double、char和boolean。 在从Guava查找原生类型方法之前，可以先查查Arrays类，或者对应的基础类型包装类，如Integer。 原生类型不能当作对象或泛型的类型参数使用，这意味着许多通用方法都不能应用于它们。Guava提供了若干通用工具，包括原生类型数组与集合API的交互，原生类型和字节数组的相互转换，以及对某些原生类型的无符号形式的支持。 原生类型 Guava工具类（都在com.google.common.primitives包） byte Bytes, SignedBytes, UnsignedBytes short Shorts int Ints, UnsignedInteger, UnsignedInts long Longs, UnsignedLong, UnsignedLongs float Floats double Doubles char Chars boolean Booleans Bytes工具类没有定义任何区分有符号和无符号字节的方法，而是把它们都放到了SignedBytes和UnsignedBytes工具类中，因为字节类型的符号性比起其它类型要略微含糊一些。 int和long的无符号形式方法在UnsignedInts和UnsignedLongs类中，但由于这两个类型的大多数用法都是有符号的，Ints和Longs类按照有符号形式处理方法的输入参数。 此外，Guava为int和long的无符号形式提供了包装类，即UnsignedInteger和UnsignedLong，以帮助你使用类型系统，以极小的性能消耗对有符号和无符号值进行强制转换。 原生类型数组工具: 方法签名 描述 List asList(prim… backingArray) 把数组转为相应包装类的List prim[] toArray(Collection collection) 把集合拷贝为数组，和collection.toArray()一样线程安全 prim[] concat(prim[]… arrays) 串联多个原生类型数组 boolean contains(prim[] array, prim target) 判断原生类型数组是否包含给定值 int indexOf(prim[] array, prim target) 给定值在数组中首次出现处的索引，若不包含此值返回-1 int lastIndexOf(prim[] array, prim target) 给定值在数组最后出现的索引，若不包含此值返回-1 prim min(prim… array) 数组中最小的值 prim max(prim… array) 数组中最大的值 String join(String separator, prim… array) 把数组用给定分隔符连接为字符串 Comparator&lt;prim[]&gt; lexicographicalComparator() 按字典序比较原生类型数组的Comparator *符号无关方法存在于Bytes, Shorts, Ints, Longs, Floats, Doubles, Chars, Booleans。而UnsignedInts,UnsignedLongs, SignedBytes, 或UnsignedBytes不存在。 *符号相关方法存在于SignedBytes, UnsignedBytes, Shorts, Ints, Longs, Floats, Doubles,Chars, Booleans, UnsignedInts, UnsignedLongs。而Bytes不存在。 通用工具方法： 方法签名 描述 int compare(prim a, prim b) 传统的Comparator.compare方法，但针对原生类型。JDK7的原生类型包装类也提供这样的方法 prim checkedCast(long value) 把给定long值转为某一原生类型，若给定值不符合该原生类型，则抛出IllegalArgumentException prim saturatedCast(long value) 把给定long值转为某一原生类型，若给定值不符合则使用最接近的原生类型值 *这里的整型包括byte, short, int, long。不包括char, boolean, float, 或double。 字节转换方法： Guava提供了若干方法，用来把原生类型按大字节序与字节数组相互转换。所有这些方法都是符号无关的，此外Booleans没有提供任何下面的方法。 方法签名或字段签名 描述 int BYTES 常量：表示该原生类型需要的字节数 prim fromByteArray(byte[] bytes) 使用字节数组的前Prims.BYTES个字节，按大字节序返回原生类型值；如果bytes.length &lt;= Prims.BYTES，抛出IAE prim fromBytes(byte b1, …, byte bk) 接受Prims.BYTES个字节参数，按大字节序返回原生类型值 byte[] toByteArray(prim value) 按大字节序返回value的字节数组 8. 区间（Ranges）1) 简介区间，有时也称为范围，是特定域中的凸性（非正式说法为连续的或不中断的）部分。在形式上，凸性表示对a&lt;=b&lt;=c, range.contains(a)且range.contains(c)意味着range.contains(b)。 区间可以延伸至无限——例如，范围”x&gt;3″包括任意大于3的值——也可以被限制为有限，如” 2&lt;=x&lt;5″。Guava用更紧凑的方法表示范围，有数学背景的程序员对此是耳熟能详的： (a..b) = {x | a &lt; x &lt; b} [a..b] = {x | a &lt;= x &lt;= b} [a..b) = {x | a &lt;= x &lt; b} (a..b] = {x | a &lt; x &lt;= b} (a..+∞) = {x | x &gt; a} [a..+∞) = {x | x &gt;= a} (-∞..b) = {x | x &lt; b} (-∞..b] = {x | x &lt;= b} (-∞..+∞) = 所有值 上面的a、b称为端点 。为了提高一致性，Guava中的Range要求上端点不能小于下端点。上下端点有可能是相等的，但要求区间是闭区间或半开半闭区间（至少有一个端点是包含在区间中的）： [a..a]：单元素区间 [a..a); (a..a]：空区间，但它们是有效的 (a..a)：无效区间 Guava用类型Range表示区间。所有区间实现都是不可变类型。 2) 构建区间区间实例可以由Range类的静态方法获取： (a..b) open(C, C) [a..b] closed(C, C) [a..b) closedOpen(C, C) (a..b] openClosed(C, C) (a..+∞) greaterThan(C) [a..+∞) atLeast(C) (-∞..b) lessThan(C) (-∞..b] atMost(C) (-∞..+∞) all() 此外，也可以明确地指定边界类型来构造区间： 有界区间 range(C, BoundType, C, BoundType) 无上界区间：((a..+∞) 或[a..+∞)) downTo(C, BoundType) 无下界区间：((-∞..b) 或(-∞..b]) upTo(C, BoundType) 这里的BoundType是一个枚举类型，包含CLOSED和OPEN两个值。 3) 区间运算Range的基本运算是它的contains(C) 方法，和你期望的一样，它用来区间判断是否包含某个值。此外，Range实例也可以当作Predicate，并且在函数式编程中使用（译者注：见第4章）。任何Range实例也都支持containsAll(Iterable&lt;? extends C&gt;)方法： 4) 查询运算Range类提供了以下方法来 查看区间的端点： hasLowerBound()和hasUpperBound()：判断区间是否有特定边界，或是无限的； lowerBoundType()和upperBoundType()：返回区间边界类型，CLOSED或OPEN；如果区间没有对应的边界，抛出IllegalStateException； lowerEndpoint()和upperEndpoint()：返回区间的端点值；如果区间没有对应的边界，抛出IllegalStateException； isEmpty()：判断是否为空区间。 5) 关系运算a) 包含[enclose] 区间之间的最基本关系就是包含[encloses(Range)]：如果内区间的边界没有超出外区间的边界，则外区间包含内区间。包含判断的结果完全取决于区间端点的比较 b) 相连[isConnected] Range.isConnected(Range)判断区间是否是相连的。具体来说，isConnected测试是否有区间同时包含于这两个区间，这等同于数学上的定义”两个区间的并集是连续集合的形式”（空区间的特殊情况除外）。 c) 交集[intersection] Range.intersection(Range)返回两个区间的交集：既包含于第一个区间，又包含于另一个区间的最大区间。当且仅当两个区间是相连的，它们才有交集。如果两个区间没有交集，该方法将抛出IllegalArgumentException。 d) 跨区间[span] Range.span(Range)返回”同时包括两个区间的最小区间”，如果两个区间相连，那就是它们的并集。 span是可互换的[commutative] 、关联的[associative] 、闭合的[closed]运算[operation]。 6) 离散域部分（但不是全部）可比较类型是离散的，即区间的上下边界都是可枚举的。 在Guava中，用DiscreteDomain实现类型C的离散形式操作。一个离散域总是代表某种类型值的全集；它不能代表类似”素数”、”长度为5的字符串”或”午夜的时间戳”这样的局部域。 DiscreteDomain提供的离散域实例包括： 类型 离散域 Integer integers() Long longs() 一旦获取了DiscreteDomain实例，你就可以使用下面的Range运算方法： ContiguousSet.create(range, domain)：用ImmutableSortedSet形式表示Range中符合离散域定义的元素，并增加一些额外操作——译者注：实际返回ImmutableSortedSet的子类ContiguousSet。（对无限区间不起作用，除非类型C本身是有限的，比如int就是可枚举的） canonical(domain)：把离散域转为区间的”规范形式”。如果ContiguousSet.create(a, domain).equals(ContiguousSet.create(b,domain))并且!a.isEmpty()，则有a.canonical(domain).equals(b.canonical(domain))。（这并不意味着a.equals(b)） 你可以创建自己的离散域，但必须记住DiscreteDomain契约的几个重要方面。 一个离散域总是代表某种类型值的全集；它不能代表类似”素数”或”长度为5的字符串”这样的局部域。所以举例来说，你无法构造一个DiscreteDomain以表示精确到秒的JODA DateTime日期集合：因为那将无法包含JODA DateTime的所有值。 DiscreteDomain可能是无限的——比如BigInteger DiscreteDomain。这种情况下，你应当用minValue()和maxValue()的默认实现，它们会抛出NoSuchElementException。但Guava禁止把无限区间传入ContiguousSet.create——译者注：那明显得不到一个可枚举的集合。 9. I/O1) Guava Files中的文件操作Java的基本API对文件的操作很繁琐，为了向文件中写入一行文本，都需要写十几行的代码。guava对此作了很多改进，提供了很多方便的操作。 10. 散列（Hash）1) 概述Java内建的散列码[hash code]概念被限制为32位，并且没有分离散列算法和它们所作用的数据，因此很难用备选算法进行替换。此外，使用Java内建方法实现的散列码通常是劣质的，部分是因为它们最终都依赖于JDK类中已有的劣质散列码。 Object.hashCode往往很快，但是在预防碰撞上却很弱，也没有对分散性的预期。这使得它们很适合在散列表中运用，因为额外碰撞只会带来轻微的性能损失，同时差劲的分散性也可以容易地通过再散列来纠正（Java中所有合理的散列表都用了再散列方法）。然而，在简单散列表以外的散列运用中，Object.hashCode几乎总是达不到要求——因此，有了com.google.common.hash包。 2) 散列包的组成在这个包的Java doc中，我们可以看到很多不同的类，但是文档中没有明显地表明它们是怎样一起配合工作的。 a) HashFunction HashFunction是一个单纯的（引用透明的）、无状态的方法，它把任意的数据块映射到固定数目的位置，并且保证相同的输入一定产生相同的输出，不同的输入尽可能产生不同的输出。 b) Hasher HashFunction的实例可以提供有状态的Hasher，Hasher提供了流畅的语法把数据添加到散列运算，然后获取散列值。Hasher可以接受所有原生类型、字节数组、字节数组的片段、字符序列、特定字符集的字符序列等等，或者任何给定了Funnel实现的对象。 Hasher实现了PrimitiveSink接口，这个接口为接受原生类型流的对象定义了fluent风格的API c) Funnel Funnel描述了如何把一个具体的对象类型分解为原生字段值，从而写入PrimitiveSink。 注：putString(“abc”,Charsets.UTF_8).putString(“def”, Charsets.UTF_8)完全等同于putString(“ab”, Charsets.UTF_8).putString(“cdef”,Charsets.UTF_8)，因为它们提供了相同的字节序列。这可能带来预料之外的散列冲突。增加某种形式的分隔符有助于消除散列冲突。 d) HashCode 一旦Hasher被赋予了所有输入，就可以通过hash()方法获取HashCode实例（多次调用hash()方法的结果是不确定的）。HashCode可以通过asInt()、asLong()、asBytes()方法来做相等性检测，此外，writeBytesTo(array, offset, maxLength)把散列值的前maxLength字节写入字节数组。 3) 布鲁姆过滤器[BloomFilter]布鲁姆过滤器是哈希运算的一项优雅运用，它可以简单地基于Object.hashCode()实现。简而言之，布鲁姆过滤器是一种概率数据结构，它允许你检测某个对象是一定不在过滤器中，还是可能已经添加到过滤器了。 Guava散列包有一个内建的布鲁姆过滤器实现，你只要提供Funnel就可以使用它。你可以使用create(Funnel funnel, int expectedInsertions, doublefalsePositiveProbability)方法获取BloomFilter，缺省误检率[falsePositiveProbability]为3%。BloomFilter提供了booleanmightContain(T) 和void put(T)，它们的含义都不言自明了。 4) Hashing类Hashing类提供了若干散列函数，以及运算HashCode对象的工具方法。 已提供的散列函数 md5() murmur3_128() murmur3_32() sha1() sha256() sha512() goodFastHash(int bits) HashCode运算 方法 描述 HashCode combineOrdered( Iterable) 以有序方式联接散列码，如果两个散列集合用该方法联接出的散列码相同，那么散列集合的元素可能是顺序相等的 HashCode combineUnordered( Iterable) 以无序方式联接散列码，如果两个散列集合用该方法联接出的散列码相同，那么散列集合的元素可能在某种排序下是相等的 int consistentHash( HashCode, int buckets) 为给定的”桶”大小返回一致性哈希值。当”桶”增长时，该方法保证最小程度的一致性哈希值变化。详见一致性哈希。 11. 事件总线（EventBus）传统上，Java的进程内事件分发都是通过发布者和订阅者之间的显式注册实现的。设计EventBus就是为了取代这种显示注册方式，使组件间有了更好的解耦。EventBus不是通用型的发布-订阅实现，不适用于进程间通信。 12. 数学运算（Math）13. 反射（Reflection）1) guava反射TypeToken解决泛型运行时类型擦除的问题介绍guava中的TypeToken类解决java 运行时泛型类型擦除问题。 TypeToken的方法列表如下： 方法 描述 getType() 获得包装的java.lang.reflect.Type. getRawType() 返回大家熟知的运行时类 getSubtype(Class&lt;?&gt;) 返回那些有特定原始类的子类型。举个例子，如果这有一个Iterable并且参数是List.class，那么返回将是List。 getSupertype(Class&lt;?&gt;) 产生这个类型的超类，这个超类是指定的原始类型。举个例子，如果这是一个Set并且参数是Iterable.class，结果将会是Iterable。 isAssignableFrom(type) 如果这个类型是 assignable from 指定的类型，并且考虑泛型参数，返回true。List&lt;? extends Number&gt;是assignable from List，但List没有. getTypes() 返回一个Set，包含了这个所有接口，子类和类是这个类型的类。返回的Set同样提供了classes()和interfaces()方法允许你只浏览超类和接口类。 isArray() 检查某个类型是不是数组，甚至是&lt;? extends A[]&gt;。 getComponentType() 返回组件类型数组。 2) guava反射之Invokable使用Guava的Invokable是对java.lang.reflect.Method和java.lang.reflect.Constructor的流式包装。它简化了常见的反射代码的使用。 一些使用例子： a) 方法是否是public的? JDK: Modifier.isPublic(method.getModifiers()); Invokable: invokable.isPublic(); b) 方法是否是package private? JDK: !(Modifier.isPrivate(method.getModifiers())||Modifier.isPublic(method.getModifiers())) Invokable: invokable.isPackagePrivate() c) 方法是否能够被子类重写？ JDK: !(Modifier.isFinal(method.getModifiers()) ||Modifiers.isPrivate(method.getModifiers()) ||Modifiers.isStatic(method.getModifiers()) ||Modifiers.isFinal(method.getDeclaringClass().getModifiers()))Invokable: invokable.isOverridable() d) 方法的第一个参数是否被定义了注解@Nullable？ JDK: for (Annotation annotation : method.getParameterAnnotations[0]) { ​ if (annotation instanceof Nullable) { ​ return true; ​ } } return false; Invokable: invokable.getParameters().get(0).isAnnotationPresent(Nullable.class) e) 构造函数和工厂方法如何共享同样的代码？ 你是否很想重复自己，因为你的反射代码需要以相同的方式工作在构造函数和工厂方法中？ Invokable提供了一个抽象的概念。下面的代码适合任何一种方法或构造函数： invokable.isPublic(); invokable.getParameters(); invokable.invoke(object,args); List的List.get(int)返回类型是什么？ Invokable提供了与众不同的类型解决方案： Invokable&lt;List,?&gt; invokable = new TypeToken&lt;List&gt;() {}.method(getMethod); invokable.getReturnType();// String.class 3) guava反射：Reflection.newProxy方法简化动态代理原理上GoogleGuava的动态代理也是使用JDK的动态代理，这是做了封装，更加简便。另外一点是能够很好的检查需要代理的对象必须拥有接口。使用Class`类的isInterface()`来做检查。 14. 注解（Annotations）com.google.common.annotations包下注解类的含义和用法： 1) Beta/** 表明一个公用API的未来版本是受不兼容变更或删除限制的 拥有这个注释标志的API不受任何兼容性保证 * */ @Retention(RetentionPolicy.CLASS) @Target({ ​ ElementType.ANNOTATION_TYPE, ​ ElementType.CONSTRUCTOR, ​ ElementType.FIELD, ​ ElementType.METHOD, ​ ElementType.TYPE}) @Documented @GwtCompatible public@interface Beta {} 2) GwtCompatible/** 表明一个类型可能会与 Google WebToolkit 一起使用. 如果一个方法使用这个注释,说明这个方法的返回值是GWT 兼容的 * */ @Retention(RetentionPolicy.CLASS) @Target({ElementType.TYPE, ElementType.METHOD }) @Documented @GwtCompatible public@interface GwtCompatible { ​ /** ​ * 说明一个类型或者方法的返回值是否支持GWT 序列化 ​ * ​ */ ​ boolean serializable() default false; ​ /** ​ * 说明一个类型是否在 GWT 被模拟. ​ * 被模拟的源(父源)和JVM的实现不一样 ​ * ​ */ ​ boolean emulated() default false; } 3) GwtIncompatible/** 说明一个方法可能无法与 GWT 一起使用 他只能用于被 @GwtCompatible标志的类的字段,方法和内部类 * */ @Retention(RetentionPolicy.CLASS) @Target({ ​ ElementType.TYPE, ElementType.METHOD, ​ ElementType.CONSTRUCTOR,ElementType.FIELD }) @Documented @GwtCompatible public@interface GwtIncompatible { ​ /** ​ * 用于表示不兼容 GWT 的原因 ​ * ​ */ ​ String value(); } 4) VisibleForTesting/** *注释程序元素的存在,或比其他必要广泛可见,仅用于测试代码。 */ @GwtCompatible public@interface VisibleForTesting { } 15. 网络编程（Net）guava中的net包目前提供的功能较少，而且大多类都标注了@Beta的注解，在guava中标记Beta注解表示这个类还不稳定，有可能在以后的版本中变化，或者去掉，所以不建议大量使用，这里也是只做简单的介绍。 先介绍下唯一一个没有Beta注解的类HttpHeaders，这个类中并没有实质的方法，只是定义了一些Http头名称的常量，通常如果需要我们会自己定义这些常量，如果你引用了guava包，那么就不再建议我们自己定义这些头名称的常量了，直接用它定义的即可。 这里面应该有几乎所有的Http头名称，例如：X_FORWARDED_FOR，UPGRADE，REFERER等等。用法也没有必要介绍了，直接引用常量就可以了。 再介绍下一个比较常用的小功能，有时候我们需要在配置文件中配置IP+端口，这时候需要自己写解析ip，端口的方法，guava为我们提供了解析类，我们看下用法实例： HostAndPort hostAndPort =HostAndPort.fromString(“127.0.0.1:8080”); System.out.println(“host== “ + hostAndPort.getHostText()); System.out.println(“port== “ + hostAndPort.getPortOrDefault(80)); HostAndPort类的静态方法fromString(String)可以解析出字符串中定义的Host和端口信息。 另外guava包中还提供了InetAddresses类，这个类是InetAddress的帮助类，通过这个类可以方便的从字符串中解析出InetAddress类。但是此类也有@Beta的注解，所以要谨慎使用。 参考资料：http://ifeve.com/google-guava/ https://code.google.com/p/guava-libraries/]]></content>
  </entry>
  <entry>
    <title><![CDATA[Java中的String，StringBuilder，StringBuffer三者的区别]]></title>
    <url>%2F2018%2F04%2F21%2FJava%E4%B8%AD%E7%9A%84String%EF%BC%8CStringBuilder%EF%BC%8CStringBuffer%E4%B8%89%E8%80%85%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[这三个类之间的区别主要是在两个方面，即运行速度和线程安全这两方面。 首先说运行速度，或者说是执行速度，在这方面运行速度快慢为：StringBuilder &gt; StringBuffer &gt; String String最慢的原因： String为字符串常量，而StringBuilder和StringBuffer均为字符串变量，即String对象一旦创建之后该对象是不可更改的，但后两者的对象是变量，是可以更改的。以下面一段代码为例： 12341 String str=&quot;abc&quot;;2 System.out.println(str);3 str=str+&quot;de&quot;;4 System.out.println(str); 如果运行这段代码会发现先输出“abc”，然后又输出“abcde”，好像是str这个对象被更改了，其实，这只是一种假象罢了，JVM对于这几行代码是这样处理的，首先创建一个String对象str，并把“abc”赋值给str，然后在第三行中，其实JVM又创建了一个新的对象也名为str，然后再把原来的str的值和“de”加起来再赋值给新的str，而原来的str就会被JVM的垃圾回收机制（GC）给回收掉了，所以，str实际上并没有被更改，也就是前面说的String对象一旦创建之后就不可更改了。所以，Java中对String对象进行的操作实际上是一个不断创建新的对象并且将旧的对象回收的一个过程，所以执行速度很慢。 而StringBuilder和StringBuffer的对象是变量，对变量进行操作就是直接对该对象进行更改，而不进行创建和回收的操作，所以速度要比String快很多。 另外，有时候我们会这样对字符串进行赋值 12341 String str=&quot;abc&quot;+&quot;de&quot;;2 StringBuilder stringBuilder=new StringBuilder().append(&quot;abc&quot;).append(&quot;de&quot;);3 System.out.println(str);4 System.out.println(stringBuilder.toString()); 这样输出结果也是“abcde”和“abcde”，但是String的速度却比StringBuilder的反应速度要快很多，这是因为第1行中的操作和 String str=”abcde”; 是完全一样的，所以会很快，而如果写成下面这种形式 1231 String str1=&quot;abc&quot;;2 String str2=&quot;de&quot;;3 String str=str1+str2; 那么JVM就会像上面说的那样，不断的创建、回收对象来进行这个操作了。速度就会很慢。 2. 再来说线程安全 在线程安全上，StringBuilder是线程不安全的，而StringBuffer是线程安全的 如果一个StringBuffer对象在字符串缓冲区被多个线程使用时，StringBuffer中很多方法可以带有synchronized关键字，所以可以保证线程是安全的，但StringBuilder的方法则没有该关键字，所以不能保证线程安全，有可能会出现一些错误的操作。所以如果要进行的操作是多线程的，那么就要使用StringBuffer，但是在单线程的情况下，还是建议使用速度比较快的StringBuilder。 3. 总结一下 String：适用于少量的字符串操作的情况 StringBuilder：适用于单线程下在字符缓冲区进行大量操作的情况 StringBuffer：适用多线程下在字符缓冲区进行大量操作的情况]]></content>
  </entry>
  <entry>
    <title><![CDATA[springmvc 一些最佳实践]]></title>
    <url>%2F2018%2F04%2F21%2Fspringmvc-%E4%B8%80%E4%BA%9B%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[1. 使用WebDataBinder来做参数的个性化绑定通常情况下，框架可以很好的处理前端传递k1=v2&amp;k2=v2形式的POST data和GET请求参数，并将其转换、映射为Controller里method的args[]类型，但是在某些情况下，我们有很多自定义的需求，例如 对于字符串yyyyMMDD转换为Date对象，这时候自定义DataBinder就非常有用了，在上面源码剖析的第（4）点介绍过。 一个更加trick的需求是，前端传递两种cases的urls参数： urls= http://c.admaster.com.cn/c/a25774,b200663567,c3353,i0,m101,h&amp;urls=http://www.baidu.com urls= http://c.admaster.com.cn/c/a25774,b200663567,c3353,i0,m101,h 对于第一种，后端接收到的urls.size()=2，符合预期，而对于第二种，后端接收的urls.size()=5,不是预期的 urls.size()=1，原因就是SpringMVC进行参数映射绑定时，默认会自动把按照逗号分隔的参数映射成数组或者list的元素。对这个问 题，同样可以使用WebDataBinder解决，解决代码如下，只需要在Controller里加入一个@InitBinder修饰的方法，去在 binder里面加入自定义的参数解析方法即可。 1234567891011121314151617181920212223242526272829303132@RequestMapping(value = &quot;/getUrls&quot;, method = RequestMethod.GET)@ResponseBodypublic JsonObject&lt;?&gt; getUrls(@RequestParam(value = &quot;urls&quot;) List urls) &#123; JsonObject&lt;?&gt; result = JsonObject.create(); System.out.println(urls); result.addData(&quot;urls&quot;, urls); return result;&#125; @InitBinderpublic void dataBinder(WebDataBinder binder) &#123; PropertyEditor urlEditor = new PropertyEditorSupport() &#123; @Override public void setValue(Object value) throws IllegalArgumentException &#123; if (value instanceof List) &#123; super.setValue(value); &#125; else if (value.getClass().isArray() &amp;&amp; value instanceof String[]) &#123; super.setValue(Lists.newArrayList((String[]) value)); &#125; &#125; @Override public void setAsText(String text) throws java.lang.IllegalArgumentException &#123; if (text instanceof String) &#123; setValue(Lists.newArrayList(text)); return; &#125; throw new IllegalArgumentException(text); &#125; &#125;; binder.registerCustomEditor(List.class, urlEditor);&#125; 2. 使用高级的HandlerMethodArgumentResolver来实现参数的个性化解析通常情况下，对于参数key的解析、映射，框架会帮助我们完成到对象的绑定，但是在某些遗留系统中，前端传递的参数与后端Form表单定义的命名 不会相同，例如在某些系统中参数为qp.page=1&amp;qp.pageSize=50，而后端的Form表单类属性命名不可能带有点号，这时候我 们可以自定义一个ArgumentResolver来自己设置参数对象。 例如，我们的query方法签名如下，QueryParamForm中的属性名称为page、pageSize： 123@RequestMapping(&quot;/dtList&quot;)@ResponseBodypublic JsonObject&lt;genderviewitem&gt; query(@Qp QueryParamForm form) &#123; ResultBundle&lt;genderviewitem&gt; res = reportService.queryGenderReport(toQP(form)); return toResponse(res, form); &#125;&lt;/genderviewitem&gt;&lt;/genderviewitem&gt; Qp是一个注解： 12345@Target(ElementType.PARAMETER)@Retention(RetentionPolicy.RUNTIME)@Documentedpublic @interface Qp &#123;&#125; 在handlerAdapter中自定义customArgumentResolvers： 12345678&lt;bean id=&quot;handlerAdapter&quot;class=&quot;org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter&quot;&gt; &lt;property name=&quot;customArgumentResolvers&quot;&gt; &lt;util:list&gt; &lt;ref bean=&quot;reportArgumentResolver&quot; /&gt; &lt;/util:list&gt; &lt;/property&gt;&lt;/bean&gt; ArgumentResolver的实现如下，只需要覆盖两个方法即可，在上面源码剖析（4）中介绍过对于参数的解析介绍过。在这里省略了 QueryParamFormBuilder类，这个类主要就是去webRequest中主动取”qp.page”与”qp.pageSize”参数的 值，利用反射去动态的set到一个空QueryParamForm对象的属性中。 123456789101112131415161718192021@Componentpublic class ReportArgumentResolver implements HandlerMethodArgumentResolver &#123; @Resource private QueryParamFormBuilder formBuilder; @Override public boolean supportsParameter(MethodParameter parameter) &#123; return parameter.hasParameterAnnotation(Qp.class); &#125; @Override public Object resolveArgument(MethodParameter parameter, ModelAndViewContainer mavContainer, NativeWebRequest webRequest, WebDataBinderFactory binderFactory) throws Exception &#123; if (parameter.getParameterType() == QueryParamForm.class) &#123; return formBuilder.buildForm(webRequest); &#125; return WebArgumentResolver.UNRESOLVED; &#125; &#125; 3. 使用aspectj拦截器以上面那个例子为背景，如果要做全局的参数校验，没必要在每个方法中主动写方法，可以利用AspectJ与Spring的集成，编入指定类到方法上的AOP切面，统一来做验证。详细代码如下： 1234567891011121314151617181920212223242526@Component@Aspectpublic class ReportQueryParamInterceptor &#123; private static final Logger LOG = LoggerFactory.getLogger(ReportQueryParamInterceptor.class); @Around(&quot;execution(* com.baidu.beidou.ui.web.portal.report.controller.*ReportController.query*(..))&quot;) public Object validate4Query(ProceedingJoinPoint pjp) throws Throwable &#123; MethodSignature methodSignature = getMethodSignature(pjp); Object[] args = pjp.getArgs(); if (args == null || args.length &lt; 1 || !(args[0] instanceof QueryParamForm)) &#123; LOG.warn(&quot;Request param is null or not instanceof QueryParamForm! &quot; + args); throw new IllegalArgumentException(&quot;Request param error which should not happen!&quot;); &#125; QueryParamForm form = (QueryParamForm) args[0]; JsonObject response = (JsonObject) (methodSignature.getReturnType().newInstance()); validateAndPrepareQueryParamForm(response, form); if (response.getStatus() != GlobalResponseStatusMsg.OK.getCode()) &#123; return response; &#125; return pjp.proceed(); &#125;&#125; 4. 全局错误处理，隐藏后端异常以及友好提示通常情况下，一个web系统，不应该像外部暴露过多的内部异常细节，那么我们可以覆盖掉SpringMVC提供的默认异常处理handler，定 义自己的GlobalExceptionHandler，这里面为了覆盖掉默认的handler，需要实现Ordered，并且赋值order为 Ordered.HIGHEST_PRECEDENCE。 在配置文件中使用自己的handler。 123&lt;bean id=&quot;exceptionHandler&quot;class=&quot;com.baidu.beidou.ui.web.common.handler.GlobalExceptionHandler&quot;&gt;&lt;/bean&gt; resolveException(..)方法内，可以针对各种异常信息，去返回给前端不同的信息，包括错误返回码等等。 1234567891011121314151617181920212223242526272829303132333435363738public class GlobalExceptionHandler implements HandlerExceptionResolver, ApplicationContextAware, Ordered &#123; protected ApplicationContext context; /** * 默认HandlerExceptionResolver优先级，设置为最高，用于覆盖系统默认的异常处理器 */ private int order = Ordered.HIGHEST_PRECEDENCE; @Override public ModelAndView resolveException(HttpServletRequest request, HttpServletResponse response, Object o, Exception e) &#123; ModelAndView model = new ModelAndView(new MappingJacksonJsonView()); try &#123; if (e instanceof TypeMismatchException) &#123; LOG.warn(&quot;TypeMismatchException occurred. &quot; + e.getMessage()); return buildBizErrors((TypeMismatchException) e, model); &#125; else if (e instanceof BindException) &#123; LOG.warn(&quot;BindException occurred. &quot; + e.getMessage()); return buildBizErrors((BindException) e, model); &#125; else if (e instanceof HttpRequestMethodNotSupportedException) &#123; LOG.warn(&quot;HttpRequestMethodNotSupportedException occurred. &quot; + e.getMessage()); return buildError(model, GlobalResponseStatusMsg.REQUEST_HTTP_METHOD_ERROR); &#125; else if (e instanceof MissingServletRequestParameterException) &#123; LOG.warn(&quot;MissingServletRequestParameterException occurred. &quot; + e.getMessage()); return buildError(model, GlobalResponseStatusMsg.PARAM_MISS_ERROR); &#125; else &#123; LOG.error(&quot;System error occurred. &quot; + e.getMessage(), e); return buildError(model, GlobalResponseStatusMsg.SYSTEM_ERROR); &#125; &#125; catch (Exception ex) &#123; // Omit all detailed error message including stack trace to external user LOG.error(&quot;Unexpected error occurred! This should never happen! &quot; + ex.getMessage(), ex); model.addObject(&quot;status&quot;, SYS_ERROR_CODE); model.addObject(&quot;msg&quot;, SYS_ERROR_MSG); return model; &#125; &#125;&#125; 5. Spring自带拦截器拦截器最常见的使用场景就是日志、登陆、权限验证等。下面以权限验证为例，一般情况下，登陆的用户会有不同的访问权限，对于controller里定义的方法进行有限制的调用，为了更好的解耦，可以定义一个公共的拦截器。 12345678910111213141516171819202122232425262728293031public class PriviledgeInterceptor implements HandlerInterceptor &#123; @Override boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; // 获取线程上下文的visitor Visitor visitor = ThreadContext.getSessionVisitor(); Preconditions.checkNotNull(visitor, &quot;Visitor should NOT be null in ThreadContext!&quot;); // 获取权限集合 Set authSet = visitor.getAuths(); if (CollectionUtils.isEmpty(authSet)) &#123; LOG.error(&quot;Visitor does NOT get any auths, userid=&quot; + visitor.getUserid()); returnJsonSystemError(request, response, GlobalResponseStatusMsg.AUTH_DENIED); return false; &#125; // 结合controller里定义方法的注解来做验证 HandlerMethod handlerMethod = (HandlerMethod) handler; Privilege privilege = handlerMethod.getMethodAnnotation(Privilege.class); if (privilege != null) &#123; if (authSet.contains(privilege.value())) &#123; return true; &#125; LOG.error(&quot;Visitor does NOT have auth=&#123;&#125; on controller=&#123;&#125;, userid=&#123;&#125;&quot;, new Object[] &#123; privilege.value(), getBeanTypeAndMethodName(handlerMethod), visitor.getUserid() &#125;); returnJsonSystemError(request, response, GlobalResponseStatusMsg.AUTH_DENIED); return false; &#125; &#125;&#125; controller定义如下： 12345@Controller@RequestMapping(&quot;/test&quot;)@Privilege(PriviledgeConstant.BEIDOU_CPROUNIT)public class SiConfController &#123;&#125; 6. 使用模板方法来简化代码开发对于很多的相似逻辑，可以利用模板模式，把公共的操作封装到父类controller中。例如对于一个下载报表的需求，可以隐藏具体的写流等底层 操作，将这些模板抽象化到父类BaseController中，子类只需要去实现传入一个调用获取报表数据Callback来，这和Hibernate的 callback思想异曲同工。 123456789@RequestMapping(value = &quot;/downloadDtList&quot;)@ResponseBodypublic HttpEntity&lt;byte[]&gt; download(@RequestParam(value = PortalReportConstants.DOWNLOAD_POST_PARAM, required = true) String iframePostParams) &#123; return toHttpEntity(new ReportCallback&lt;ResultBundle&lt;?&gt;&gt;() &#123; public ResultBundle&lt;GenderViewItem&gt; call(QueryParamForm form) &#123; return reportService.queryGenderReport(toQP(form)); &#125; &#125;);&#125; 转载于https://www.cnblogs.com/prefect/p/5664589.html]]></content>
  </entry>
  <entry>
    <title><![CDATA[springMVC请求流程详解]]></title>
    <url>%2F2018%2F04%2F21%2FspringMVC%E8%AF%B7%E6%B1%82%E6%B5%81%E7%A8%8B%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[SpringMVC框架是一个基于请求驱动的Web框架，并且使用了‘前端控制器’模型来进行设计，再根据‘请求映射规则’分发给相应的页面控制器进行处理。 （一）整体流程 具体步骤： 1、 首先用户发送请求到前端控制器，前端控制器根据请求信息（如 URL）来决定选择哪一个页面控制器进行处理并把请求委托给它，即以前的控制器的控制逻辑部分；图中的 1、2 步骤； 2、 页面控制器接收到请求后，进行功能处理，首先需要收集和绑定请求参数到一个对象，这个对象在 Spring Web MVC 中叫命令对象，并进行验证，然后将命令对象委托给业务对象进行处理；处理完毕后返回一个 ModelAndView（模型数据和逻辑视图名）；图中的 3、4、5 步骤； 3、 前端控制器收回控制权，然后根据返回的逻辑视图名，选择相应的视图进行渲染，并把模型数据传入以便视图渲染；图中的步骤 6、7； 4、 前端控制器再次收回控制权，将响应返回给用户，图中的步骤 8；至此整个结束。 （二）核心流程 具体步骤： 第一步：发起请求到前端控制器(DispatcherServlet) 第二步：前端控制器请求HandlerMapping查找 Handler （可以根据xml配置、注解进行查找） 第三步：处理器映射器HandlerMapping向前端控制器返回Handler，HandlerMapping会把请求映射为HandlerExecutionChain对象（包含一个Handler处理器（页面控制器）对象，多个HandlerInterceptor拦截器对象），通过这种策略模式，很容易添加新的映射策略 第四步：前端控制器调用处理器适配器去执行Handler 第五步：处理器适配器HandlerAdapter将会根据适配的结果去执行Handler 第六步：Handler执行完成给适配器返回ModelAndView 第七步：处理器适配器向前端控制器返回ModelAndView （ModelAndView是springmvc框架的一个底层对象，包括 Model和view） 第八步：前端控制器请求视图解析器去进行视图解析 （根据逻辑视图名解析成真正的视图(jsp)），通过这种策略很容易更换其他视图技术，只需要更改视图解析器即可 第九步：视图解析器向前端控制器返回View 第十步：前端控制器进行视图渲染 （视图渲染将模型数据(在ModelAndView对象中)填充到request域） 第十一步：前端控制器向用户响应结果 （三）总结 核心开发步骤1、 DispatcherServlet 在 web.xml 中的部署描述，从而拦截请求到 Spring Web MVC 2、 HandlerMapping 的配置，从而将请求映射到处理器 3、 HandlerAdapter 的配置，从而支持多种类型的处理器 注：处理器映射求和适配器使用纾解的话包含在了注解驱动中，不需要在单独配置 4、 ViewResolver 的配置，从而将逻辑视图名解析为具体视图技术 5、 处理器（页面控制器）的配置，从而进行功能处理 View是一个接口，实现类支持不同的View类型（jsp、freemarker、pdf…） 转载于：https://www.cnblogs.com/leskang/p/6101368.html]]></content>
  </entry>
  <entry>
    <title><![CDATA[fail-fast机制]]></title>
    <url>%2F2018%2F04%2F21%2Ffail-fast%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[“快速失败”也就是fail-fast，它是Java集合的一种错误检测机制。当多个线程对集合进行结构上的改变的操作时，有可能会产生fail-fast机制。记住是有可能，而不是一定。例如：假设存在两个线程（线程1、线程2），线程1通过Iterator在遍历集合A中的元素，在某个时候线程2修改了集合A的结构（是结构上面的修改，而不是简单的修改集合元素的内容），那么这个时候程序就会抛出 ConcurrentModificationException 异常，从而产生fail-fast机制。 一、fail-fast示例 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class FailFastTest &#123; private static List&lt;Integer&gt; list = new ArrayList&lt;&gt;(); /** * @desc:线程one迭代list * @Project:test * @file:FailFastTest.java * @Authro:chenssy * @data:2014年7月26日 */ private static class threadOne extends Thread&#123; public void run() &#123; Iterator&lt;Integer&gt; iterator = list.iterator(); while(iterator.hasNext())&#123; int i = iterator.next(); System.out.println(&quot;ThreadOne 遍历:&quot; + i); try &#123; Thread.sleep(10); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; /** * @desc:当i == 3时，修改list * @Project:test * @file:FailFastTest.java * @Authro:chenssy * @data:2014年7月26日 */ private static class threadTwo extends Thread&#123; public void run()&#123; int i = 0 ; while(i &lt; 6)&#123; System.out.println(&quot;ThreadTwo run：&quot; + i); if(i == 3)&#123; list.remove(i); &#125; i++; &#125; &#125; &#125; public static void main(String[] args) &#123; for(int i = 0 ; i &lt; 10;i++)&#123; list.add(i); &#125; new threadOne().start(); new threadTwo().start(); &#125; &#125; ​ 运行结果： 12345678910ThreadTwo run：0 ThreadTwo run：1 ThreadTwo run：2 ThreadTwo run：3 ThreadTwo run：4 ThreadTwo run：5 Exception in thread &quot;Thread-0&quot; java.util.ConcurrentModificationException at java.util.ArrayList$Itr.checkForComodification(Unknown Source) at java.util.ArrayList$Itr.next(Unknown Source) at test.ArrayListTest$threadOne.run(ArrayListTest.java:23) 二、fail-fast产生原因​ 通过上面的示例和讲解，我初步知道fail-fast产生的原因就在于程序在对 collection 进行迭代时，某个线程对该 collection 在结构上对其做了修改，这时迭代器就会抛出 ConcurrentModificationException 异常信息，从而产生 fail-fast。 ​ 要了解fail-fast机制，我们首先要对ConcurrentModificationException 异常有所了解。当方法检测到对象的并发修改，但不允许这种修改时就抛出该异常。同时需要注意的是，该异常不会始终指出对象已经由不同线程并发修改，如果单线程违反了规则，同样也有可能会抛出改异常。 ​ 诚然，迭代器的快速失败行为无法得到保证，它不能保证一定会出现该错误，但是快速失败操作会尽最大努力抛出ConcurrentModificationException异常，所以因此，为提高此类操作的正确性而编写一个依赖于此异常的程序是错误的做法，正确做法是：ConcurrentModificationException 应该仅用于检测 bug。下面我将以ArrayList为例进一步分析fail-fast产生的原因。 从前面我们知道fail-fast是在操作迭代器时产生的。现在我们来看看ArrayList中迭代器的源代码： 123456789101112131415161718192021222324252627private class Itr implements Iterator&lt;E&gt; &#123; int cursor; int lastRet = -1; int expectedModCount = ArrayList.this.modCount; public boolean hasNext() &#123; return (this.cursor != ArrayList.this.size); &#125; public E next() &#123; checkForComodification(); /** 省略此处代码 */ &#125; public void remove() &#123; if (this.lastRet &lt; 0) throw new IllegalStateException(); checkForComodification(); /** 省略此处代码 */ &#125; final void checkForComodification() &#123; if (ArrayList.this.modCount == this.expectedModCount) return; throw new ConcurrentModificationException(); &#125; &#125; ​ 从上面的源代码我们可以看出，迭代器在调用next()、remove()方法时都是调用checkForComodification()方法，该方法主要就是检测modCount == expectedModCount ? 若不等则抛出ConcurrentModificationException 异常，从而产生fail-fast机制。所以要弄清楚为什么会产生fail-fast机制我们就必须要用弄明白为什么modCount != expectedModCount ，他们的值在什么时候发生改变的。 ​ expectedModCount 是在Itr中定义的：int expectedModCount = ArrayList.this.modCount;所以他的值是不可能会修改的，所以会变的就是modCount。modCount是在 AbstractList 中定义的，为全局变量： protected transient int modCount = 0; 那么他什么时候因为什么原因而发生改变呢？请看ArrayList的源码： [java] view plaincopyprint? 1234public boolean add(E paramE) &#123; ensureCapacityInternal(this.size + 1); /** 省略此处代码 */ &#125; 123456789101112131415161718192021222324252627282930313233343536373839private void ensureCapacityInternal(int paramInt) &#123; if (this.elementData == EMPTY_ELEMENTDATA) paramInt = Math.max(10, paramInt); ensureExplicitCapacity(paramInt); &#125; private void ensureExplicitCapacity(int paramInt) &#123; this.modCount += 1; //修改modCount /** 省略此处代码 */ &#125; ublic boolean remove(Object paramObject) &#123; int i; if (paramObject == null) for (i = 0; i &lt; this.size; ++i) &#123; if (this.elementData[i] != null) continue; fastRemove(i); return true; &#125; else for (i = 0; i &lt; this.size; ++i) &#123; if (!(paramObject.equals(this.elementData[i]))) continue; fastRemove(i); return true; &#125; return false; &#125; private void fastRemove(int paramInt) &#123; this.modCount += 1; //修改modCount /** 省略此处代码 */ &#125; public void clear() &#123; this.modCount += 1; //修改modCount /** 省略此处代码 */ &#125; ​ 从上面的源代码我们可以看出，ArrayList中无论add、remove、clear方法只要是涉及了改变ArrayList元素的个数的方法都会导致modCount的改变。所以我们这里可以初步判断由于expectedModCount 得值与modCount的改变不同步，导致两者之间不等从而产生fail-fast机制。知道产生fail-fast产生的根本原因了，我们可以有如下场景： ​ 有两个线程（线程A，线程B），其中线程A负责遍历list、线程B修改list。线程A在遍历list过程的某个时候（此时expectedModCount = modCount=N），线程启动，同时线程B增加一个元素，这是modCount的值发生改变（modCount + 1 = N + 1）。线程A继续遍历执行next方法时，通告checkForComodification方法发现expectedModCount = N ，而modCount = N + 1，两者不等，这时就抛出ConcurrentModificationException 异常，从而产生fail-fast机制。 ​ 所以，直到这里我们已经完全了解了fail-fast产生的根本原因了。知道了原因就好找解决办法了。 三、fail-fast解决办法​ 通过前面的实例、源码分析，我想各位已经基本了解了fail-fast的机制，下面我就产生的原因提出解决方案。这里有两种解决方案： ​ 方案一：在遍历过程中所有涉及到改变modCount值得地方全部加上synchronized或者直接使用Collections.synchronizedList，这样就可以解决。但是不推荐，因为增删造成的同步锁可能会阻塞遍历操作。 ​ 方案二：使用CopyOnWriteArrayList来替换ArrayList。推荐使用该方案。 ​ CopyOnWriteArrayList为何物？ArrayList 的一个线程安全的变体，其中所有可变操作（add、set 等等）都是通过对底层数组进行一次新的复制来实现的。 该类产生的开销比较大，但是在两种情况下，它非常适合使用。1：在不能或不想进行同步遍历，但又需要从并发线程中排除冲突时。2：当遍历操作的数量大大超过可变操作的数量时。遇到这两种情况使用CopyOnWriteArrayList来替代ArrayList再适合不过了。那么为什么CopyOnWriterArrayList可以替代ArrayList呢？ ​ 第一、CopyOnWriterArrayList的无论是从数据结构、定义都和ArrayList一样。它和ArrayList一样，同样是实现List接口，底层使用数组实现。在方法上也包含add、remove、clear、iterator等方法。 ​ 第二、CopyOnWriterArrayList根本就不会产生ConcurrentModificationException异常，也就是它使用迭代器完全不会产生fail-fast机制。请看： [java] view plaincopyprint? 1234567891011121314151617181920212223242526272829303132private static class COWIterator&lt;E&gt; implements ListIterator&lt;E&gt; &#123; /** 省略此处代码 */ public E next() &#123; if (!(hasNext())) throw new NoSuchElementException(); return this.snapshot[(this.cursor++)]; &#125; /** 省略此处代码 */ &#125; CopyOnWriterArrayList的方法根本就没有像ArrayList中使用checkForComodification方法来判断expectedModCount 与 modCount 是否相等。它为什么会这么做，凭什么可以这么做呢？我们以add方法为例：[java] view plaincopyprint?public boolean add(E paramE) &#123; ReentrantLock localReentrantLock = this.lock; localReentrantLock.lock(); try &#123; Object[] arrayOfObject1 = getArray(); int i = arrayOfObject1.length; Object[] arrayOfObject2 = Arrays.copyOf(arrayOfObject1, i + 1); arrayOfObject2[i] = paramE; setArray(arrayOfObject2); int j = 1; return j; &#125; finally &#123; localReentrantLock.unlock(); &#125; &#125; final void setArray(Object[] paramArrayOfObject) &#123; this.array = paramArrayOfObject; &#125; [java] view plaincopyprint? 123Object[] arrayOfObject2 = Arrays.copyOf(arrayOfObject1, i + 1); arrayOfObject2[i] = paramE; setArray(arrayOfObject2); ​ 就是这三句代码使得CopyOnWriterArrayList不会抛ConcurrentModificationException异常。他们所展现的魅力就在于copy原来的array，再在copy数组上进行add操作，这样做就完全不会影响COWIterator中的array了。 ​ 所以CopyOnWriterArrayList所代表的核心概念就是：任何对array在结构上有所改变的操作（add、remove、clear等），CopyOnWriterArrayList都会copy现有的数据，再在copy的数据上修改，这样就不会影响COWIterator中的数据了，修改完成之后改变原有数据的引用即可。同时这样造成的代价就是产生大量的对象，同时数组的copy也是相当有损耗的。 转载于 https://my.oschina.net/elain/blog/383814]]></content>
  </entry>
  <entry>
    <title><![CDATA[Netty--ChannelHandler,ChannelHandlerContext,ChannelPipeline]]></title>
    <url>%2F2018%2F04%2F19%2FNetty-ChannelHandler-ChannelHandlerContext-ChannelPipeline%2F</url>
    <content type="text"><![CDATA[首先先分析一下ChannelHandler，ChannelHandler是我们日常开发中使用最多的组件了，大概我们平时写的最多的组件就是Handler了，继承图如下 我们平时继承的最多的就是ChannelInboundHandlerAdapter和ChannelOutboundHandlerAdapter,这两个不是接口也不是抽象类，所以我们可以仅仅重写我们需要的方法，没有必须要实现的方法，当然我们也会使用SimpleChannelInboundHandler，这个类我们上个小节也稍微讲了它的优缺点，这里不赘述 ChannelHandler,ChannelHandlerContext,ChannelPipeline这三者的关系很特别，相辅相成，一个ChannelPipeline中可以有多个ChannelHandler实例，而每一个ChannelHandler实例与ChannelPipeline之间的桥梁就是ChannelHandlerContext实例，如图所示： 看图就知道，ChannelHandlerContext的重要性了，如果你获取到了ChannelHandlerContext的实例的话，你可以获取到你想要的一切，你可以根据ChannelHandlerContext执行ChannelHandler中的方法，我们举个例子来说，我们可以看下ChannelHandlerContext部分API: 这几个API都是使用比较频繁的，都是调用当前handler之后同一类型的channel中的某个方法，这里的同一类型指的是同一个方向，比如inbound调用inbound，outbound调用outbound类型的channel，一般来说，都是一个channel的ChannnelActive方法中调用fireChannelActive来触发调用下一个handler中的ChannelActive方法 我们举例来说，我们修改Helloworld版中的部分代码，在客户端中的channel中修改一下代码 首先我们修改一下bootstrap的启动类代码： [html] view plain copy try { ​ Bootstrap b = new Bootstrap(); ​ b.group(group) ​ .channel(NioSocketChannel.class) ​ .option(ChannelOption.TCP_NODELAY, true) ​ .handler(new ChannelInitializer() { ​ @Override ​ public void initChannel(SocketChannel ch) throws Exception { ​ ChannelPipeline p = ch.pipeline(); ​ p.addLast(“decoder”, new StringDecoder()); ​ p.addLast(“encoder”, new StringEncoder()); ​ p.addLast(new BaseClient1Handler()); ​ p.addLast(new BaseClient2Handler()); ​ } ​ }); ​ ChannelFuture future = b.connect(HOST, PORT).sync(); ​ future.channel().writeAndFlush(“Hello Netty Server ,I am a common client”); ​ future.channel().closeFuture().sync(); ​ } finally { ​ group.shutdownGracefully(); ​ } 我们在channelhandler链中加了两个自定义的BaseClient1Handler和BaseClient2Handler的处理器 BaseClient1Handler的方法也很简单： BaseClient1Handler.java [java] view plain copy package com.lyncc.netty.component.channelhandler; import io.netty.channel.ChannelHandlerContext; import io.netty.channel.ChannelInboundHandlerAdapter; /** @author bazingaLyncc 描述：客户端的第一个自定义的inbound处理器 时间 2016年5月3日 */ public class BaseClient1Handler extends ChannelInboundHandlerAdapter{ ​ ​ @Override ​ public void channelActive(ChannelHandlerContext ctx) throws Exception { ​ System.out.println(“BaseClient1Handler channelActive”); // ctx.fireChannelActive(); ​ } ​ ​ @Override ​ public void channelInactive(ChannelHandlerContext ctx) throws Exception { ​ System.out.println(“BaseClient1Handler channelInactive”); ​ } } BaseClient2Handler.java [java] view plain copy package com.lyncc.netty.component.channelhandler; import io.netty.channel.ChannelHandlerContext; import io.netty.channel.ChannelInboundHandlerAdapter; /** @author bazingaLyncc 描述：客户端的第二个自定义的inbound处理器 时间 2016年5月3日 */ public class BaseClient2Handler extends ChannelInboundHandlerAdapter{ ​ ​ @Override ​ public void channelActive(ChannelHandlerContext ctx) throws Exception { ​ System.out.println(“BaseClient2Handler Active”); ​ } ​ ​ } 其他的代码不修改的，我们先启动服务器端，然后启动客户端，你会发现控制台打印了： 不会打印BaseClient2Handler类中channelActive方法中的输出语句，如果你想要打印，你可以将BaseClient1Handler中的channelActive的ctx.fireChannelActive()注释去掉。重新运行： 也就是说如果一个channelPipeline中有多个channelHandler时，且这些channelHandler中有同样的方法时，例如这里的channelActive方法，只会调用处在第一个的channelHandler中的channelActive方法，如果你想要调用后续的channelHandler的同名的方法就需要调用以“fire”为开头的方法了，这样做很灵活 目前来说这样做的好处： 1）每一个handler只需要关注自己要处理的方法，如果你不关注channelActive方法时，你自定义的channelhandler就不需要重写channelActive方法 2）异常处理，如果 exceptionCaught方法每个handler都重写了，只需有一个类捕捉到然后做处理就可以了，不需要每个handler都处理一遍 3）灵活性。例如如下图所示： 如图所示在业务逻辑处理中，也许左侧第一个ChannelHandler根本不需要管理某个业务逻辑，但是从第二个ChannelHandler就需要关注处理某个业务需求了，那么就可以很灵活地从第二个ChannelHandler开始处理业务，不需要从channel中的第一个ChannelHandler开始处理，这样会使代码显得让人看不懂~ 初步看懂的ChannelHandler,ChannelHandlerContext,ChannelPipeline之间的关系就是如上总结的]]></content>
  </entry>
  <entry>
    <title><![CDATA[Google Guava--localcache本地缓存实例]]></title>
    <url>%2F2018%2F04%2F19%2FGoogle-Guava-localcache%E6%9C%AC%E5%9C%B0%E7%BC%93%E5%AD%98%E5%AE%9E%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[一、思考和猜想首先看一下三种基于时间的清理或刷新缓存数据的方式： expireAfterAccess: 当缓存项在指定的时间段内没有被读或写就会被回收。同步执行 expireAfterWrite：当缓存项在指定的时间段内没有更新就会被回收。同步执行 refreshAfterWrite：当缓存项上一次更新操作之后的多久会被刷新。 异步执行 考虑到时效性，我们可以使用expireAfterWrite，使每次更新之后的指定时间让缓存失效，然后重新加载缓存。guava cache会严格限制只有1个加载操作，这样会很好地防止缓存失效的瞬间大量请求穿透到后端引起雪崩效应。 ​ 然而，通过分析源码，guava cache在限制只有1个加载操作时进行加锁，其他请求必须阻塞等待这个加载操作完成；而且，在加载完成之后，其他请求的线程会逐一获得锁，去判断是否已被加载完成，每个线程必须轮流地走一个“”获得锁，获得值，释放锁“”的过程，这样性能会有一些损耗。这里由于我们计划本地缓存1秒，所以频繁的过期和加载，锁等待等过程会让性能有较大的损耗。 ​ 因此我们考虑使用refreshAfterWrite。refreshAfterWrite的特点是，在refresh的过程中，严格限制只有1个重新加载操作，而其他查询先返回旧值，这样有效地可以减少等待和锁争用，所以refreshAfterWrite会比expireAfterWrite性能好。但是它也有一个缺点，因为到达指定时间后，它不能严格保证所有的查询都获取到新值。了解过guava cache的定时失效（或刷新）原来的同学都知道，guava cache并没使用额外的线程去做定时清理和加载的功能，而是依赖于查询请求。在查询的时候去比对上次更新的时间，如超过指定时间则进行加载或刷新。所以，如果使用refreshAfterWrite，在吞吐量很低的情况下，如很长一段时间内没有查询之后，发生的查询有可能会得到一个旧值（这个旧值可能来自于很长时间之前），这将会引发问题。 ​ 可以看出refreshAfterWrite和expireAfterWrite两种方式各有优缺点，各有使用场景。那么能否在refreshAfterWrite和expireAfterWrite找到一个折中？比如说控制缓存每1s进行refresh，如果超过2s没有访问，那么则让缓存失效，下次访问时不会得到旧值，而是必须得待新值加载。由于guava官方文档没有给出一个详细的解释，查阅一些网上资料也没有得到答案，因此只能对源码进行分析，寻找答案。经过分析，当同时使用两者的时候，可以达到预想的效果，这真是一个好消息呐！ 二、源码分析 通过追踪LoadingCache的get方法源码，发现最终会调用以下核心方法，下面贴出源码： com.google.common.cache.LocalCache.Segment.get方法： ​ 这个缓冲的get方法，编号1是判断是否有存活值，即根据expireAfterAccess和expireAfterWrite进行判断是否过期，如果过期，则value为null，执行编号3,。编号2指不过期的情况下，根据refreshAfterWrite判断是否需要refresh。而编号3是需要进行加载（load而非reload），原因是没有存活值，可能因为过期，可能根本就没有过该值。 ​ 从段代码来看，在get的时候，是先判断过期，再判断refresh，所以我们可以通过设置refreshAfterWrite为1s，将expireAfterWrite 设为2s，当访问频繁的时候，会在每秒都进行refresh，而当超过2s没有访问，下一次访问必须load新值。 ​ 我们继续顺藤摸瓜，顺带看看load和refresh分别都做了什么事情，验证以下上面说的理论。 下面看看 com.google.common.cache.LocalCache.Segment.lockedGetOrLoad方法： 这个方法有点长，限于篇幅，没有贴出全部代码，关键步骤有7步。 1.获得锁 2.获得key对应的valueReference 3.判断是否该缓存值正在loading，如果loading，则不再进行load操作（通过设置createNewEntry为false），后续会等待获取新值。 4.如果不是在loading，判断是否已经有新值了（被其他请求load完了），如果是则返回新值 5.准备loading，设置为loadingValueReference。loadingValueReference 会使其他请求在步骤3的时候会发现正在loding。 6。释放锁。 7.如果真的需要load，则进行load操作。 通过分析发现，只会有1个load操作，其他get会先阻塞住，验证了之前的理论。 下面看看com.google.common.cache.LocalCache.Segment.scheduleRefresh方法： 1.判断是否需要refresh，且当前非loading状态，如果是则进行refresh操作，并返回新值。 2.步骤2是我加上去的，为后面的测试做准备。如果需要refresh，但是有其他线程正在对该值进行refreshing，则打印，最终会返回旧值。 继续深入步骤1中调用的refresh方法： 1.插入loadingValueReference，表示该值正在loading，其他请求根据此判断是需要进行refresh还是返回旧值。insertLoadingValueReference里有加锁操作，确保只有1个refresh穿透到后端。限于篇幅，这里不再展开。但是，这里加锁的范围比load时候加锁的范围要小，在expire-&gt;load的过程，所有的get一旦知道expire，则需要获得锁，直到得到新值为止，阻塞的影响范围会是从expire到load到新值为止；而refresh-&gt;reload的过程，一旦get发现需要refresh，会先判断是否有loading，再去获得锁，然后释放锁之后再去reload，阻塞的范围只是insertLoadingValueReference的一个小对象的new和set操作，几乎可以忽略不计，所以这是之前说refresh比expire高效的原因之一。 2.进行refresh操作，这里不对loadAsync进行展开，它调用了CacheLoader的reload方法，reload方法支持重载去实现异步的加载，而当前线程返回旧值，这样性能会更好，其默认是同步地调用了CacheLoader的load方法实现。 ​ 到这里，我们知道了refresh和expire的区别了吧！refresh执行reload，而expire后会重新执行load，和初始化时一样。 三、测试和验证 ​ 在上面贴出的源码，大家应该注意到一些System.out.println语句，这些是我加上去的，便于后续进行测试验证。现在就来对刚刚的分析进行程序验证。 ​ 贴出测试的源码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687packagecom.example.demo; importjava.util.concurrent.CountDownLatch; importjava.util.concurrent.CyclicBarrier; importjava.util.concurrent.ExecutionException; importjava.util.concurrent.TimeUnit; importcom.google.common.cache.CacheBuilder; importcom.google.common.cache.CacheLoader; importcom.google.common.cache.LoadingCache ; importcom.google.common.util.concurrent.Futures; importcom.google.common.util.concurrent.ListenableFuture; publicclassConcurrentTest &#123; privatestaticfinal int CONCURRENT_NUM = 10;//并发数 privatevolatilestatic int value = 1; privatestaticLoadingCache &lt;String, String&gt; cache = CacheBuilder.newBuilder().maximumSize(1000) .expireAfterWrite(5, TimeUnit. SECONDS) .refreshAfterWrite(1, TimeUnit. SECONDS) .build(newCacheLoader&lt;String, String&gt;() &#123; publicString load(String key) throwsInterruptedException &#123; System. out.println( "load by " + Thread.currentThread().getName()); returncreateValue(key); &#125; @Override publicListenableFuture&lt;String&gt; reload(String key, String oldValue) throwsException &#123; System. out.println( "reload by " + Thread.currentThread().getName()); returnFutures.immediateFuture(createValue(key )); &#125; &#125; ); //创建value privatestaticString createValue(String key) throwsInterruptedException&#123; Thread. sleep(1000L);//让当前线程sleep 1秒，是为了测试load和reload时候的并发特性 returnString. valueOf(value++); &#125; publicstaticvoid main(String[] args) throwsInterruptedException, ExecutionException &#123; CyclicBarrier barrier = newCyclicBarrier(CONCURRENT_NUM ); CountDownLatch latch = newCountDownLatch(CONCURRENT_NUM ); for(inti = 0; i &lt; CONCURRENT_NUM; i++) &#123; finalClientRunnable runnable = newClientRunnable(barrier, latch ); Thread thread = newThread( runnable, "client-"+ i); thread.start(); &#125; //测试一段时间不访问后是否执行expire而不是refresh latch.await(); Thread. sleep(5100L); System. out.println( "\n超过expire时间未读之后..."); System. out.println(Thread. currentThread().getName() + ",val:"+ cache .get("key")); &#125; staticclassClientRunnable implementsRunnable&#123; CyclicBarrier barrier; CountDownLatch latch; publicClientRunnable(CyclicBarrier barrier, CountDownLatch latch)&#123; this. barrier = barrier; this. latch = latch; &#125; publicvoidrun() &#123; try&#123; barrier.await(); Thread. sleep((long)(Math.random()*4000));//每个client随机睡眠，为了充分测试refresh和load System. out.println(Thread. currentThread().getName() + ",val:"+ cache .get("key")); latch.countDown(); &#125;catch(Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; 执行结果： 验证结果和预期一致： 1.在缓存还没初始化的时候，client-1最新获得了load锁，进行load操作，在进行load的期间，其他client也到达进入load过程，阻塞，等待client-1释放锁，再依次获得锁。最终只load by client-1。 2.当超过了refreshAfterWrite设定的时间之内没有访问，需要进行refresh，client-5进行 refresh，在这个过程中，其他client并没有获得锁，而是直接查询旧值，直到refresh后才得到新值，过渡平滑。 3.在超过了expireAfterWrite设定的时间内没有访问，main线程在访问的时候，值已经过期，需要进行load操作，而不会得到旧值。]]></content>
  </entry>
  <entry>
    <title><![CDATA[高并发的核心技术-幂等的实现方案]]></title>
    <url>%2F2018%2F04%2F17%2F%E9%AB%98%E5%B9%B6%E5%8F%91%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF-%E5%B9%82%E7%AD%89%E7%9A%84%E5%AE%9E%E7%8E%B0%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[高并发的核心技术-幂等的实现方案 一、背景我们实际系统中有很多操作，是不管做多少次，都应该产生一样的效果或返回一样的结果。 例如： 前端重复提交选中的数据，应该后台只产生对应这个数据的一个反应结果。 我们发起一笔付款请求，应该只扣用户账户一次钱，当遇到网络重发或系统bug重发，也应该只扣一次钱； 发送消息，也应该只发一次，同样的短信发给用户，用户会哭的； 创建业务订单，一次业务请求只能创建一个，创建多个就会出大问题。 等等很多重要的情况，这些逻辑都需要幂等的特性来支持。 二、幂等性概念幂等（idempotent、idempotence）是一个数学与计算机学概念，常见于抽象代数中。 在编程中.一个幂等操作的特点是其任意多次执行所产生的影响均与一次执行的影响相同。幂等函数，或幂等方法，是指可以使用相同参数重复执行，并能获得相同结果的函数。这些函数不会影响系统状态，也不用担心重复执行会对系统造成改变。例如，“getUsername()和setTrue()”函数就是一个幂等函数. 更复杂的操作幂等保证是利用唯一交易号(流水号)实现. 我的理解：幂等就是一个操作，不论执行多少次，产生的效果和返回的结果都是一样的 三、技术方案1. 查询操作查询一次和查询多次，在数据不变的情况下，查询结果是一样的。select是天然的幂等操作 2. 删除操作删除操作也是幂等的，删除一次和多次删除都是把数据删除。(注意可能返回结果不一样，删除的数据不存在，返回0，删除的数据多条，返回结果多个) 3.唯一索引，防止新增脏数据比如：支付宝的资金账户，支付宝也有用户账户，每个用户只能有一个资金账户，怎么防止给用户创建资金账户多个，那么给资金账户表中的用户ID加唯一索引，所以一个用户新增成功一个资金账户记录 要点： 唯一索引或唯一组合索引来防止新增数据存在脏数据 （当表存在唯一索引，并发时新增报错时，再查询一次就可以了，数据应该已经存在了，返回结果即可） 4. token机制，防止页面重复提交业务要求：页面的数据只能被点击提交一次发生原因：由于重复点击或者网络重发，或者nginx重发等情况会导致数据被重复提交解决办法：集群环境：采用token加redis（redis单线程的，处理需要排队）单JVM环境：采用token加redis或token加jvm内存处理流程： 数据提交前要向服务的申请token，token放到redis或jvm内存，token有效时间 提交后后台校验token，同时删除token，生成新的token返回token特点：要申请，一次有效性，可以限流 注意：redis要用删除操作来判断token，删除成功代表token校验通过，如果用select+delete来校验token，存在并发问题，不建议使用 5. 悲观锁获取数据的时候加锁获取select * from table_xxx where id=’xxx’ for update;注意：id字段一定是主键或者唯一索引，不然是锁表，会死人的 悲观锁使用时一般伴随事务一起使用，数据锁定时间可能会很长，根据实际情况选用 6. 乐观锁乐观锁只是在更新数据那一刻锁表，其他时间不锁表，所以相对于悲观锁，效率更高。 乐观锁的实现方式多种多样可以通过version或者其他状态条件： 通过版本号实现update table_xxx set name=#name#,version=version+1 where version=#version#如下图(来自网上)： 通过条件限制update table_xxx set avai_amount=avai_amount-#subAmount# where avai_amount-#subAmount# &gt;= 0要求：quality-#subQuality# &gt;= ，这个情景适合不用版本号，只更新是做数据安全校验，适合库存模型，扣份额和回滚份额，性能更高 注意：乐观锁的更新操作，最好用主键或者唯一索引来更新,这样是行锁，否则更新时会锁表，上面两个sql改成下面的两个更好 update table_xxx set name=#name#,version=version+1 where id=#id# and version=#version# update table_xxx set avai_amount=avai_amount-#subAmount# where id=#id# and avai_amount-#subAmount# &gt;= 0 分布式锁还是拿插入数据的例子，如果是分布是系统，构建全局唯一索引比较困难，例如唯一性的字段没法确定，这时候可以引入分布式锁，通过第三方的系统(redis或zookeeper)，在业务系统插入数据或者更新数据，获取分布式锁，然后做操作，之后释放锁，这样其实是把多线程并发的锁的思路，引入多多个系统，也就是分布式系统中得解决思路。 要点：某个长流程处理过程要求不能并发执行，可以在流程执行之前根据某个标志(用户ID+后缀等)获取分布式锁，其他流程执行时获取锁就会失败，也就是同一时间该流程只能有一个能执行成功，执行完成后，释放分布式锁(分布式锁要第三方系统提供) select + insert并发不高的后台系统，或者一些任务JOB，为了支持幂等，支持重复执行，简单的处理方法是，先查询下一些关键数据，判断是否已经执行过，在进行业务处理，就可以了注意：核心高并发流程不要用这种方法 9. 状态机幂等在设计单据相关的业务，或者是任务相关的业务，肯定会涉及到状态机(状态变更图)，就是业务单据上面有个状态，状态在不同的情况下会发生变更，一般情况下存在有限状态机，这时候，如果状态机已经处于下一个状态，这时候来了一个上一个状态的变更，理论上是不能够变更的，这样的话，保证了有限状态机的幂等。 注意：订单等单据类业务，存在很长的状态流转，一定要深刻理解状态机，对业务系统设计能力提高有很大帮助 10. 对外提供接口的api如何保证幂等如银联提供的付款接口：需要接入商户提交付款请求时附带：source来源，seq序列号source+seq在数据库里面做唯一索引，防止多次付款，(并发时，只能处理一个请求) 重点： 对外提供接口为了支持幂等调用，接口有两个字段必须传，一个是来源source，一个是来源方序列号seq，这个两个字段在提供方系统里面做联合唯一索引，这样当第三方调用时，先在本方系统里面查询一下，是否已经处理过，返回相应处理结果；没有处理过，进行相应处理，返回结果。注意，为了幂等友好，一定要先查询一下，是否处理过该笔业务，不查询直接插入业务系统，会报错，但实际已经处理了。 总结：幂等性应该是合格程序员的一个基因，在设计系统时，是首要考虑的问题，尤其是在像支付宝，银行，互联网金融公司等涉及的都是钱的系统，既要高效，数据也要准确，所以不能出现多扣款，多打款等问题，这样会很难处理，用户体验也不好]]></content>
  </entry>
  <entry>
    <title><![CDATA[zookeeper 跨机房]]></title>
    <url>%2F2018%2F04%2F09%2Fzookeeper-%E8%B7%A8%E6%9C%BA%E6%88%BF%2F</url>
    <content type="text"><![CDATA[背景 前段时间学习了zookeeper后，在新的项目中刚好派上了用场，我在项目中主要负责分布式任务调度模块的开发，对我自己来说是个不小的挑战。 分布式的任务调度，技术上我们选择了zookeeper，具体的整个分布式任务调度的架构选择会另起一篇文章进行介绍。 本文主要是介绍自己在项目中zookeeper的一些扩展使用，希望可以对大家有所帮助。 项目中使用的zookeeper版本3.3.3，对应的文档地址： http://zookeeper.apache.org/doc/trunk/ zookeeper学习记录 zookeeper学习记录(二) 扩展一：优先集群先来点背景知识： 1.zookeeper中的server机器之间会组成leader/follower集群，1:n的关系。采用了paxos一致性算法保证了数据的一致性，就是leader/follower会采用通讯的方式进行投票来实现paxns。 2.zookeeper还支持一种observer模式，提供只读服务不参与投票，提升系统，对应文档： http://zookeeper.apache.org/doc/trunk/zookeeperObservers.html 我们项目特性的决定了我们需要进行跨机房操作，比如杭州，美国，香港，青岛等多个机房之间进行数据交互。 跨机房之间对应的网络延迟都比较大，比如中美机房走海底光缆有ping操作200ms的延迟，杭州和青岛机房有70ms的延迟。 为了提升系统的网络性能，我们在部署zookeeper网络时会在每个机房部署节点，多个机房之间再组成一个大的网络保证数据一致性。(zookeeper千万别再搞多个集群) 最后的部署结构就会是： 杭州机房 &gt;=3台 (构建leader/follower的zk集群) 青岛机房 &gt;=1台 (构建observer的zk集群) 美国机房 &gt;=1台 (构建observer的zk集群) 香港机房 &gt;=1台 (构建observer的zk集群) 一句话概括就是： 在单个机房内组成一个投票集群，外围的机房都会是一个observer集群和投票集群进行数据交互。 这样部署的一些好处，大家可以细细体会一下 针对这样的部署结构，我们会引入一个优先集群问题： 比如在美国机房的机器需要优先去访问本机房的zk集群，访问不到后才去访问杭州机房。 默认在zookeeper3.3.3的实现中，认为所有的节点都是对等的。并没有对应的优先集群的概念，单个机器也没有对应的优先级的概念。 扩展代码：(比较暴力，采用反射的方式改变了zk client的集群列表) 先使用美国机房的集群ip初始化一次zk client 通过反射方式，强制在初始化后的zk client中的server列表中又加入杭州机房的机器列表 12345678910111213141516171819202122232425ZooKeeper zk = null; try &#123; zk = new ZooKeeper(cluster1, sessionTimeout, new AsyncWatcher() &#123; public void asyncProcess(WatchedEvent event) &#123; //do nothing &#125; &#125;); if (serveraddrs.size() &gt; 1) &#123; // 强制的声明accessible ReflectionUtils.makeAccessible(clientCnxnField); ReflectionUtils.makeAccessible(serverAddrsField); // 添加第二组集群列表 for (int i = 1; i &lt; serveraddrs.size(); i++) &#123; String cluster = serveraddrs.get(i); // 强制获取zk中的地址信息 ClientCnxn cnxn = (ClientCnxn) ReflectionUtils.getField(clientCnxnField, zk); List&lt;InetSocketAddress&gt; serverAddrs = (List&lt;InetSocketAddress&gt;) ReflectionUtils .getField(serverAddrsField, cnxn); // 添加第二组集群列表 serverAddrs.addAll(buildServerAddrs(cluster)); &#125; &#125; &#125; 扩展二：异步Watcher处理 最早在看zookeeper的代码时，一直对它的watcher处理比较满意，使用watcher推送数据可以很方便的实现分布式锁的功能。 zookeeper的watcher实现原理也挺简单的，就是在zookeeper client和zookeeper server上都保存一份对应的watcher对象。每个zookeeper机器都会有一份完整的node tree数据和watcher数据，每次leader通知follower/observer数据发生变更后，每个zookeeper server会根据自己节点中的watcher事件推送给响应的zookeeper client，每个zk client收到后再根据内存中的watcher引用，进行回调。 这里会有个问题，就是zk client在处理watcher时，回凋的过程是一个串行的执行过程，所以单个watcher的处理慢会影响整个列表的响应。 可以看一下ClientCnxn类中的EventThread处理，该线程会定时消费一个queue的数据，挨个调用processEvent(Object event) 进行回调处理。 123456789101112131415161718192021222324252627282930public abstract class AsyncWatcher implements Watcher &#123; private static final int DEFAULT_POOL_SIZE = 30; private static final int DEFAULT_ACCEPT_COUNT = 60; private static ExecutorService executor = new ThreadPoolExecutor( 1, DEFAULT_POOL_SIZE, 0L, TimeUnit.MILLISECONDS, new ArrayBlockingQueue( DEFAULT_ACCEPT_COUNT), new NamedThreadFactory( "Arbitrate-Async-Watcher"), new ThreadPoolExecutor.CallerRunsPolicy()); public void process(final WatchedEvent event) &#123; executor.execute(new Runnable() &#123;//提交异步处理 @Override public void run() &#123; asyncProcess(event); &#125; &#125;); &#125; public abstract void asyncProcess(WatchedEvent event); &#125; 说明： zookeeper针对watcher的调用是以单线程串行的方式进行处理，容易造成堵塞影响，monitor的数据同步及时性 AsyncWatcher为采取的一种策略为当不超过acceptCount=60的任务时，会采用异步线程的方式处理。如果超过60任务，会变为原先的单线程串行的模式 扩展三：重试处理这个也不多说啥，看一下相关文档就清楚了 http://wiki.apache.org/hadoop/ZooKeeper/ErrorHandling http://wiki.apache.org/hadoop/ZooKeeper/FAQ#A3 需要特殊处理下ConnectionLoss的异常，一种可恢复的异常。 12345678910111213141516171819202122232425262728293031public interface ZooKeeperOperation&lt;T&gt; &#123; public T execute() throws KeeperException, InterruptedException; &#125; /** * 包装重试策略 */ public &lt;T&gt; T retryOperation(ZooKeeperOperation&lt;T&gt; operation) throws KeeperException, InterruptedException &#123; KeeperException exception = null; for (int i = 0; i &lt; maxRetry; i++) &#123; try &#123; return (T) operation.execute(); &#125; catch (KeeperException.SessionExpiredException e) &#123; logger.warn("Session expired for: " + this + " so reconnecting due to: " + e, e); throw e; &#125; catch (KeeperException.ConnectionLossException e) &#123; //特殊处理Connection Loss if (exception == null) &#123; exception = e; &#125; logger.warn("Attempt " + i + " failed with connection loss so " + "attempting to reconnect: " + e, e); retryDelay(i); &#125; &#125; throw exception; &#125; 注意点：Watcher原子性在使用zookeeper的过程中，需要特别注意一点就是注册对应watcher事件时，如果当前的节点已经满足了条件，比如exist的watcher，它不会触发你的watcher，而会等待下一次watcher条件的满足。 它的watcher是一个一次性的监听，而不是一个永久的订阅过程。所以在watcher响应和再次注册watcher过程并不是一个原子操作，编写多线程代码和锁时需要特别注意 总结 zookeepr是一个挺不错的产品，源代码写的也非常不错，大量使用了queue和异步Thread的处理模式，真是一个伟大的产品。 http://agapple.iteye.com/blog/1184023]]></content>
  </entry>
  <entry>
    <title><![CDATA[Cookie详解]]></title>
    <url>%2F2018%2F04%2F06%2FCookie%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[cookie简介1. 定义cookie是由服务器发送给客户端（浏览器）的小量信息。 2. 作用cookie是键值对形式存储的少量信息，那它有什么作用呢？ 我们知道，平时上网时都是使用无状态的HTTP协议传输出数据，这意味着客户端与服务端在数据传送完成后就会中断连接。这时我们就需要一个一直保持会话连接的机制。在session出现前，cookie就完全充当了这种角色。也就是，cookie的小量信息能帮助我们跟踪会话。一般该信息记录用户身份。 当然cookie也常记录跟踪购物车的商品信息（如数量）、记录用户访问次数等。 3. 原理客户端请求服务器时，如果服务器需要记录该用户状态，就使用response向客户端浏览器颁发一个Cookie。而客户端浏览器会把Cookie保存起来。当浏览器再请求服务器时，浏览器把请求的网址连同该Cookie一同提交给服务器。服务器通过检查该Cookie来获取用户状态。 4.添加cookie示例获取客户端的Cookie时，只能获取name与value属性，其它属性都不会被提交。 123Cookie c = new Cookie(&quot;username&quot;,&quot;peter&quot;);// 新建一个Cookie对象c.setMaxAge(24*60*60); // 设置过期时间1天，以秒为单位response.addCookie(c); // 保存cookie到客户端123 5.删除cookie示例删除某个Cookie时，只需要新建一个只有maxAge和value不一样的同名Cookie，然后添加到response中覆盖原来的Cookie 123Cookie cookie = new Cookie(&quot;username&quot;,&quot;peter&quot;);// 新建Cookiecookie.setMaxAge(0); // 设置生命周期为0，表示将要删除response.addCookie(cookie); // 执行添加后就从response里删除了123 6.修改cookie示例修改某个Cookie时，只需要新建一个只有value属性不一样的同名Cookie，然后添加到response中覆盖原来的Cookie 123Cookie cookie = new Cookie(&quot;username&quot;,&quot;joker&quot;);// 新建Cookiecookie.setMaxAge(24*60*60); // 设置生命周期response.addCookie(cookie); // 执行添加后就从response里覆盖修改了123 注意：修改、删除Cookie时，新建的Cookie除value、maxAge之外的所有属性，例如name、path、domain等，都要与原Cookie完全一样。否则，浏览器将视为两个不同的Cookie而不会覆盖之前的Cookie，从而导致修改、删除失败。 Cookie类的各方法详解Cookie类在javax.servlet.http.Cookie包中 方法名 返回类型 说明 setValue(String newValue) void 给当前cookie重新赋值 setComment(String purpose) void 对该cookie进行描述的信息(说明作用)，浏览器显示cookie信息时能看到 setDomain(String pattern) void 符合该pattern（域名正则）的就可以访问该Cookie的域名。如果设置为“.google.com”，则所有以“google.com”结尾的域名都可以访问该Cookie。注意第一个字符必须为“.” setHttpOnly(boolean httpOnly) void 设为true后，只能通过http访问，javascript无法访问,还可防止xss读取cookie setMaxAge(int expiry) void 该Cookie失效时间，单位秒。如果为正数，则该Cookie在expiry秒之后失效。如果为负数，该Cookie为临时Cookie，关闭浏览器即失效，浏览器也不会以任何形式保存该Cookie。如果为0，表示删除该Cookie。默认为–1 setPath(String uri) void 设置Cookie的使用路径。后面紧接着详解。如果设置为“/agx/”，则只有uri为“/agx”的程序可以访问该Cookie。如果设置为“/”，则本域名下的uri都可以访问该Cookie。注意最后一个字符必须为”/” setSecure(boolean flag) void 是否使用安全传输协议。为true时，只有当是https请求连接时cookie才会发送给服务器端，而http时不会，但是服务端还是可以发送给浏览端的。 对应的getter方法我就不讲了。如果cookie值为Unicode字符，需要为字符编码。如果cookie值为二进制数据，则需要使用BASE64编码 cookie的setPath()和setDomain()方法默认情况下cookie只能在一个应用中共享，即一个cookie只能由创建它的应用获得。 设置同一服务器内的cookie使用范围用setPath c.setPath(“/”)，使同一服务器内所有应用都可访问到该Cookie： 12345Cookie c = new Cookie(&quot;name&quot;,&quot;peter&quot;);c.setMaxAge(24*60*60); c.setPath(&quot;/&quot;);//同一服务器内所有应用都可访问到该Cookieresponse.addCookie(c); //保存cookie到客户端12345 如果同一服务器内有两个应用agx1.0和agx2.0当我们在agx1.0里有c.setPath(&quot;/agx2.0/&quot;);时，该cookie就只能在agx2.0下面能获取到，就连创建该cookie的agx1.0也获取不到。 如果在agx1.0里有c.setPath(&quot;/agx2.0/abc/&quot;);时,则只能在agx2.0/abc下面才能获得该cookie，即使在agx2.0下面也不能获取到。 cookie的跨域1.正常情况下Cookie不可跨域名，如域名www.google.com颁发的Cookie不会被提交到域名www.baidu.com去。这是由Cookie的隐私安全机制决定的。即使在同一个一级域名下的两个二级域名如www.agx.com和images.agx.com也不能交互使用Cookie，因为二者的域名并不严格相同。如果想所有agx.com名下的二级域名都可以使用该Cookie，则需要设置Cookie的domain参数为”.agx.com”，例如： 12345Cookie cookie = new Cookie(&quot;name&quot;,&quot;peter&quot;); // 新建Cookiecookie.setDomain(&quot;.agx.com&quot;); // 设置域名cookie.setPath(&quot;/&quot;); // 设置路径cookie.setMaxAge(Integer.MAX_VALUE); // 设置有效期为永久response.addCookie(cookie); // 输出到客户端12345 读者可以修改本机C:\WINDOWS\system32\drivers\etc下的hosts文件来配置多个临时域名，然后使用setCookie.jsp程序来设置跨域名Cookie验证domain属性。注意：domain参数必须以点(“.”)开始。另外，name相同但domain不同的两个Cookie是两个不同的Cookie。如果想要两个域名完全不同的网站共有Cookie，可以生成两个name相同的Cookie，domain属性分别为两个域名。 2.若A服务器的域名为：adv.audiogroup.com,有应用名为：agx1.0; B服务器的域名为：agx.com,有应用名为：agx2.0。在A服务器的agx1.0应用下设置cookie如下： 12345Cookie cookie = new Cookie(&quot;name&quot;,&quot;peter&quot;); // 新建Cookiecookie.setDomain(&quot;.agx.com&quot;); // 设置域名cookie.setPath(&quot;/&quot;); // 设置路径cookie.setMaxAge(Integer.MAX_VALUE); // 设置有效期为永久response.addCookie(cookie); // 输出到客户端12345 这时，在B服务器下的agx2.0应用和agx1.0里都能取到上面的Cookie。注：输入URL访问agx2.0时，必须输入域名才能获取其它服务器共享给它的cookie，如：输入http://images.agx.com:8080/agx2.0,可以获取agx1.0在客户端设置的cookie输入：http://localhost:8080/agx2.0则不可以获得cookie。 setPath()与setDomain()的区别?setDomain()主要用来确定两个不同名称但后缀相同的网站地址是否能使用同一个Cookie。例: www.agx.com和 bbs.agx.com只要有cookie.setDomain(&quot;.zjut.edu.cn&quot;);就都能使用该cookie setPath()主要用来确定地址里什么后缀下能够使用这个Cookie 归结起来就是：setDomain决定允许访问Cookie的域名，而setPath决定允许访问Cookie的路径（ContextPath） 获取用户请求里的cookie1234567Cookie[] cookie = request.getCookies();//获取的是请求里的所有cookie组成的数组for(int i=0;i&lt;cookie.length;i++)&#123; if(&quot;name&quot;.equals(cookie[i].getName()))&#123; System.out.println(cookie[i].getValue());//得到peter break; &#125;&#125;1234567 解决cookie里中文乱码问题Cookie中要保存中文只能编码。一般使用UTF-8编码即可。不推荐使用GBK等中文编码，因为浏览器不一定支持，而且JavaScript也不支持GBK编码。 Cookie不仅可以使用ASCII字符与Unicode字符，还可以使用二进制数据。例如在Cookie中使用数字证书，提供安全度。使用二进制数据时也需要进行编码（如用BASE64编码保存二进制图片）。由于浏览器每次请求都会带着Cookie，因此Cookie内容不宜过多，所以一般不会在Cookie中存储二进制的内容 JS操作CookieCookie是保存在客户端的，所以浏览器可以使用脚本（JS）等操作Cookie。 12345678910111213141516171819202122232425&lt;script language=javascript&gt; //添加cookie function setCookie(name,value,time)&#123; var date= new Date(); date.setDate(date.getDate()+time); document.cookie = name+&quot;=&quot;+value+&quot;;expires=&quot;+date; &#125; //获得cookie function getCookie(name)&#123; var arr = document.cookie.split(&quot;;&quot;); for(var i=0; i&lt;arr.length; i++)&#123; var arr2 = arr[i].split(&quot;=&quot;); if(arr2[0] == name)&#123; return arr2[1]; &#125; &#125; return null; &#125; //删除cookie function removeCookie(name)&#123; setCookie(name,&quot;&quot;,0) &#125; &lt;/script&gt;12345678910111213141516171819202122232425 12W3C标准的浏览器会阻止JavaScript读写任何不属于自己网站的Cookie。即A网站的JavaScript代码里获取不到B网站的Cookie。12 使用cookie记住密码方案1：直接把用户名与密码都保持到Cookie中，下次访问时检查Cookie中的用户名与密码，与数据库比较。这是一种比较危险的选择，一般不把密码等重要信息保存到Cookie中。方案2：把密码加密后保存到Cookie中，下次访问时解密并与数据库比较。这种方案略微安全一些。如果不希望保存密码，还可以把登录的时间戳保存到Cookie与数据库中，到时只验证用户名与登录时间戳就可以了。方案3：实现方式是把账号按照一定的规则（密钥）加密后，连同账号一块保存到Cookie中。下次访问时只需要判断账号的加密规则是否相同即可。加 密： 123456789101112String userName = request.getParameter(&quot;userName&quot;);//获取用户名Md5Hash psw = new Md5Hash(userName, &quot;peter.com&quot;, 2);//以peter.com为密钥加密//将用户名添加进cookie并发送给客户端Cookie userCookie = new Cookie(&quot;userName&quot;,userName);userCookie.setMaxAge(7*24*60*60);response.addCookie(userCookie);//将密钥生成的密文加进cookie并发送给客户端Cookie c = new Cookie(&quot;key&quot;,psw.toString());c.setMaxAge(7*24*60*60);response.addCookie(c);123456789101112 解密： 123456789101112131415161718String usreName = null;String key = null;Cookie[] cookie = request.getCookies();if(cookie !=null)&#123; for(Cookie c:cookie)&#123; // 遍历Cookie if(&quot;userName&quot;.equals(c.getName()) userName = c.getValue(); if(&quot;key&quot;.equals(c.getName()) key= cookie.getValue(); &#125;&#125;if(userName != null &amp;&amp; key != null)&#123; String secrect = new Md5Hash(userName, &quot;peter.com&quot;, 2); if(key.equals(secrect ))&#123;//加密规则正确，说明已经登录 //... //....省略后续处理 &#125;&#125;123456789101112131415161718 由上面可知，如果将密码加密后存进cookie后，当我们下次访问登录页时，密码框里的密码将不是用户真正的密码。 博主地址：http://blog.csdn.net/zcl_love_wx https://blog.csdn.net/zcl_love_wx/article/details/51992999]]></content>
  </entry>
  <entry>
    <title><![CDATA[客户端与服务器端交互 如何保持session]]></title>
    <url>%2F2018%2F04%2F06%2F%E5%AE%A2%E6%88%B7%E7%AB%AF%E4%B8%8E%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%AB%AF%E4%BA%A4%E4%BA%92-%E5%A6%82%E4%BD%95%E4%BF%9D%E6%8C%81session%2F</url>
    <content type="text"><![CDATA[最近在开发项目的过程中，遇到android与web服务器要在同一session下通信的问题。 在解决问题前先回顾下Session与Cookie： Cookie和Session都为了用来保存状态信息，都是保存客户端状态的机制，它们都是为了解决HTTP无状态的问题而所做的努力。 Session可以用Cookie来实现，也可以用URL回写的机制来实现。 Cookie和Session有以下明显的不同点： 1）Cookie将状态保存在客户端，Session将状态保存在服务器端； 2）Cookies是服务器在本地机器上存储的小段文本并随每一个请求发送至同一个服务器。网络服务器用HTTP头向客户端发送cookies，在客户终端，浏览器解析这些cookies并将它们保存为一个本地文件，它会自动将同一服务器的任何请求缚上这些cookies。 3）Session是针对每一个用户的，变量的值保存在服务器上，用一个sessionID来区分是不同用户session变量,这个值是通过用户的浏览器在访问的时候返回给服务器，当客户禁用cookie时，这个值也可能设置为由get来返回给服务器； 4）就安全性来说：当你访问一个使用session 的站点，同时在自己机器上建立一个cookie，建议在服务器端的SESSION机制更安全些.因为它不会任意读取客户存储的信息。 Session机制 Session机制是一种服务器端的机制，服务器使用一种类似于散列表的结构（也可能就是使用散列表）来保存信息。 当程序需要为某个客户端的请求创建一个session的时候，服务器首先检查这个客户端的请求里是否已包含了一个session标识 - 称为 session id，如果已包含一个session id则说明以前已经为此客户端创建过session，服务器就按照session id把这个 session检索出来使用（如果检索不到，可能会新建一个），如果客户端请求不包含session id，则为此客户端创建一个session并且生成一个与此session相关联的session id，session id的值应该是一个既不会重复，又不容易被找到规律以仿造的字符串，这个 session id将被在本次响应中返回给客户端保存。 Session的实现方式 1 ） 使用Cookie来实现 服务器给每个Session分配一个唯一的JSESSIONID，并通过Cookie发送给客户端。 当客户端发起新的请求的时候，将在Cookie头中携带这个JSESSIONID。这样服务器能够找到这个客户端对应的Session。 2 ）使用URL回显来实现 URL回写是指服务器在发送给浏览器页面的所有链接中都携带JSESSIONID的参数，这样客户端点击任何一个链接都会把JSESSIONID带给服务器。如果直接在浏览器中输入url来请求资源，Session是匹配不到的。 Tomcat对 Session的实现，是一开始同时使用Cookie和URL回写机制，如果发现客户端支持Cookie，就继续使用Cookie，停止使用URL回写。如果发现Cookie被禁用，就一直使用URL回写。jsp开发处理到Session的时候，对页面中的链接记得使用 response.encodeURL() 。 回顾完Session和Cookie，我们来说说为什么手机端与服务器交互没有实现在同一session下？ 1）原因很简单，就是因为android手机端在访问web服务器时，没有给http请求头部设置sessionID，而使用web浏览器作为客户端访问服务器时，在客户端每次发起请求的时候，都会将交互中的sessionID：JSESSIONID设置在Cookie头中携带过去，服务器根据这个sessionID获取对应的Session,而不是重新创建一个新Session(除了这个Session失效)。 以java.net.HttpURLConnection发起请求为例： 获取Cookie： URL url = new URL(requrl); HttpURLConnection con= (HttpURLConnection) url.openConnection();// 取得sessionid.String cookieval = con.getHeaderField(“set-cookie”);String sessionid;if(cookieval != null) {sessionid = cookieval.substring(0, cookieval.indexOf(“;”));} //sessionid值格式：JSESSIONID=AD5F5C9EEB16C71EC3725DBF209F6178，是键值对，不是单指值 发送设置cookie： URL url = new URL(requrl);HttpURLConnectioncon= (HttpURLConnection) url.openConnection();if(sessionid != null) {con.setRequestProperty(“cookie”, sessionid);} 只要设置了sessionID，这样web服务器在接受请求的时候就会自动搜索对应的session了，从而保证了在同一会话Session。 文章出处：http://hi.baidu.com/cuihenrychl/item/a08e18268a01461577272ce4]]></content>
  </entry>
  <entry>
    <title><![CDATA[spring 注解标签总结]]></title>
    <url>%2F2018%2F04%2F06%2Fspring-%E6%B3%A8%E8%A7%A3%E6%A0%87%E7%AD%BE%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[声明Bean的注解: @Component : 组件,没有明确的角色 @Service : 在业务逻辑层(service层)使用 @Repository : 在数据访问层(dao层)使用. @Controller : 在展现层(MVC–SpringMVC)使用 注入Bean的注解: @Aautowired : Spring提供的注解. @Inject : JSR-330提供的注解 @Resource : JSR-250提供的注解 配置文件的注解: @Configuration : 声明当前类是个配置类,相当于一个Spring配置的xml文件. @ComponentScan (cn.test.demo): 自动扫描包名下所有使用 @Component @Service @Repository @Controller 的类,并注册为Bean @WiselyConfiguration : 组合注解可以替代 @Configuration和@ComponentScan @Bean : 注解在方法上,声明当前方法的返回值为一个Bean.· @Bean(initMethod=”aa”,destroyMethod=”bb”)–&gt; 指定 aa和bb方法在构造之后.Bean销毁之前执行. AOP切面编程注解: @Aspect : 声明这是一个切面 @After @Before. @Around 定义切面,可以直接将拦截规则(切入点 PointCut)作为参数 @PointCut : 专门定义拦截规则然后在 @After @Before. @Around 中调用 @Transcational : 事务处理 @Cacheable : 数据缓存 @EnableAaspectJAutoProxy : 开启Spring 对这个切面(Aspect )的支持 @Target (ElementType.TYPE):元注解,用来指定注解修饰类的那个成员 –&gt;指定拦截规则 @Retention(RetentionPolicy.RUNTIME) · —&gt;当定义的注解的@Retention为RUNTIME时，才能够通过运行时的反射机制来处理注解.–&gt;指定拦截规则 Spring 常用配置: @import :导入配置类 @Scope : 新建Bean的实例 @Scope(“prototype”) 声明Scope 为 Prototype @Value : 属性注入· @Value (“我爱你”) –&gt; 普通字符串注入 @Value (“#{systemProperties[‘os.name’]}”) –&gt;注入操作系统属性 @Value (“#{ T (java.lang.Math).random() * 100.0 }”) –&gt; 注入表达式结果 @Value (“#{demoService.another}”) –&gt; 注入其他Bean属性 @Value ( “classpath:com/wisely/highlight_spring4/ch2/el/test.txt” ) –&gt; 注入文件资源 @Value (“http://www.baidu.com&quot;)--&gt;注入网址资源 @Value (“${book.name}” ) –&gt; 注入配置文件 注意: 使用的是$ 而不是 # @PostConstruct : 在构造函数执行完之后执行 @PreDestroy : 在 Bean 销毁之前执行 @ActiveProfiles : 用来声明活动的 profile @profile: 为不同环境下使用不同的配置提供了支持· @Profile(“dev”) …….对方法名为 dev-xxxx的方法提供实例化Bean @ActiveProfiles(“dev”)测试类中激活相应环境Bean @EnableAsync : 开启异步任务的支持(多线程) @Asyns : 声明这是一个异步任务,可以在类级别和方法级别声明. @EnableScheduling : 开启对计划任务的支持(定时器) @Scheduled : 声明这是一个计划任务支持多种计划任务,包含 cron. fixDelay fixRate· @Scheduled (dixedDelay = 5000) 通过注解定时更新 @Conditional : 条件注解,根据满足某一特定条件创建一个特定的Bean @ContextConfiguration : 加载配置文件· @ContextConfiguration(classes = {TestConfig.class}) @ContextConfiguration用来加载ApplicationContext classes属性用来加载配置类 @WebAppCofiguration : 指定加载 ApplicationContext是一个WebApplicationContext @Enable*注解: @EnableAsync : 开启异步任务的支持(多线程) @EnableScheduling : 开启对计划任务的支持(定时器) @EnableWebMVC : 开启对Web MVC 的配置支持 @EnableAaspectJAutoProxy : 开启Spring 对这个切面(Aspect )的支持 @EnableConfigurationProperties 开启对@ConfigurationProperties注解配置Bean的支持 @EnableJpaRepositories : 开启对Spring Data JAP Repository 的支持 @EnableTransactionManagement 开启对注解式事物的支持 @EnableCaching开启注解是缓存的支持. @EnableDiscoveryClient 让服务发现服务器,使用服务器.Spring cloud 实现服务发现 @EnableEurekaServer 注册服务器 spring cloud 实现服务注册@ @EnableScheduling 让spring可以进行任务调度,功能类似于spring.xml文件中的命名空间task:* @EnableCaching 开启Cache缓存支持; SpringMVC 常用注解: @Controller : 注解在类上声明这个类是springmvc里的Controller,将其声明为一个spring的Bean. @RequestMapping :可以注解在类上和方法上映射WEB请求(访问路径和参数)· @RequestMapping(value= “/convert”,produces+{“application/x-wisely”}) 设置访问URL 返回值类型 @ResponseBody : 支持将返回值放入response体内而不是返回一个页面(返回的是一个组数据) @RequestBody : 允许request的参数在request体中,而不是直接连接在地址后面次注解放置在参数前 @Path Variable : 用来接收路径参数如/test/001,001为参数,次注解放置在参数前 @RestController : @Controller + @ResponseBody 组合注解 @ControllerAdvice : 通过@ControllerAdvice可以将对已控制器的全局配置放置在同一个位置 @ExceptionHandler : 用于全局处理控制器的异常· @ExceptionHandier(value=Exception.class) –&gt;通过value属性可过滤拦截器条件,拦截所有的异常 @InitBinder : 用来设置WebDataBinder , WebDataBinder用来自动绑定前台请求参数到Model中. @ModelAttrbuute : 绑定键值对到Model中, @RunWith : 运行器 · @RunWith(JUnit4.class)就是指用JUnit4来运行 @RunWith(SpringJUnit4ClassRunner.class),让测试运行于Spring测试环境 @RunWith(Suite.class)的话就是一套测试集合， @WebAppConfiguration(“src/main/resources”) : 注解在类上,用来声明加载的ApplicationContex 是一个WebApplicationContext ,它的属性指定的是Web资源的位置,默认为 src/main/webapp ,自定义修改为 resource @Before : 在 xxx 前初始化 Spring Boot 注解: @SpringBootApplication : 是Spring Boot 项目的核心注解主要目的是开启自动配置· @SpringBootApplication注解是一个组合注解,主要组合了@Configuration .+@EnableAutoConfiguration.+@ComponentScan @Value : 属性注入,读取properties或者 Yml 文件中的属性 @ConfigurationProperties : 将properties属性和一个Bean及其属性关联,从而实现类型安全的配置· @ConfigurationProperties(prefix = “author”,locations = {“classpath:config/author.properties”}) 通过@ConfigurationProperties加载配置,通过prefix属性指定配置前缀,通过location指定配置文件位置 @EnableAutoConfiguration 注解:作用在于让 Spring Boot 根据应用所声明的依赖来对 Spring框架进行自动配置这个注解告诉Spring Boot根据添加的jar依赖猜测你想如何配置Spring。由于spring-boot-starter-web添加了Tomcat和Spring MVC，所以auto-configuration将假定你正在开发一个web应用并相应地对Spring进行设置。 @ Configuration 注解，以明确指出该类是 Bean 配置的信息源 @ComponentScan 注解会告知Spring扫描指定的包来初始化Spring Bean这能够确保我们声明的Bean能够被发现。 @ImportResource 注解加载XML配置文件 @EnableAutoConfiguration(exclude={xxxx.class}) 禁用特定的自动配置 @SpringBootApplication 注解等价于以默认属性使用@Configuration，@EnableAutoConfiguration和 @ComponentScan。 @SuppressWarnings注解 @SuppressWarnings(“unchecked”)· 告诉编译器忽略 unchecked 警告信息,如使用 list ArrayList等未进行参数化产生的警告信息 @SuppressWarnings(“serial”)· 如果编译器出现这样的警告信息: The serializable class WmailCalendar does not declare a static final serialVersionUID field of type long 使用这个注释将警告信息去掉。 @SuppressWarnings(“deprecation”)· 如果使用了使用@Deprecated注释的方法，编译器将出现警告信息。使用这个注释将警告信息去掉。 @SuppressWarnings(“unchecked”, “deprecation”)· 告诉编译器同时忽略unchecked和deprecation的警告信息。 @SuppressWarnings(value={“unchecked”, “deprecation”})· 等同于@SuppressWarnings(“unchecked”, “deprecation”) 案例 @Entity : 映射数据库实体类 @Table(name =”S_PRODUCEINFO”) : 表名为 “S_PRODUCEINFO” @Id : 声明主键ID @Column(name =”app_name”, unique =true, length = 50) :对应数据库字段,属性 @Enumerated(EnumType.STRING) : 采用枚举值类型和数据库字段进行交互 @Temporal : 时间格式映射数据库会得到规定时间格式的日期 @Enumerted(EnumType.STRING) HH:MM:SS 格式的日期 @Enumerted(EnumType.DATE) 获取年月日 yyyy-MM-dd @Enumerted(EnumType.TIME) 获取时分秒 HH:MM:SS https://blog.csdn.net/wufaliang003/article/details/77662523]]></content>
  </entry>
  <entry>
    <title><![CDATA[spring-session简介、使用及实现原理]]></title>
    <url>%2F2018%2F04%2F06%2Fspring-session%E7%AE%80%E4%BB%8B%E3%80%81%E4%BD%BF%E7%94%A8%E5%8F%8A%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[一：spring-session 介绍1.简介session一直都是我们做集群时需要解决的一个难题，过去我们可以从serlvet容器上解决，比如开源servlet容器-tomcat提供的tomcat-redis-session-manager、memcached-session-manager。或者通过nginx之类的负载均衡做ip_hash，路由到特定的服务器上..但是这两种办法都存在弊端。 1spring-session是spring旗下的一个项目，把servlet容器实现的httpSession替换为spring-session，专注于解决 session管理问题。可简单快速且无缝的集成到我们的应用中。 2.支持功能1）轻易把session存储到第三方存储容器，框架提供了redis、jvm的map、mongo、gemfire、hazelcast、jdbc等多种存储session的容器的方式。2）同一个浏览器同一个网站，支持多个session问题。3）Restful API，不依赖于cookie。可通过header来传递jessionID4）WebSocket和spring-session结合，同步生命周期管理。 3.集成方式集成方式非常简单，直接看官网的samples and guide 。http://docs.spring.io/spring-session/docs/1.3.0.RELEASE/reference/html5/主要分为以下几个集成步骤：1）引入依赖jar包2）注解方式或者 xml方式配置 特定存储容器的存储方式，如redis的xml配置方式 12345&lt;context:annotation-config/&gt; /** 初始化一切spring-session准备，且把springSessionFilter放入IOC **/&lt;beanclass=&quot;org.springframework.session.data.redis.config.annotation.web.http.RedisHttpSessionConfiguration&quot;/&gt; /** 这是存储容器的链接池 **/ &lt;beanclass=&quot;org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory&quot;/&gt;12345 12 3）xml方式配置 web.xml ，配置 springSessionFilter到 filter chain中12 123456789&lt;filter&gt; &lt;filter-name&gt;springSessionRepositoryFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.DelegatingFilterProxy&lt;/filter-class&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;springSessionRepositoryFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;dispatcher&gt;REQUEST&lt;/dispatcher&gt;&lt;dispatcher&gt;ERROR&lt;/dispatcher&gt; &lt;/filter-mapping&gt;123456789 二：spring-session框架内部剖析1.框架高层抽象结构图 2.spring-session重写servlet request 及 redis实现存储相关问题 spring-session无缝替换应用服务器的request大概原理是：1.自定义个Filter，实现doFilter方法2.继承 HttpServletRequestWrapper 、HttpServletResponseWrapper 类，重写getSession等相关方法(在这些方法里调用相关的 session存储容器操作类)。3.在 第一步的doFilter中，new 第二步 自定义的request和response的类。并把它们分别传递 到 过滤器链4.把该filter配置到 过滤器链的第一个位置上 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330/** 这个类是spring-session的1.30源码，也是实现上面第一到第三步的关键类 **/public class SessionRepositoryFilter&lt;S extends ExpiringSession&gt; extends OncePerRequestFilter &#123; /** session存储容器接口，redis、mongoDB、genfire等数据库都是实现该接口 **/ private final SessionRepository&lt;S&gt; sessionRepository; private ServletContext servletContext; /** sessionID的传递方式接口。目前spring-session自带两个实现类 1.cookie方式 ：CookieHttpSessionStrategy 2.http header 方式：HeaderHttpSessionStrategy 当然，我们也可以自定义其他方式。 **/ private MultiHttpSessionStrategy httpSessionStrategy = new CookieHttpSessionStrategy(); public SessionRepositoryFilter(SessionRepository&lt;S&gt; sessionRepository) &#123; if (sessionRepository == null) &#123; throw new IllegalArgumentException("sessionRepository cannot be null"); &#125; this.sessionRepository = sessionRepository; &#125; public void setHttpSessionStrategy(HttpSessionStrategy httpSessionStrategy) &#123; if (httpSessionStrategy == null) &#123; throw new IllegalArgumentException("httpSessionStrategy cannot be null"); &#125; /** 通过前面的spring-session功能介绍，我们知道spring-session可以支持单浏览器多 session， 就是通过MultiHttpSessionStrategyAdapter来实现的。 每个浏览器拥有一个sessionID，但是这个sessionID拥有多个别名（根据浏览器的tab）。如： 别名1 sessionID 别名2 sessionID ... 而这个别名通过url来传递，这就是单浏览器多session原理了 **/ this.httpSessionStrategy = new MultiHttpSessionStrategyAdapter( httpSessionStrategy); &#125; public void setHttpSessionStrategy(MultiHttpSessionStrategy httpSessionStrategy) &#123; if (httpSessionStrategy == null) &#123; throw new IllegalArgumentException("httpSessionStrategy cannot be null"); &#125; this.httpSessionStrategy = httpSessionStrategy; &#125; /** 该方法相当于重写了doFilter，只是spring-session又做了多一层封装。 在这个方法里创建自定义的 request和response，然后传递到过滤器链filterChain **/ @Override protected void doFilterInternal(HttpServletRequest request, HttpServletResponse response, FilterChain filterChain) throws ServletException, IOException &#123; request.setAttribute(SESSION_REPOSITORY_ATTR, this.sessionRepository); /** spring-session重写的ServletRequest。这个类继承了HttpServletRequestWrapper **/ SessionRepositoryRequestWrapper wrappedRequest = new SessionRepositoryRequestWrapper( request, response, this.servletContext); SessionRepositoryResponseWrapper wrappedResponse = new SessionRepositoryResponseWrapper( wrappedRequest, response); HttpServletRequest strategyRequest = this.httpSessionStrategy .wrapRequest(wrappedRequest, wrappedResponse); HttpServletResponse strategyResponse = this.httpSessionStrategy .wrapResponse(wrappedRequest, wrappedResponse); try &#123; /** 传递自定义 request和response到链中,想象下如果 该spring-sessionFilter位于过滤器链的第一个，那么后续的Filter， 以及到达最后的控制层所获取的 request和response，是不是就是我们自定义的了？ **/ filterChain.doFilter(strategyRequest, strategyResponse); &#125; finally &#123; wrappedRequest.commitSession(); &#125; &#125; public void setServletContext(ServletContext servletContext) &#123; this.servletContext = servletContext; &#125; /** 这个就是Servlet response的重写类了 */ private final class SessionRepositoryResponseWrapper extends OnCommittedResponseWrapper &#123; private final SessionRepositoryRequestWrapper request; SessionRepositoryResponseWrapper(SessionRepositoryRequestWrapper request, HttpServletResponse response) &#123; super(response); if (request == null) &#123; throw new IllegalArgumentException("request cannot be null"); &#125; this.request = request; &#125; /** 这步是持久化session到存储容器，我们可能会在一个控制层里多次调用session的操作方法 如果我们每次对session的操作都持久化到存储容器，必定会带来性能的影响。比如redis 所以我们可以在整个控制层执行完毕了，response返回信息到浏览器时，才持久化session **/ @Override protected void onResponseCommitted() &#123; this.request.commitSession(); &#125; &#125; /** spring-session 的request重写类，这几乎是最重要的一个重写类。里面重写了获取getSession，Session等方法以及类 */ private final class SessionRepositoryRequestWrapper extends HttpServletRequestWrapper &#123; private Boolean requestedSessionIdValid; private boolean requestedSessionInvalidated; private final HttpServletResponse response; private final ServletContext servletContext; private SessionRepositoryRequestWrapper(HttpServletRequest request, HttpServletResponse response, ServletContext servletContext) &#123; super(request); this.response = response; this.servletContext = servletContext; &#125; /** * Uses the HttpSessionStrategy to write the session id to the response and * persist the Session. */ private void commitSession() &#123; HttpSessionWrapper wrappedSession = getCurrentSession(); if (wrappedSession == null) &#123; // session失效，删除cookie或者header if (isInvalidateClientSession()) &#123; SessionRepositoryFilter.this.httpSessionStrategy .onInvalidateSession(this, this.response); &#125; &#125; else &#123; S session = wrappedSession.getSession(); SessionRepositoryFilter.this.sessionRepository.save(session); if (!isRequestedSessionIdValid() || !session.getId().equals(getRequestedSessionId())) &#123; // 把cookie或者header写回给浏览器保存 SessionRepositoryFilter.this.httpSessionStrategy.onNewSession(session, this, this.response); &#125; &#125; &#125; @SuppressWarnings("unchecked") private HttpSessionWrapper getCurrentSession() &#123; return (HttpSessionWrapper) getAttribute(CURRENT_SESSION_ATTR); &#125; private void setCurrentSession(HttpSessionWrapper currentSession) &#123; if (currentSession == null) &#123; removeAttribute(CURRENT_SESSION_ATTR); &#125; else &#123; setAttribute(CURRENT_SESSION_ATTR, currentSession); &#125; &#125; @SuppressWarnings("unused") public String changeSessionId() &#123; HttpSession session = getSession(false); if (session == null) &#123; throw new IllegalStateException( "Cannot change session ID. There is no session associated with this request."); &#125; // eagerly get session attributes in case implementation lazily loads them Map&lt;String, Object&gt; attrs = new HashMap&lt;String, Object&gt;(); Enumeration&lt;String&gt; iAttrNames = session.getAttributeNames(); while (iAttrNames.hasMoreElements()) &#123; String attrName = iAttrNames.nextElement(); Object value = session.getAttribute(attrName); attrs.put(attrName, value); &#125; SessionRepositoryFilter.this.sessionRepository.delete(session.getId()); HttpSessionWrapper original = getCurrentSession(); setCurrentSession(null); HttpSessionWrapper newSession = getSession(); original.setSession(newSession.getSession()); newSession.setMaxInactiveInterval(session.getMaxInactiveInterval()); for (Map.Entry&lt;String, Object&gt; attr : attrs.entrySet()) &#123; String attrName = attr.getKey(); Object attrValue = attr.getValue(); newSession.setAttribute(attrName, attrValue); &#125; return newSession.getId(); &#125; // 判断session是否有效 @Override public boolean isRequestedSessionIdValid() &#123; if (this.requestedSessionIdValid == null) &#123; String sessionId = getRequestedSessionId(); S session = sessionId == null ? null : getSession(sessionId); return isRequestedSessionIdValid(session); &#125; return this.requestedSessionIdValid; &#125; private boolean isRequestedSessionIdValid(S session) &#123; if (this.requestedSessionIdValid == null) &#123; this.requestedSessionIdValid = session != null; &#125; return this.requestedSessionIdValid; &#125; private boolean isInvalidateClientSession() &#123; return getCurrentSession() == null &amp;&amp; this.requestedSessionInvalidated; &#125; private S getSession(String sessionId) &#123; // 从session存储容器中根据sessionID获取session S session = SessionRepositoryFilter.this.sessionRepository .getSession(sessionId); if (session == null) &#123; return null; &#125; // 设置sesison的最后访问时间，以防过期 session.setLastAccessedTime(System.currentTimeMillis()); return session; &#125; /** 这个方法是不是很熟悉，下面还有个getSession()才更加熟悉。没错，就是在这里重新获取session方法 **/ @Override public HttpSessionWrapper getSession(boolean create) &#123; //快速获取session，可以理解为一级缓存、二级缓存这种关系 HttpSessionWrapper currentSession = getCurrentSession(); if (currentSession != null) &#123; return currentSession; &#125; //从httpSessionStratge里面根据cookie或者header获取sessionID String requestedSessionId = getRequestedSessionId(); if (requestedSessionId != null &amp;&amp; getAttribute(INVALID_SESSION_ID_ATTR) == null) &#123; //从存储容器获取session以及设置当次初始化属性 S session = getSession(requestedSessionId); if (session != null) &#123; this.requestedSessionIdValid = true; currentSession = new HttpSessionWrapper(session, getServletContext()); currentSession.setNew(false); setCurrentSession(currentSession); return currentSession; &#125; else &#123; if (SESSION_LOGGER.isDebugEnabled()) &#123; SESSION_LOGGER.debug( "No session found by id: Caching result for getSession(false) for this HttpServletRequest."); &#125; setAttribute(INVALID_SESSION_ID_ATTR, "true"); &#125; &#125; if (!create) &#123; return null; &#125; if (SESSION_LOGGER.isDebugEnabled()) &#123; SESSION_LOGGER.debug( "A new session was created. To help you troubleshoot where the session was created we provided a StackTrace (this is not an error). You can prevent this from appearing by disabling DEBUG logging for " + SESSION_LOGGER_NAME, new RuntimeException( "For debugging purposes only (not an error)")); &#125; // 如果该浏览器或者其他http访问者是初次访问服务器，则为他创建个新的session S session = SessionRepositoryFilter.this.sessionRepository.createSession(); session.setLastAccessedTime(System.currentTimeMillis()); currentSession = new HttpSessionWrapper(session, getServletContext()); setCurrentSession(currentSession); return currentSession; &#125; @Override public ServletContext getServletContext() &#123; if (this.servletContext != null) &#123; return this.servletContext; &#125; // Servlet 3.0+ return super.getServletContext(); &#125; @Override public HttpSessionWrapper getSession() &#123; return getSession(true); &#125; @Override public String getRequestedSessionId() &#123; return SessionRepositoryFilter.this.httpSessionStrategy .getRequestedSessionId(this); &#125; /** HttpSession的重写类 */ private final class HttpSessionWrapper extends ExpiringSessionHttpSession&lt;S&gt; &#123; HttpSessionWrapper(S session, ServletContext servletContext) &#123; super(session, servletContext); &#125; @Override public void invalidate() &#123; super.invalidate(); SessionRepositoryRequestWrapper.this.requestedSessionInvalidated = true; setCurrentSession(null); SessionRepositoryFilter.this.sessionRepository.delete(getId()); &#125; &#125; &#125;&#125; Redis存储容器实现。主要实现存储公共基础类-&gt;FindByIndexNameSessionRepository ,里面主要有根据indexName从redis中查找session、根据sessionID对redis中的session增删改查的方法。关于redis的session存储容器，实际上spring-session是有些缺陷的。比如无法做到session的过期以及销毁的实时发布事件，以及getCurrentSession中可能存在的一些并发问题（小问题）。但整体来说还是可用性很高的，毕竟我们自己写一套这类框架成本很高。以上只是针对redis session的存储容器，其他存储容器可能会比redis更好，比如gemfire，至少在事件发布上是完整了 注意： 错误问题：NoSuchMethodError:redis.clients.jedis.JedisShardInfo.setTimeout(I)V #252答：This is more of a Spring Data Redis issue，Jedis 2.7.x changed the name of setTimeout. The Evans release(s) stick to jedis 2.6.x and therefore won’t work. DATAREDIS-374 fixed the issue for Fowler aka spring-data-redis:1.5.0.RELEASE。就是版本问题。若redis是高版本，则spring-session、spring-data-redis也要使用高版本的。目前我redis使用2.8，spring-session使用1.2.0.RELEASE，spring-data-redis使用1.7.1.RELEASE 问题二： 如果要设置Session的过期时间，通常我们会在web.xml文件中进行设置： 但是，使用Spring Session托管session后，这里的设置将会失效。我们要专门为Spring Session进行设置： 将application-context.xml，即步骤4中的的RedisHttpSessionConfiguration，设置其maxInactiveIntervalInSeconds属性即可。注意，maxInactiveIntervalInSeconds的的单位是秒！ 如下将设置session为10分钟过期！ [html] view plain copy 123&lt;bean id="redisHttpSessionConfiguration" class="org.springframework.session.data.redis.config.annotation.web.http.RedisHttpSessionConfiguration"&gt; &lt;property name="maxInactiveIntervalInSeconds" value="600" /&gt; &lt;/bean&gt; 问题三： 需要注意的就是redis需要2.8以上版本，然后开启事件通知，在redis配置文件里面加上 [html] view plain copy notify-keyspace-events Ex Keyspace notifications功能默认是关闭的（默认地，Keyspace 时间通知功能是禁用的，因为它或多或少会使用一些CPU的资源）。 或是使用如下命令： [xml] view plain copy redis-cli config set notify-keyspace-events Egx 如果你的Redis不是你自己维护的，比如你是使用阿里云的Redis数据库，你不能够更改它的配置，那么可以使用如下方法：在applicationContext.xml中配置 [html] view plain copy &lt;util:constant static-field=”org.springframework.session.data.redis.config.ConfigureRedisAction.NO_OP”/&gt; 备注： applicationContext.xml完整配置如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566&lt;?xml version="1.0" encoding="utf-8"?&gt; &lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:aop="http://www.springframework.org/schema/aop" xmlns:tx="http://www.springframework.org/schema/tx" xmlns:jdbc="http://www.springframework.org/schema/jdbc" xmlns:context="http://www.springframework.org/schema/context" xmlns:util="http://www.springframework.org/schema/util" xsi:schemaLocation=" http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-3.2.xsd http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.2.xsd http://www.springframework.org/schema/jdbc http://www.springframework.org/schema/jdbc/spring-jdbc-3.3.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-3.2.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-3.2.xsd http://www.springframework.org/schema/util http://www.springframework.org/schema/util/spring-util.xsd"&gt; &lt;context:component-scan base-package="com.whitetile"&gt; &lt;context:exclude-filter type="annotation" expression="org.springframework.stereotype.Controller"/&gt; &lt;/context:component-scan&gt; &lt;bean id="propertyConfigurer" class="org.springframework.beans.factory.config.PropertyPlaceholderConfigurer"&gt; &lt;property name="locations"&gt; &lt;list&gt; &lt;value&gt;classpath:redis_$&#123;deployType&#125;.properties&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;/bean&gt; &lt;!-- redis --&gt; &lt;bean id="jedisPoolConfig" class="redis.clients.jedis.JedisPoolConfig"&gt; &lt;property name="maxTotal" value="500" /&gt; &lt;property name="maxIdle" value="256" /&gt; &lt;property name="maxWaitMillis" value="10000" /&gt; &lt;property name="testOnBorrow" value="true" /&gt; &lt;property name="testOnReturn" value="false" /&gt; &lt;/bean&gt; &lt;bean id="jedisConnectionFactory" class="org.springframework.data.redis.connection.jedis.JedisConnectionFactory"&gt; &lt;property name="hostName" value="$&#123;os.write.redis.ip&#125;" /&gt; &lt;property name="port" value="$&#123;os.write.redis.port&#125;" /&gt; &lt;property name="timeout" value="2000" /&gt; &lt;property name="poolConfig" ref="jedisPoolConfig" /&gt; &lt;property name="usePool" value="true" /&gt; &lt;/bean&gt; &lt;bean id="redisTemplate" class="org.springframework.data.redis.core.StringRedisTemplate"&gt; &lt;property name="connectionFactory" ref="jedisConnectionFactory" /&gt; &lt;/bean&gt; &lt;!-- 将session放入redis --&gt; &lt;bean id="redisHttpSessionConfiguration" class="org.springframework.session.data.redis.config.annotation.web.http.RedisHttpSessionConfiguration"&gt; &lt;property name="maxInactiveIntervalInSeconds" value="172800" /&gt; &lt;/bean&gt; &lt;util:constant static-field="org.springframework.session.data.redis.config.ConfigureRedisAction.NO_OP"/&gt; &lt;!-- &lt;bean class="org.springframework.session.data.redis.config.annotation.web.http.RedisHttpSessionConfiguration"/&gt; &lt;bean class="org.springframework.data.redis.connection.jedis.JedisConnectionFactory"&gt; redis 配置 &lt;property name="hostName" value="10.60.81.32"/&gt; &lt;property name="port" value="6379"/&gt; &lt;/bean&gt; --&gt; &lt;import resource="classpath*:spring/datasource-mysql-$&#123;deployType&#125;.xml" /&gt; &lt;/beans&gt;]]></content>
  </entry>
  <entry>
    <title><![CDATA[Redis学习笔记——分布式锁的正确实现方式]]></title>
    <url>%2F2018%2F04%2F02%2FRedis%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E2%80%94%E2%80%94%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E7%9A%84%E6%AD%A3%E7%A1%AE%E5%AE%9E%E7%8E%B0%E6%96%B9%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[分布式锁一般有三种实现方式：1. 数据库乐观锁；2. 基于Redis的分布式锁；3. 基于ZooKeeper的分布式锁。本篇博客将介绍第二种方式，基于Redis实现分布式锁。虽然网上已经有各种介绍Redis分布式锁实现的博客，然而他们的实现却有着各种各样的问题，为了避免误人子弟，本篇博客将详细介绍如何正确地实现Redis分布式锁。 可靠性 首先，为了确保分布式锁可用，我们至少要确保锁的实现同时满足以下四个条件： 互斥性。在任意时刻，只有一个客户端能持有锁。 不会发生死锁。即使有一个客户端在持有锁的期间崩溃而没有主动解锁，也能保证后续其他客户端能加锁。 具有容错性。只要大部分的Redis节点正常运行，客户端就可以加锁和解锁。 解铃还须系铃人。加锁和解锁必须是同一个客户端，客户端自己不能把别人加的锁给解了。 代码实现 组件依赖 首先我们要通过Maven引入Jedis开源组件，在pom.xml文件加入下面的代码： redis.clients jedis 2.9.0 加锁代码 正确姿势 Talk is cheap, show me the code。先展示代码，再带大家慢慢解释为什么这样实现： public class RedisTool { private static final String LOCK_SUCCESS = “OK”; private static final String SET_IF_NOT_EXIST = “NX”; private static final String SET_WITH_EXPIRE_TIME = “PX”; /** * 尝试获取分布式锁 * @param jedis Redis客户端 * @param lockKey 锁 * @param requestId 请求标识 * @param expireTime 超期时间 * @return 是否获取成功 */ public static boolean tryGetDistributedLock(Jedis jedis, String lockKey, String requestId,int expireTime) { String result = jedis.set(lockKey, requestId, SET_IF_NOT_EXIST, SET_WITH_EXPIRE_TIME, expireTime); if (LOCK_SUCCESS.equals(result)) { return true; } return false; } } 可以看到，我们加锁就一行代码：jedis.set(String key, String value, String nxxx, String expx, int time)，这个set()方法一共有五个形参： 第一个为key，我们使用key来当锁，因为key是唯一的。 第二个为value，我们传的是requestId，很多童鞋可能不明白，有key作为锁不就够了吗，为什么还要用到value？原因就是我们在上面讲到可靠性时，分布式锁要满足第四个条件解铃还须系铃人，通过给value赋值为requestId，我们就知道这把锁是哪个请求加的了，在解锁的时候就可以有依据。requestId可以使用UUID.randomUUID().toString()方法生成。 第三个为nxxx，这个参数我们填的是NX，意思是SET IF NOT EXIST，即当key不存在时，我们进行set操作；若key已经存在，则不做任何操作； 第四个为expx，这个参数我们传的是PX，意思是我们要给这个key加一个过期的设置，具体时间由第五个参数决定。 第五个为time，与第四个参数相呼应，代表key的过期时间。 总的来说，执行上面的set()方法就只会导致两种结果：1. 当前没有锁（key不存在），那么就进行加锁操作，并对锁设置个有效期，同时value表示加锁的客户端。2. 已有锁存在，不做任何操作。 心细的童鞋就会发现了，我们的加锁代码满足我们可靠性里描述的三个条件。首先，set()加入了NX参数，可以保证如果已有key存在，则函数不会调用成功，也就是只有一个客户端能持有锁，满足互斥性。其次，由于我们对锁设置了过期时间，即使锁的持有者后续发生崩溃而没有解锁，锁也会因为到了过期时间而自动解锁（即key被删除），不会发生死锁。最后，因为我们将value赋值为requestId，代表加锁的客户端请求标识，那么在客户端在解锁的时候就可以进行校验是否是同一个客户端。由于我们只考虑Redis单机部署的场景，所以容错性我们暂不考虑。 错误示例1 比较常见的错误示例就是使用jedis.setnx()和jedis.expire()组合实现加锁，代码如下： public static void wrongGetLock1(Jedis jedis, String lockKey, String requestId, intexpireTime) { Long result = jedis.setnx(lockKey, requestId); if (result == 1) { // 若在这里程序突然崩溃，则无法设置过期时间，将发生死锁 jedis.expire(lockKey, expireTime); } } setnx()方法作用就是SET IF NOT EXIST，expire()方法就是给锁加一个过期时间。乍一看好像和前面的set()方法结果一样，然而由于这是两条Redis命令，不具有原子性，如果程序在执行完setnx()之后突然崩溃，导致锁没有设置过期时间。那么将会发生死锁。网上之所以有人这样实现，是因为低版本的jedis并不支持多参数的set()方法。 错误示例2 这一种错误示例就比较难以发现问题，而且实现也比较复杂。实现思路：使用jedis.setnx()命令实现加锁，其中key是锁，value是锁的过期时间。执行过程：1. 通过setnx()方法尝试加锁，如果当前锁不存在，返回加锁成功。2. 如果锁已经存在则获取锁的过期时间，和当前时间比较，如果锁已经过期，则设置新的过期时间，返回加锁成功。代码如下： public static boolean wrongGetLock2(Jedis jedis, String lockKey, int expireTime) { long expires = System.currentTimeMillis() + expireTime; String expiresStr = String.valueOf(expires); // 如果当前锁不存在，返回加锁成功 if (jedis.setnx(lockKey, expiresStr) == 1) { return true; } // 如果锁存在，获取锁的过期时间 String currentValueStr = jedis.get(lockKey); if (currentValueStr != null &amp;&amp; Long.parseLong(currentValueStr) &lt; System.currentTimeMillis()) { // 锁已过期，获取上一个锁的过期时间，并设置现在锁的过期时间 String oldValueStr = jedis.getSet(lockKey, expiresStr); if (oldValueStr != null &amp;&amp; oldValueStr.equals(currentValueStr)) { // 考虑多线程并发的情况，只有一个线程的设置值和当前值相同，它才有权利加锁 return true; } } // 其他情况，一律返回加锁失败 return false; } 那么这段代码问题在哪里？1. 由于是客户端自己生成过期时间，所以需要强制要求分布式下每个客户端的时间必须同步。 2. 当锁过期的时候，如果多个客户端同时执行jedis.getSet()方法，那么虽然最终只有一个客户端可以加锁，但是这个客户端的锁的过期时间可能被其他客户端覆盖。3. 锁不具备拥有者标识，即任何客户端都可以解锁。 解锁代码 正确姿势 还是先展示代码，再带大家慢慢解释为什么这样实现： public class RedisTool { private static final Long RELEASE_SUCCESS = 1L; /** * 释放分布式锁 * @param jedis Redis客户端 * @param lockKey 锁 * @param requestId 请求标识 * @return 是否释放成功 */ public static boolean releaseDistributedLock(Jedis jedis, String lockKey, String requestId) { String script = “if redis.call(‘get’, KEYS[1]) == ARGV[1] then return redis.call(‘del’, KEYS[1]) else return 0 end”; Object result = jedis.eval(script, Collections.singletonList(lockKey), Collections.singletonList(requestId)); if (RELEASE_SUCCESS.equals(result)) { return true; } return false; } } 可以看到，我们解锁只需要两行代码就搞定了！第一行代码，我们写了一个简单的Lua脚本代码，上一次见到这个编程语言还是在《黑客与画家》里，没想到这次居然用上了。第二行代码，我们将Lua代码传到jedis.eval()方法里，并使参数KEYS[1]赋值为lockKey，ARGV[1]赋值为requestId。eval()方法是将Lua代码交给Redis服务端执行。 那么这段Lua代码的功能是什么呢？其实很简单，首先获取锁对应的value值，检查是否与requestId相等，如果相等则删除锁（解锁）。那么为什么要使用Lua语言来实现呢？因为要确保上述操作是原子性的。关于非原子性会带来什么问题，可以阅读【解锁代码-错误示例2】 。那么为什么执行eval()方法可以确保原子性，源于Redis的特性，下面是官网对eval命令的部分解释： 简单来说，就是在eval命令执行Lua代码的时候，Lua代码将被当成一个命令去执行，并且直到eval命令执行完成，Redis才会执行其他命令。 错误示例1 最常见的解锁代码就是直接使用jedis.del()方法删除锁，这种不先判断锁的拥有者而直接解锁的方式，会导致任何客户端都可以随时进行解锁，即使这把锁不是它的。 public static void wrongReleaseLock1(Jedis jedis, String lockKey) { jedis.del(lockKey); } 错误示例2 这种解锁代码乍一看也是没问题，甚至我之前也差点这样实现，与正确姿势差不多，唯一区别的是分成两条命令去执行，代码如下： public static void wrongReleaseLock2(Jedis jedis, String lockKey, String requestId) { // 判断加锁与解锁是不是同一个客户端 if (requestId.equals(jedis.get(lockKey))) { // 若在此时，这把锁突然不是这个客户端的，则会误解锁 jedis.del(lockKey); } } 如代码注释，问题在于如果调用jedis.del()方法的时候，这把锁已经不属于当前客户端的时候会解除他人加的锁。那么是否真的有这种场景？答案是肯定的，比如客户端A加锁，一段时间之后客户端A解锁，在执行jedis.del()之前，锁突然过期了，此时客户端B尝试加锁成功，然后客户端A再执行del()方法，则将客户端B的锁给解除了。 总结 本文主要介绍了如何使用Java代码正确实现Redis分布式锁，对于加锁和解锁也分别给出了两个比较经典的错误示例。其实想要通过Redis实现分布式锁并不难，只要保证能满足可靠性里的四个条件。互联网虽然给我们带来了方便，只要有问题就可以google，然而网上的答案一定是对的吗？其实不然，所以我们更应该时刻保持着质疑精神，多想多验证。 如果你的项目中Redis是多机部署的，那么可以尝试使用Redisson实现分布式锁，这是Redis官方提供的Java组件，链接在参考阅读章节已经给出。 参考阅读 Distributed locks with Redis EVAL command Redisson 原文 ：https://www.jianshu.com/p/6ae15854ed3b]]></content>
  </entry>
  <entry>
    <title><![CDATA[Redis学习笔记——redis的事务和watch]]></title>
    <url>%2F2018%2F04%2F02%2FRedis%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E2%80%94%E2%80%94redis%E7%9A%84%E4%BA%8B%E5%8A%A1%E5%92%8Cwatch%2F</url>
    <content type="text"><![CDATA[redis的事务严格意义来讲,redis的事务和我们理解的传统数据库(如mysql)的事务是不一样的。 redis中的事务定义Redis中的事务（transaction）是一组命令的集合。 事务同命令一样都是Redis的最小执行单位，一个事务中的命令要么都执行，要么都不执行。事务的原理是先将属于一个事务的命令发送给Redis，然后再让Redis依次执行这些命令。 Redis保证一个事务中的所有命令要么都执行，要么都不执行。如果在发送EXEC命令前客户端断线了，则Redis会清空事务队列，事务中的所有命令都不会执行。而一旦客户端发送了EXEC命令，所有的命令就都会被执行，即使此后客户端断线也没关系，因为Redis中已经记录了所有要执行的命令。 除此之外，Redis的事务还能保证一个事务内的命令依次执行而不被其他命令插入。试想客户端A需要执行几条命令，同时客户端B发送了一条命令，如果不使用事务，则客户端B的命令可能会插入到客户端A的几条命令中执行。如果不希望发生这种情况，也可以使用事务。 事务的应用 事务的应用非常普遍，如银行转账过程中A给B汇款，首先系统从A的账户中将钱划走，然后向B的账户增加相应的金额。这两个步骤必须属于同一个事务，要么全执行，要么全不执行。否则只执行第一步，钱就凭空消失了，这显然让人无法接受。 和传统的事务不同 和传统的mysql事务不同的事，即使我们的加钱操作失败,我们也无法在这一组命令中让整个状态回滚到操作之前 事务的错误处理如果一个事务中的某个命令执行出错，Redis会怎样处理呢？要回答这个问题，首先需要知道什么原因会导致命令执行出错。 语法错误语法错误指命令不存在或者命令参数的个数不对。比如： 12345678910redis＞MULTIOKredis＞SET key valueQUEUEDredis＞SET key(error)ERR wrong number of arguments for &apos;set&apos; commandredis＞ errorCOMMAND key(error) ERR unknown command &apos;errorCOMMAND&apos;redis＞ EXEC(error) EXECABORT Transaction discarded because of previous errors. 跟在MULTI命令后执行了3个命令：一个是正确的命令，成功地加入事务队列；其余两个命令都有语法错误。而只要有一个命令有语法错误，执行EXEC命令后Redis就会直接返回错误，连语法正确的命令也不会执行。 这里需要注意一点：Redis 2.6.5之前的版本会忽略有语法错误的命令，然后执行事务中其他语法正确的命令。就此例而言，SET key value会被执行，EXEC命令会返回一个结果：1) OK。 运行错误运行错误指在命令执行时出现的错误，比如使用散列类型的命令操作集合类型的键，这种错误在实际执行之前Redis是无法发现的，所以在事务里这样的命令是会被Redis接受并执行的。如果事务里的一条命令出现了运行错误，事务里其他的命令依然会继续执行（包括出错命令之后的命令），示例如下： 1234567891011121314redis＞MULTIOKredis＞SET key 1QUEUEDredis＞SADD key 2QUEUEDredis＞SET key 3QUEUEDredis＞EXEC1) OK2) (error) ERR Operation against a key holding the wrong kind of value3) OKredis＞GET key&quot;3&quot; 可见虽然SADD key 2出现了错误，但是SET key 3依然执行了。 Redis的事务没有关系数据库事务提供的回滚（rollback）功能。为此开发者必须在事务执行出错后自己收拾剩下的摊子（将数据库复原回事务执行前的状态等,这里我们一般采取日志记录然后业务补偿的方式来处理，但是一般情况下，在redis做的操作不应该有这种强一致性要求的需求，我们认为这种需求为不合理的设计）。 Watch命令大家可能知道redis提供了基于incr命令来操作一个整数型数值的原子递增，那么我们假设如果redis没有这个incr命令，我们该怎么实现这个incr的操作呢？ 那么我们下面的正主watch就要上场了。 如何使用watch命令正常情况下我们想要对一个整形数值做修改是这么做的(伪代码实现)： 123val = GET mykeyval = val + 1SET mykey $val 但是上述的代码会出现一个问题,因为上面吧正常的一个incr(原子递增操作)分为了两部分,那么在多线程(分布式)环境中，这个操作就有可能不再具有原子性了。 研究过java的juc包的人应该都知道cas，那么redis也提供了这样的一个机制，就是利用watch命令来实现的。 watch命令描述 WATCH命令可以监控一个或多个键，一旦其中有一个键被修改（或删除），之后的事务就不会执行。监控一直持续到EXEC命令（事务中的命令是在EXEC之后才执行的，所以在MULTI命令后可以修改WATCH监控的键值） 利用watch实现incr具体做法如下: 123456WATCH mykeyval = GET mykeyval = val + 1MULTISET mykey $valEXEC 和此前代码不同的是，新代码在获取mykey的值之前先通过WATCH命令监控了该键，此后又将set命令包围在事务中，这样就可以有效的保证每个连接在执行EXEC之前，如果当前连接获取的mykey的值被其它连接的客户端修改，那么当前连接的EXEC命令将执行失败。这样调用者在判断返回值后就可以获悉val是否被重新设置成功。 注意点由于WATCH命令的作用只是当被监控的键值被修改后阻止之后一个事务的执行，而不能保证其他客户端不修改这一键值，所以在一般的情况下我们需要在EXEC执行失败后重新执行整个函数。 执行EXEC命令后会取消对所有键的监控，如果不想执行事务中的命令也可以使用UNWATCH命令来取消监控。 实现一个hsetNX函数我们实现的hsetNX这个功能是：仅当字段存在时才赋值。 为了避免竞态条件我们使用watch和事务来完成这一功能（伪代码）： 123456789WATCH key isFieldExists = HEXISTS key, field if isFieldExists is 1 MULTI HSET key, field, value EXEC else UNWATCH return isFieldExists 在代码中会判断要赋值的字段是否存在，如果字段不存在的话就不执行事务中的命令，但需要使用UNWATCH命令来保证下一个事务的执行不会受到影响。]]></content>
  </entry>
  <entry>
    <title><![CDATA[UML各种图总结-精华]]></title>
    <url>%2F2018%2F03%2F30%2FUML%E5%90%84%E7%A7%8D%E5%9B%BE%E6%80%BB%E7%BB%93-%E7%B2%BE%E5%8D%8E%2F</url>
    <content type="text"><![CDATA[UML（Unified Modeling Language）是一种统一建模语言，为面向对象开发系统的产品进行说明、可视化、和编制文档的一种标准语言。下面将对UML的九种图+包图的基本概念进行介绍以及各个图的使用场景。 一、基本概念 如下图所示，UML图分为用例视图、设计视图、进程视图、实现视图和拓扑视图，又可以静动分为静态视图和动态视图。静态图分为：用例图，类图，对象图，包图，构件图，部署图。动态图分为：状态图，活动图，协作图，序列图。 1、用例图（UseCase Diagrams）： 用例图主要回答了两个问题：1、是谁用软件。2、软件的功能。从用户的角度描述了系统的功能，并指出各个功能的执行者，强调用户的使用者，系统为执行者完成哪些功能。 2、类图（Class Diagrams）： 用户根据用例图抽象成类，描述类的内部结构和类与类之间的关系，是一种静态结构图。 在UML类图中，常见的有以下几种关系: 泛化（Generalization）, 实现（Realization），关联（Association)，聚合（Aggregation），组合(Composition)，依赖(Dependency)。 各种关系的强弱顺序： 泛化 = 实现 &gt; 组合 &gt; 聚合 &gt; 关联 &gt; 依赖 2.1.泛化 【泛化关系】：是一种继承关系，表示一般与特殊的关系，它指定了子类如何继承父类的所有特征和行为。例如：老虎是动物的一种，即有老虎的特性也有动物的共性。 2.2.实现 【实现关系】：是一种类与接口的关系，表示类是接口所有特征和行为的实现。 2.3.关联 【关联关系】：是一种拥有的关系，它使一个类知道另一个类的属性和方法；如：老师与学生，丈夫与妻子关联可以是双向的，也可以是单向的。双向的关联可以有两个箭头或者没有箭头，单向的关联有一个箭头。 ​ 【代码体现】：成员变量 2.4.聚合 【聚合关系】：是整体与部分的关系，且部分可以离开整体而单独存在。如车和轮胎是整体和部分的关系，轮胎离开车仍然可以存在。 ​ 聚合关系是关联关系的一种，是强的关联关系；关联和聚合在语法上无法区分，必须考察具体的逻辑关系。 ​ 【代码体现】：成员变量 2.5.组合 【组合关系】：是整体与部分的关系，但部分不能离开整体而单独存在。如公司和部门是整体和部分的关系，没有公司就不存在部门。 ​ 组合关系是关联关系的一种，是比聚合关系还要强的关系，它要求普通的聚合关系中代表整体的对象负责代表部分的对象的生命周期。 【代码体现】：成员变量 【箭头及指向】：带实心菱形的实线，菱形指向整体 2.6.依赖 【依赖关系】：是一种使用的关系，即一个类的实现需要另一个类的协助，所以要尽量不使用双向的互相依赖. ​ 【代码表现】：局部变量、方法的参数或者对静态方法的调用 ​ 【箭头及指向】：带箭头的虚线，指向被使用者 2.7 各种类图关系 3、对象图（Object Diagrams）: 描述的是参与交互的各个对象在交互过程中某一时刻的状态。对象图可以被看作是类图在某一时刻的实例。 4、状态图（Statechart Diagrams）： 是一种由状态、变迁、事件和活动组成的状态机，用来描述类的对象所有可能的状态以及时间发生时状态的转移条件。 5、活动图（Activity Diagrams）： 是状态图的一种特殊情况，这些状态大都处于活动状态。本质是一种流程图，它描述了活动到活动的控制流。 交互图强调的是对象到对象的控制流，而活动图则强调的是从活动到活动的控制流。 活动图是一种表述过程基理、业务过程以及工作流的技术。 它可以用来对业务过程、工作流建模，也可以对用例实现甚至是程序实现来建模。 5.1 带泳道的活动图 泳道表明每个活动是由哪些人或哪些部门负责完成。 5.2 带对象流的活动图 用活动图描述某个对象时，可以把涉及到的对象放置在活动图中，并用一个依赖将其连接到进行创建、修改和撤销的动作状态或者活动状态上，对象的这种使用方法就构成了对象流。对象流用带有箭头的虚线表示。 6、序列图-时序图（Sequence Diagrams）： 交互图的一种，描述了对象之间消息发送的先后顺序，强调时间顺序。 序列图的主要用途是把用例表达的需求，转化为进一步、更加正式层次的精细表达。用例常常被细化为一个或者更多的序列图。同时序列图更有效地描述如何分配各个类的职责以及各类具有相应职责的原因。 消息用从一个对象的生命线到另一个对象生命线的箭头表示。箭头以时间顺序在图中从上到下排列。 序列图中涉及的元素： 6.1 生命线 生命线名称可带下划线。当使用下划线时，意味着序列图中的生命线代表一个类的特定实例。 6.2 同步消息 同步等待消息 6.3 异步消息 异步发送消息，不需等待 6.4 注释 6.5 约束 6.6 组合 组合片段**用来解决交互执行的条件及方式**。它允许在序列图中直接表示逻辑组件，用于通过指定条件或子进程的应用区域，为任何生命线的任何部分定义特殊条件和子进程。常用的组合片段有：抉择、选项、循环、并行。 7、协作图（Collaboration Diagrams）： 交互图的一种，描述了收发消息的对象的组织关系，强调对象之间的合作关系。时序图按照时间顺序布图，而写作图按照空间结构布图 8、构件图（Component Diagrams）： 构件图是用来表示系统中构件与构件之间，类或接口与构件之间的关系图。其中，构建图之间的关系表现为依赖关系，定义的类或接口与类之间的关系表现为依赖关系或实现关系。 9、部署图（Deployment Diagrams）： 描述了系统运行时进行处理的结点以及在结点上活动的构件的配置。强调了物理设备以及之间的连接关系。 部署模型的目的： 描述一个具体应用的主要部署结构，通过对各种硬件，在硬件中的软件以及各种连接协议的显示，可以很好的描述系统是如何部署的；平衡系统运行时的计算资源分布；可以通过连接描述组织的硬件网络结构或者是嵌入式系统等具有多种硬件和软件相关的系统运行模型。 二、图的差异比较 1.序列图(时序图)VS协作图 ​ 序列图和协作图都是交互图。二者在语义上等价，可以相互转化。但是侧重点不同：序列图侧重时间顺序，协作图侧重对象间的关系。 共同点：时序图与协作图均显示了对象间的交互。 不同点：时序图强调交互的时间次序。 ​ 协作图强调交互的空间结构。 2.状态图VS活动图 ​ 状态图和活动图都是行为图。状态图侧重从行为的结果来描述，活动图侧重从行为的动作来描述。状态图描述了一个具体对象的可能状态以及他们之间的转换。在实际的项目中，活动图并不是必须的，需要满足以下条件：1、出现并行过程&amp;行为；2、描述算法；3、跨越多个用例的活动图。 3.活动图VS交互图 二者都涉及到对象和他们之间传递的关系。区别在于交互图观察的是传送消息的对象，而活动图观察的是对象之间传递的消息。看似语义相同，但是他们是从不同的角度来观察整个系统的。 三、UML与软件工程 UML图是软件工程的组成部分，软件工程从宏观的角度保证了软件开发的各个过程的质量。而UML作为一种建模语言，更加有效的实现了软件工程的要求。 如下图，在软件的各个开发阶段需要的UML图。 下表是UML使用人员图示： 源博客：https://www.cnblogs.com/jiangds/p/6596595.html]]></content>
  </entry>
  <entry>
    <title><![CDATA[为什么Java内部类要设计成静态和非静态两种]]></title>
    <url>%2F2018%2F03%2F29%2F%E4%B8%BA%E4%BB%80%E4%B9%88Java%E5%86%85%E9%83%A8%E7%B1%BB%E8%A6%81%E8%AE%BE%E8%AE%A1%E6%88%90%E9%9D%99%E6%80%81%E5%92%8C%E9%9D%9E%E9%9D%99%E6%80%81%E4%B8%A4%E7%A7%8D%2F</url>
    <content type="text"><![CDATA[​ 静态内部类的作用：只是为了降低包的深度，方便类的使用，静态内部类适用于包含类当中，但又不依赖与外在的类，不用使用外在类的非静态属性和方法，只是为了方便管理类结构而定义。在创建静态内部类的时候，不需要外部类对象的引用。非静态内部类有一个很大的优点：可以自由使用外部类的所有变量和方法。 ​ ——引自知乎 12345678910111213public class IdSeqDataSource &#123; private IdSeqDataSource() &#123; &#125; public static NamedParameterJdbcTemplate getWrite() &#123; return LazyHolder.WRITE; &#125; private static class LazyHolder &#123; private static final NamedParameterJdbcTemplate WRITE = DataSources.IdSeq.write(); &#125;&#125;]]></content>
  </entry>
  <entry>
    <title><![CDATA[Redis学习笔记——数据持久化]]></title>
    <url>%2F2018%2F03%2F28%2FRedis%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E2%80%94%E2%80%94%E6%95%B0%E6%8D%AE%E6%8C%81%E4%B9%85%E5%8C%96%2F</url>
    <content type="text"><![CDATA[一、概述 ​ Redis的强大性能很大程度上都是因为所有数据都是存储在内存中的，然而当Redis重启后，所有存储在内存中的数据将会丢失，在很多情况下是无法容忍这样的事情的。所以，我们需要将内存中的数据持久化！典型的需要持久化数据的场景如下： 将Redis作为数据库使用； 将Redis作为缓存服务器使用，但是缓存miss后会对性能造成很大影响，所有缓存同时失效时会造成服务雪崩，无法响应。 本文介绍Redis所支持的两种数据持久化方式。 二、Redis数据持久化 ​ Redis支持两种数据持久化方式：RDB方式和AOF方式。前者会根据配置的规则定时将内存中的数据持久化到硬盘上，后者则是在每次执行写命令之后将命令记录下来。两种持久化方式可以单独使用，但是通常会将两者结合使用。 1、RDB方式 ​ RDB方式的持久化是通过快照的方式完成的。当符合某种规则时，会将内存中的数据全量生成一份副本存储到硬盘上，这个过程称作”快照”，Redis会在以下几种情况下对数据进行快照： 根据配置规则进行自动快照； 用户执行SAVE, BGSAVE命令； 执行FLUSHALL命令； 执行复制（replication）时。 执行快照的场景 （1）根据配置自动快照 ​ Redis允许用户自定义快照条件，当满足条件时自动执行快照。缺省情况下，Redis把数据快照存放在磁盘上的二进制文件中，文件名为dump.rdb，此外，我们也可以通过配置文件来修改Redis服务器dump快照的频率，在打开redis.windows.conf文件之后，我们搜索save，可以看到下面的配置信息： 注意最后三行，分别表示： 在900秒(15分钟)之后，如果至少有1个key发生变化，则dump内存快照； 在300秒(5分钟)之后，如果至少有10个key发生变化，则dump内存快照； 在60秒(1分钟)之后，如果至少有10000个key发生变化，则dump内存快照。 ​ 每个快照条件独占一行，他们之间是或（||）关系，只要满足任何一个就进行快照。上面配置save后的第一个参数T是时间，单位是秒，第二个参数M是更改的键的个数，含义是：当时间T内被更改的键的个数大于M时，自动进行快照。比如save 900 1的含义是15分钟内(900s)被更改的键的个数大于1时，自动进行快照操作。 （2）执行SAVE或BGSAVE命令 除了让Redis自动进行快照外，当我们需要重启，迁移，备份Redis时，我们也可以手动执行SAVE或BGSAVE命令主动进行快照操作。 SAVE命令：当执行SAVE命令时，Redis同步进行快照操作，期间会阻塞所有来自客户端的请求，所以放数据库数据较多时，应该避免使用该命令； BGSAVE命令： 从命令名字就能看出来，这个命令与SAVE命令的区别就在于该命令的快照操作是在后台异步进行的，进行快照操作的同时还能处理来自客户端的请求。执行BGSAVE命令后Redis会马上返回OK表示开始进行快照操作，如果想知道快照操作是否已经完成，可以使用LASTSAVE命令返回最近一次成功执行快照的时间，返回结果是一个Unix时间戳。 （3）执行FLUSHALL命令 ​ 当执行FLUSHALL命令时，Redis会清除数据库中的所有数据。需要注意的是：不论清空数据库的过程是否触发了自动快照的条件，只要自动快照条件不为空，Redis就会执行一次快照操作，当没有定义自动快照条件时，执行FLUSHALL命令不会进行快照操作。 （4）执行复制 当设置了主从模式时，Redis会在复制初始化时进行自动快照。 快照原理 ​ Redis默认会将快照文件存储在Redis当前进程的工作目录的dump.rdb文件中，可以通过配置文件中的dir和dbfilename两个参数分别指定快照文件的存储路径和文件名，默认的存储路径和文件名如下图所示： 快照执行的过程如下： （1）Redis使用fork函数复制一份当前进程（父进程）的副本（子进程）；（2）父进程继续处理来自客户端的请求，子进程开始将内存中的数据写入硬盘中的临时文件；（3）当子进程写完所有的数据后，用该临时文件替换旧的RDB文件，至此，一次快照操作完成。 需要注意的是： 在执行fork的时候操作系统（类Unix操作系统）会使用写时复制（copy-on-write）策略，即fork函数发生的一刻，父进程和子进程共享同一块内存数据，当父进程需要修改其中的某片数据（如执行写命令）时，操作系统会将该片数据复制一份以保证子进程不受影响，所以RDB文件存储的是执行fork操作那一刻的内存数据。所以RDB方式理论上是会存在丢数据的情况的(fork之后修改的的那些没有写进RDB文件)。 ​ 通过上述的介绍可以知道，快照进行时是不会修改RDB文件的，只有完成的时候才会用临时文件替换老的RDB文件，所以就保证任何时候RDB文件的都是完整的。这使得我们可以通过定时备份RDB文件来实现Redis数据的备份。RDB文件是经过压缩处理的二进制文件，所以占用的空间会小于内存中数据的大小，更有利于传输。 ​ Redis启动时会自动读取RDB快照文件，将数据从硬盘载入到内存，根据数量的不同，这个过程持续的时间也不尽相同，通常来讲，一个记录1000万个字符串类型键，大小为1GB的快照文件载入到内存需要20-30秒的时间。]]></content>
  </entry>
  <entry>
    <title><![CDATA[redis,memcached二者的区别是]]></title>
    <url>%2F2018%2F03%2F28%2FRedis%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E2%80%94%E2%80%94redis%26memcached%E4%BA%8C%E8%80%85%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[Memcached介绍 Memecached、memecached和memecache的区别： 其中首字母大写的Memcached，指的是Memcached服务器，就是独立运行Memcached的后台服务器，用于存储数据的“数据库”; 而memcached和memcache指的是Memcached的客户端。其中memcache是独立用php实现的，属于老旧的版本。而memcached是基于原生的c的libmemcached的扩展，更加完善，性能更高一些。 Memcached和Redis共同点和区别： 共同点 Memcache，Redis 都是内存数据库 区别 Redis中，并不是所有的数据都一直存储在内存中的，这是和Memcache相比一个最大的区别。 Redis在很多方面具备数据库的特征，或者说就是一个数据库系统，而Memcache只是简单的K/V缓存。 他们的扩展都需要做集群；实现方式：master-slave、Hash。 在100k以上的数据中，Memcache性能要高于Redis。 如果要说内存使用效率，使用简单的key-value存储的话，Memcached的内存利用率更高，而如果Redis采用hash结构来做key-value存储，由于其组合式的压缩，其内存利用率会高于Memcache。当然，这和你的应用场景和数据特性有关。 如果你对数据持久化和数据同步有所要求，那么推荐你选择Redis，因为这两个特性Memcache都不具备。redis通过master-slave机制，可以实时进行数据的同步复制，支持多级复制和增量复制（快照、AOF）：依赖快照进行持久化，aof增强了可靠性的同时，对性能有所影响。即使你只是希望在升级或者重启系统后缓存数据不会丢失，选择Redis也是明智的。 Redis和Memcache在写入性能上面差别不大，读取性能上面尤其是批量读取性能上面Memcache更强。 Memcache可以利用多核优势，单实例吞吐量极高，可以达到几十万QPS,适用于最大程度扛量 数据一致性（事务支持）： Memcache 在并发场景下，用cas保证一致性； redis事务支持比较弱，只能保证事务中的每个操作连续执行， redis单线程请求，所有命令串行执行，并发情况下不需要考虑数据一致性问题]]></content>
  </entry>
  <entry>
    <title><![CDATA[Redis学习笔记——redis的pub/Sub(订阅与发布)在java中的实践]]></title>
    <url>%2F2018%2F03%2F28%2FRedis%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E2%80%94%E2%80%94redis%E7%9A%84pub-Sub-%E8%AE%A2%E9%98%85%E4%B8%8E%E5%8F%91%E5%B8%83-%E5%9C%A8java%E4%B8%AD%E7%9A%84%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[1.什么是pub/subPub/Sub功能（means Publish, Subscribe）即发布及订阅功能。基于事件的系统中，Pub/Sub是目前广泛使用的通信模型，它采用事件作为基本的通信机制，提供大规模系统所要求的松散耦合的交互模式：订阅者(如客户端)以事件订阅的方式表达出它有兴趣接收的一个事件或一类事件；发布者(如服务器)可将订阅者感兴趣的事件随时通知相关订阅者。熟悉设计模式的朋友应该了解这与23种设计模式中的观察者模式极为相似。同样,Redis的pub/sub是一种消息通信模式，主要的目的是解除消息发布者和消息订阅者之间的耦合,Redis作为一个pub/sub的server,在订阅者和发布者之间起到了消息路由的功能。 2.Redis pub/sub的实现Redis通过publish和subscribe命令实现订阅和发布的功能。订阅者可以通过subscribe向redis server订阅自己感兴趣的消息类型。redis将信息类型称为通道(channel)。当发布者通过publish命令向redis server发送特定类型的信息时，订阅该消息类型的全部订阅者都会收到此消息。 客户端1订阅CCTV1: 123456127.0.0.1:6379&gt; subscribe CCTV1Reading messages... (press Ctrl-C to quit)1) &quot;subscribe&quot;2) &quot;CCTV1&quot;3) (integer) 1123456 客户端2订阅CCTV1和CCTV2: 12345678910127.0.0.1:6379&gt; subscribe CCTV1 CCTV2Reading messages... (press Ctrl-C to quit)1) &quot;subscribe&quot;2) &quot;CCTV1&quot;3) (integer) 11) &quot;subscribe&quot;2) &quot;CCTV2&quot;3) (integer) 212345678910 此时这两个客户端分别监听这指定的频道。现在另一个客户端向服务器推送了关于这两个频道的信息。 1234567891011127.0.0.1:6379&gt; publish CCTV1 &quot;cctv1 is good&quot;(integer) 2//返回2表示两个客户端接收了次消息。被接收到消息的客户端如下所示。1) &quot;message&quot;2) &quot;CCTV1&quot;3) &quot;cctv1 is good&quot;----1) &quot;message&quot;2) &quot;CCTV1&quot;3) &quot;cctv1 is good&quot;1234567891011 如上的订阅/发布也称订阅发布到频道(使用publish与subscribe命令)，此外还有订阅发布到模式(使用psubscribe来订阅一个模式) 订阅CCTV的全部频道 123456127.0.0.1:6379&gt; psubscribe CCTV*Reading messages... (press Ctrl-C to quit)1) &quot;psubscribe&quot;2) &quot;CCTV*&quot;3) (integer) 1123456 当依然先如上推送一个CCTV1的消息时，该客户端正常接收。 Pub/Sub在java中的实现: 导入Redis驱动: 123dependencies &#123; compile &apos;redis.clients:jedis:2.4.2&apos;&#125;123 Redis驱动包提供了一个抽象类:JedisPubSub…继承这个类就完成了对客户端对订阅的监听。示例代码: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class TestPubSub extends JedisPubSub &#123; @Override public void onMessage(String channel, String message) &#123; // TODO Auto-generated method stub System.out.println(channel + &quot;,&quot; + message); &#125; @Override public void onPMessage(String pattern, String channel, String message) &#123; // TODO Auto-generated method stub System.out.println(pattern + &quot;,&quot; + channel + &quot;,&quot; + message); &#125; @Override public void onSubscribe(String channel, int subscribedChannels) &#123; // TODO Auto-generated method stub System.out.println(&quot;onSubscribe: channel[&quot; + channel + &quot;],&quot; + &quot;subscribedChannels[&quot; + subscribedChannels + &quot;]&quot;); &#125; @Override public void onUnsubscribe(String channel, int subscribedChannels) &#123; // TODO Auto-generated method stub System.out.println( &quot;onUnsubscribe: channel[&quot; + channel + &quot;], &quot; + &quot;subscribedChannels[&quot; + subscribedChannels + &quot;]&quot;); &#125; @Override public void onPUnsubscribe(String pattern, int subscribedChannels) &#123; // TODO Auto-generated method stub System.out.println(&quot;onPUnsubscribe: pattern[&quot; + pattern + &quot;],&quot; + &quot;subscribedChannels[&quot; + subscribedChannels + &quot;]&quot;); &#125; @Override public void onPSubscribe(String pattern, int subscribedChannels) &#123; System.out.println(&quot;onPSubscribe: pattern[&quot; + pattern + &quot;], &quot; + &quot;subscribedChannels[&quot; + subscribedChannels + &quot;]&quot;); &#125;&#125;12345678910111213141516171819202122232425262728293031323334353637383940414243444546 如上所示,抽象类中存在六个方法。分别表示 监听到订阅模式接受到消息时的回调 (onPMessage) 监听到订阅频道接受到消息时的回调 (onMessage ) 订阅频道时的回调( onSubscribe ) 取消订阅频道时的回调( onUnsubscribe ) 订阅频道模式时的回调 ( onPSubscribe ) 取消订阅模式时的回调( onPUnsubscribe ) 运行我们刚刚编写的类: 123456789101112131415161718@Test public void pubsubjava() &#123; // TODO Auto-generated method stub Jedis jr = null; try &#123; jr = new Jedis(&quot;127.0.0.1&quot;, 6379, 0);// redis服务地址和端口号 jr.auth(&quot;wx950709&quot;); TestPubSub sp = new TestPubSub(); // jr客户端配置监听两个channel sp.subscribe(jr.getClient(), &quot;news.share&quot;, &quot;news.blog&quot;); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally&#123; if(jr!=null)&#123; jr.disconnect(); &#125; &#125; &#125;123456789101112131415161718 从代码中我们不难看出，我们声明的一个redis链接在设置监听后就可以执行一些操作，例如发布消息，订阅消息等。。。当运行上述代码后会在控制台输出: 123onSubscribe: channel[news.share],subscribedChannels[1]onSubscribe: channel[news.blog],subscribedChannels[2]//onSubscribe方法成功运行123 此时当在有客户端向new.share或者new.blog通道publish消息时，onMessage方法即可被相应。(jedis.publish(channel, message))。 Pub/Sub在Spring中的实践导入依赖jar 1234dependencies &#123; compile &apos;org.springframework.data:spring-data-redis:1.7.2.RELEASE&apos; compile &apos;redis.clients:jedis:2.4.2&apos;&#125;1234 Spring配置redis的链接: 12345678910111213141516171819202122232425262728293031323334353637383940414243@Configurationpublic class AppConfig &#123; @Bean JedisConnectionFactory jedisConnectionFactory() &#123; JedisConnectionFactory jedisConnectionFactory = new JedisConnectionFactory(); jedisConnectionFactory.setPassword(&quot;xxxx&quot;); return jedisConnectionFactory; &#125; @Bean RedisTemplate&lt;String, Object&gt; redisTemplate() &#123; final RedisTemplate&lt;String, Object&gt; template = new RedisTemplate&lt;String, Object&gt;(); template.setConnectionFactory(jedisConnectionFactory()); template.setDefaultSerializer(new StringRedisSerializer()); return template; &#125; @Bean MessageListenerAdapter messageListener() &#123; return new MessageListenerAdapter(new RedisMessageListener()); &#125; @Bean RedisMessageListenerContainer redisContainer() &#123; final RedisMessageListenerContainer container = new RedisMessageListenerContainer(); container.setConnectionFactory(jedisConnectionFactory()); container.addMessageListener(messageListener(), topic()); return container; &#125; @Bean RedisPublisherImpl redisPublisher() &#123; return new RedisPublisherImpl(redisTemplate(), topic()); &#125; @Bean ChannelTopic topic() &#123; return new ChannelTopic( &quot;pubsub:queue&quot; ); &#125;&#125;12345678910111213141516171819202122232425262728293031323334353637383940414243 如上的配置即配置了对Redis的链接。在RedisTemplate中没有设置ip端口等信息则全部为默认的。在配置类中的将ChannelTopic加入IOC容器。则在Spring启动时会在一个RedisTemplate(一个对Redis的链接)中设置的一个channel，即pubsub:queue。在上述配置中，RedisMessageListener是我们生成的，这个类即为核心监听类，RedisTemplate接受到数据如何处理就是在该类中处理的。 123456public class RedisMessageListener implements MessageListener &#123; @Override public void onMessage( final Message message, final byte[] pattern ) &#123; System.out.println(&quot;Message received: &quot; + message.toString() ); &#125;&#125;123456 现在我们在获取RedisTemplate,并给pubsub:queue这个channel publish数据。 123456789101112131415public class PubSubMain &#123; RedisTemplate&lt;String,Object&gt; redisTemplate; public void execute() &#123; String channel = &quot;pubsub:queue&quot;; redisTemplate.convertAndSend(channel, &quot;from testData&quot;); &#125; public static void main(String[] args) &#123; ApplicationContext applicationContext = new AnnotationConfigApplicationContext(AppConfig.class); PubSubMain pubSubMain = new PubSubMain(); pubSubMain.redisTemplate = (RedisTemplate&lt;String, Object&gt;) applicationContext.getBean(&quot;redisTemplate&quot;); pubSubMain.execute(); &#125;&#125;123456789101112131415 此时运行main 方法: 12Message received: from app 12//表明接受成功，当在命令行中启动一个客户端并publish时依然可以在客户端打印出message 转载于：https://blog.csdn.net/canot/article/details/51938955]]></content>
  </entry>
  <entry>
    <title><![CDATA[MAC下的Intellij IDEA常用快捷键]]></title>
    <url>%2F2018%2F03%2F27%2FMAC%E4%B8%8B%E7%9A%84Intellij-IDEA%E5%B8%B8%E7%94%A8%E5%BF%AB%E6%8D%B7%E9%94%AE%2F</url>
    <content type="text"><![CDATA[alt+f7 : 查找在哪里使用 相当于eclipse的ctrl+shift+G command+alt+f7 : 这个是查找选中的字符在工程中出现的地方，可以不是方法变量类等，这个和上面的有区别的 command＋F7 : 可以查询当前元素在当前文件中的引用，然后按F3可以选择 ，功能基本同上选中文本，按command+shift+F7 ，高亮显示所有该文本，按Esc高亮消失。选中文本，按Alt+F3 ，逐个往下查找相同文本，并高亮显示。 shift+f3 : 就是往上找 ctrl+enter : 出现生成get,set方法的界面 shift+enter : 换到下一行 command+N : 查找类 command+shift+N : 查找文件 command+R : 替换 ctrl+shift+R : 可以在整个工程或着某个目录下面替换变量 command+Y : 查看当前方法实现 command+D : 复制当前行到下一行 ctrl+shift+J : 把多行连接成一行，会去掉空格的行 command+J : 可以生成一些自动代码，比如for循环 command+B : 找变量的来源 同F4 查找变量来源 ctrl+shift+B : 找变量所属的类 command+G : 定位 command+F : 在当前文件里查找文本 f3向下看，shift+f3向上看 ctrl+shift+F : 可以在整个工程或着某个目录下面查找变量 相当于eclipse里的ctrl+H alt+shift+C :最近修改的文件 command+E :最近打开的文件 alt+enter :导入包，自动修改 command+alt+L :格式化代码command+alt+I : 自动缩进，不用多次使用tab或着backspace键，也是比较方便的 ctrl+shift+space :代码补全，这个会判断可能用到的，这个代码补全和代码提示是不一样的 command+P : 方法参数提示 command+alt+T : 把选中的代码放在 TRY{} IF{} ELSE{} 里 command+X :剪切删除行 command+shift+V : 可以复制多个文本 command+shift+U : 大小写转换 alt+f1 :查找文件所在目录位置 command+/ :注释一行或着多行 // ctrl+shift+/ : 注释/…/ command+alt+左右箭头 : 返回上次编辑的位置 shift+f6 :重命名 command+shift+上下箭头 : 把代码上移或着下移 command+[ 或 ] : 可以跳到大括号的开头结尾 command+f12 :可以显示当前文件的结构 command+alt+B :可以导航到一个抽象方法的实现代码 command+shift+* :列编辑 alt+f8 : debug时选中查看值f8相当于eclipse的f6跳到下一步 shift+f8 :相当于eclipse的f8跳到下一个断点 alt+shift+f7 :这个是强制进入代码 command+f9 debug :运行java类 ctrl+shift+f10 :正常运行java类 command+f2 :停止运行]]></content>
  </entry>
  <entry>
    <title><![CDATA[git reset、checkout & revert 代码回滚]]></title>
    <url>%2F2018%2F03%2F26%2Fgit%20reset%7Ccheckout%20%7C%20revert%20%E4%BB%A3%E7%A0%81%E5%9B%9E%E6%BB%9A%2F</url>
    <content type="text"><![CDATA[git reset 和 git checkout 即可以用于commit，也可以用于一个文件，而 revert只能用于commit git revert：撤销某次commit的修改，并且自动新建一个commit提交，git log中添加新的revert日志；revert只能作用于commit，不能用于文件假设当前有3个commit，git log如下： 123commit3: add test3.ccommit2: add test2.ccommit1: add test1.c123 执行 git revert HEAD~1之后，会提示提交信息，提交后git log如下： 1234commit4: Reverts “test2.c”commit3: test3.ccommit2: test2.ccommit1: test1.c1234 执行完后，test2.c被删除了（因为commit2的修改就是添加 test2.c，所以 revert commit2 就是撤销此次修改，即删除添加的test2.c），revert后运行git status，无任何变化（因为已经自动commit了），其结果就是新的commit中有 test1.c 和 test3.c 两个文件，无 test2.c。 git checkout三个作用： checking out files, checking out commits, and checking out branches. checkout commits， 例如: 123git checkout hotfix // 切换到 hotfix 分支git checkout HEAD~2 // checkout到两个commit之前, 执行 git status 你会发现： HEAD detached at b09ab7cgit checkout api.c // 相当于撤销某个文件的修改123 checkout commit 基本上只用于查看之前的某一次commit，千万别直接在 checkout commits 后直接修改，然后 add，然后再commit. 因为这样你在 这个branch 上 新 修改的东西会消失的。。。（如果想找回，见文章最后 git reflog 命令），相当于你在下图中 Non-existent Branch 上的代码都是临时滴，在分支切换后（切到别的分支，再切回来）就会消失（因为一个分支只有一个HEAD，就是Master指的那个），见图： 正确的做法是，在 checkout commit 之后，再马上新建一个branch，然后checkout到新建的 branch，再在新建的 branch上add commit就OK了（因为新的 branch 的 HEAD 就会指向你新修改的代码了，而不是跟你那个Master抢同一个HEAD指针）。 It’s important to understand that branches are just pointers to commits.例如执行 git branch crazy_experiment 如下图：To start adding commits to it, you need to select it with git checkout, and then use the standard git add and git commit commands Remember that the HEAD is Git’s way of referring to the current snapshot. Internally, the git checkout command simply updates the HEAD to point to either the specified branch or commit. When it points to a branch, Git doesn’t complain, but when you check out a commit, it switches into a “detached HEAD” state. see link: https://www.atlassian.com/git/tutorials/using-branches/git-checkout git reset：move the tip of a branch to a different commit; 回退到某次修改，根据 –mixed, –soft, –hard 选择是否提交修改（add &amp; commit） ，git log中会”删除”回退版本的commit之后的日志同样有3个commit，git log如下： 123commit3: add test3.ccommit2: add test2.ccommit1: add test1.c123 执行 git reset HEAD~1 （默认–mixed）之后，再次看git log，如下： 12commit2: test2.ccommit1: test1.c12 执行完后，commit3的log信息被删除了；但是test3.c还在本地缓存区，运行git status，可以看见提示test3.c，可以用git add 包含该文件； 若执行git reset –hard HEAD~1，log为： 12commit2: test2.ccommit1: test1.c12 执行完后，test3.c被删除了，查看git status，无任何变化（因为暂存区，工作区全部用指定提交版本的目录树替换掉了）。 例如，执行 123git checkout hotfix // 切换到 hotfix 分支git reset HEAD~2 // 回退到两个commit之前git reset HEAD api.c // 相当于撤销对某个文件的修改123 其实reset命令有两种用法： 12git reset HEAD~2 foo.py // 针对某个文件的resetgit reset [--soft | --mixed | --hard | --merge | --keep] [-q] [&lt;commit&gt;] // 针对某次commit的reset12 第一种用法是不会重置引用的，即不会修改master文件。只是把某一次提交的文件放到暂存区（已经 git add 过的），而且没有 soft、mixed、hard等选项，因为该文件肯定是被 git add 过了的。 第二种用法会重置引用，并且根据参数不同决定是否覆盖暂存区和工作目录（但是都会影响提交记录）： –hard参数会将工作目录、暂存区(git add)和提交记录(git commit) 用 指定提交版本替换掉 –soft 参数只执行提交记录的操作， 不进行工作目录和暂存区的覆盖 –mixed或加参数（默认），覆盖暂存区和提交记录，但不覆盖工目录 These flags are often used with HEAD as the parameter. For instance, git reset --mixed HEAD has the affect of unstaging all changes, but leaves them in the working directory. On the other hand, if you want to completely throw away all your uncommitted changes, you would use git reset --hard HEAD. These are two of the most common uses of git reset.Be careful when passing a commit other than HEAD to git reset, since this re-writes the current branch’s history. Remember: reset 最好只跟HEAD一块使用，而且是uncommitted changes Remember: Git reset will alter the existing commit history. For this reason, git revert should be used to undo changes on a public branch, and git reset should be reserved for undoing changes on a private branch. You can also think of git revert as a tool for undoing committed changes, while git reset HEAD is for undoing uncommitted changes. git撤销提交到暂存区的代码，撤销更改过的代码 git reset HEAD – file 撤销提交到暂存区的代码 撤销掉修改：git checkout – filepath 还原文件到某个版本 git checkout HEAD filepath But But But…如果你不听劝，还是将reset用于了其他commit，但执行完git reset后又反悔了，想重新回到rest之前的commit，但是此时git log已经找不到那个之前的commit的信息了怎么办？(因为 git reset 会覆盖提交记录，即 “删除”相应git log中的信息) 这时我们可以使用 git reflog 查看所有的变更记录，如下： 1234$ git reflog22f8aae HEAD@&#123;0&#125;: pull: Merge made by the &apos;recursive&apos; strategy.4e79a0b HEAD@&#123;1&#125;: reset: moving to HEAD^22f8aae HEAD@&#123;2&#125;: reset: moving to 22f8aae1234 此时恢复某次修改只需要执行： 1git reset --hard 22f8aae1 尊重原作，参考自：http://www.open-open.com/lib/view/open1397013992747.html http://blog.csdn.net/n289950578/article/details/24738427 https://www.atlassian.com/git/tutorials/resetting-checking-out-and-reverting/commit-level-operations]]></content>
  </entry>
  <entry>
    <title><![CDATA[grpc 初探]]></title>
    <url>%2F2018%2F03%2F26%2Fgrpc-%E5%88%9D%E6%8E%A2%2F</url>
    <content type="text"><![CDATA[背景：gRPC是一个高性能、通用的开源RPC框架，其由Google主要面向移动应用开发并基于HTTP/2协议标准而设计，基于ProtoBuf(Protocol Buffers)序列化协议开发，且支持众多开发语言。gRPC提供了一种简单的方法来精确地定义服务和为iOS、Android和后台支持服务自动生成可靠性很强的客户端功能库。客户端充分利用高级流和链接功能，从而有助于节省带宽、降低的TCP链接次数、节省CPU使用、和电池寿命。 以下初探编码过程： 1、安装插件Protobuf-dt最新版本，我的版本为2.2.1 2、下载protobuf ​ 找到对应操作系统版本（我的系统为OS）直接解压到某个目录（我的目录为：/Users/peng/protoc-3.0.0-beta-2-osx-x86_64），链接：https://github.com/google/protobuf 3、新建maven项目，过程省略 4、在pom.xml文件中添加gRPC的相关依赖 12345&lt;dependency&gt; &lt;groupId&gt;io.grpc&lt;/groupId&gt; &lt;artifactId&gt;grpc-all&lt;/artifactId&gt; &lt;version&gt;0.13.2&lt;/version&gt; &lt;/dependency&gt; ​ 添加maven-protobuf-plugin，在pom.xml中添加以下内容 ;) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869&lt;build&gt; &lt;extensions&gt; &lt;extension&gt; &lt;groupId&gt;kr.motd.maven&lt;/groupId&gt; &lt;artifactId&gt;os-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.4.1.Final&lt;/version&gt; &lt;/extension&gt; &lt;/extensions&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.xolstice.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;protobuf-maven-plugin&lt;/artifactId&gt; &lt;version&gt;0.5.0&lt;/version&gt; &lt;configuration&gt; &lt;!-- The version of protoc must match protobuf-java. If you don&apos;t depend on protobuf-java directly, you will be transitively depending on the protobuf-java version that grpc depends on. --&gt; &lt;protocArtifact&gt;com.google.protobuf:protoc:3.0.0-beta-2:exe:$&#123;os.detected.classifier&#125;&lt;/protocArtifact&gt; &lt;pluginId&gt;grpc-java&lt;/pluginId&gt; &lt;pluginArtifact&gt;io.grpc:protoc-gen-grpc-java:0.13.2:exe:$&#123;os.detected.classifier&#125;&lt;/pluginArtifact&gt; &lt;protocExecutable&gt;/Users/peng/protoc-3.0.0-beta-2-osx-x86_64/protoc&lt;/protocExecutable&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;compile&lt;/goal&gt; &lt;goal&gt;compile-custom&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; 注意protocExecutable节点后的目录为第2步中protobuf的安装路径 最终的pom.xml文件如下 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.mzsg.demo&lt;/groupId&gt; &lt;artifactId&gt;grpc&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;grpc&lt;/name&gt; &lt;url&gt;http://maven.apache.org&lt;/url&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;3.8.1&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.grpc&lt;/groupId&gt; &lt;artifactId&gt;grpc-all&lt;/artifactId&gt; &lt;version&gt;0.13.2&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;extensions&gt; &lt;extension&gt; &lt;groupId&gt;kr.motd.maven&lt;/groupId&gt; &lt;artifactId&gt;os-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.4.1.Final&lt;/version&gt; &lt;/extension&gt; &lt;/extensions&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.xolstice.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;protobuf-maven-plugin&lt;/artifactId&gt; &lt;version&gt;0.5.0&lt;/version&gt; &lt;configuration&gt; &lt;!-- The version of protoc must match protobuf-java. If you don&apos;t depend on protobuf-java directly, you will be transitively depending on the protobuf-java version that grpc depends on. --&gt; &lt;protocArtifact&gt;com.google.protobuf:protoc:3.0.0-beta-2:exe:$&#123;os.detected.classifier&#125;&lt;/protocArtifact&gt; &lt;pluginId&gt;grpc-java&lt;/pluginId&gt; &lt;pluginArtifact&gt;io.grpc:protoc-gen-grpc-java:0.13.2:exe:$&#123;os.detected.classifier&#125;&lt;/pluginArtifact&gt; &lt;protocExecutable&gt;/Users/peng/protoc-3.0.0-beta-2-osx-x86_64/protoc&lt;/protocExecutable&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;compile&lt;/goal&gt; &lt;goal&gt;compile-custom&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;/project&gt; 5、编写proto文件，描述入参、出参及远程方法 在src/main下面建立proto目录，protobuf-maven-plugin默认会扫描该目录以生成java文件 在proto目录下新建文件，AccountQry.proto，内容为 123456789101112131415161718192021222324252627282930313233syntax = &quot;proto3&quot;;package accountService;option java_package = &quot;com.mzsg.demo.grpc.qryaccount&quot;;option java_outer_classname = &quot;QryAccountProto&quot;;//账户查询请求message AccountQryRequest &#123; //请求流水 string requestId = 1; //用户ID string userId = 2;&#125;//账户查询响应message AccountQryResponse &#123; //请求流水 string requestId = 1; //返回码，1:成功; -1:失败 int32 rc = 2; //错误消息 string msg = 3; //账户余额 int32 amount = 4;&#125;/** * 账户操查询服务 */service QryAccountService &#123; //账户查询方法 rpc Qry(AccountQryRequest) returns (AccountQryResponse);&#125; 注意：本例用查账户查询作为demo，因为涉及到后面的性能（包括了序列化，反序列化）对比，故不再简单采用Hello world来测试 6、运行maven-generate-source，生成proto对应的java文件 grpc-java下的为方法，java下的为入参出参，将这两个文件copy到com.mzsg.demo.grpc.qryaccount包下 注意：QryAccountServiceGrpc.java文件会提示@Override注解报错，直接删除注解即可，另外生成的代码也不是很简洁，有点无语 7、编写接口实现类QryAccountServiceImpl.java 123456789101112131415161718package com.mzsg.demo.grpc.qryaccount.impl;import com.mzsg.demo.grpc.qryaccount.QryAccountProto;import com.mzsg.demo.grpc.qryaccount.QryAccountProto.AccountQryRequest;import com.mzsg.demo.grpc.qryaccount.QryAccountProto.AccountQryResponse;import com.mzsg.demo.grpc.qryaccount.QryAccountServiceGrpc.QryAccountService;import io.grpc.stub.StreamObserver;public class QryAccountServiceImpl implements QryAccountService &#123; public void qry(AccountQryRequest request, StreamObserver&lt;AccountQryResponse&gt; responseObserver) &#123; System.out.println(&quot;qry &quot; + request.getUserId()); AccountQryResponse response = QryAccountProto.AccountQryResponse.newBuilder().setRc(1).setAmount(666).build(); responseObserver.onNext(response); responseObserver.onCompleted(); &#125;&#125; 8、编码Server端代码Server.java 12345678910111213141516171819202122232425262728293031package com.mzsg.demo.grpc;import java.io.IOException;import com.mzsg.demo.grpc.qryaccount.QryAccountServiceGrpc;import com.mzsg.demo.grpc.qryaccount.impl.QryAccountServiceImpl;public class Server &#123; private static int port = 8883; private static io.grpc.Server server; public void run() &#123; QryAccountServiceGrpc.QryAccountService modifyAccountServiceImpl = new QryAccountServiceImpl(); server = io.grpc.ServerBuilder.forPort(port).addService(QryAccountServiceGrpc.bindService(modifyAccountServiceImpl)).build(); try &#123; server.start(); System.out.println(&quot;Server start success on port:&quot; + port); server.awaitTermination(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; public static void main(String[] args) &#123; Server server = new Server(); server.run(); &#125;&#125; 9、编码Client端代码Client.java 1234567891011121314151617181920212223242526272829303132package com.mzsg.demo.grpc;import java.io.FileNotFoundException;import java.io.IOException;import com.mzsg.demo.grpc.qryaccount.QryAccountProto;import com.mzsg.demo.grpc.qryaccount.QryAccountProto.AccountQryRequest;import com.mzsg.demo.grpc.qryaccount.QryAccountProto.AccountQryResponse;import com.mzsg.demo.grpc.qryaccount.QryAccountServiceGrpc;import com.mzsg.demo.grpc.qryaccount.QryAccountServiceGrpc.QryAccountServiceBlockingStub;import io.grpc.ManagedChannel;import io.grpc.ManagedChannelBuilder;public class Client &#123; public static void main( String[] args ) throws FileNotFoundException, IOException&#123; AccountQryRequest request = QryAccountProto.AccountQryRequest.newBuilder().setUserId(&quot;20012&quot;).setRequestId(&quot;123&quot;).build(); ManagedChannel channel = ManagedChannelBuilder .forAddress(&quot;localhost&quot;, 8883) .usePlaintext(true) .build(); QryAccountServiceBlockingStub stub = QryAccountServiceGrpc.newBlockingStub(channel); for (int j = 0; j &lt; 20; j++) &#123; long start = System.currentTimeMillis(); for(int i=0; i&lt;10000; i++)&#123; AccountQryResponse rsp = stub.qry(request); //System.out.println(rsp); &#125; System.out.println(System.currentTimeMillis() - start + &quot; MS&quot;); &#125; &#125;&#125; ;) 10、运行Server.java，再运行Client.java ​ 简单性能对比（每万次调用消耗时间比）： 实现 时间（毫秒） 备注 HTTP接口 13000 springboot+json，客户端采用HttpClient Google Grpc 2100 本demo Facebook swift（Thrift） 1500 Thrift实现 转载于 https://www.cnblogs.com/mzsg/p/5643367.html]]></content>
  </entry>
  <entry>
    <title><![CDATA[Twitter的分布式自增ID算法snowflake]]></title>
    <url>%2F2018%2F03%2F23%2FTwitter%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E8%87%AA%E5%A2%9EID%E7%AE%97%E6%B3%95snowflake%2F</url>
    <content type="text"><![CDATA[Twitter的分布式自增ID算法snowflake (Java版)概述分布式系统中，有一些需要使用全局唯一ID的场景，这种时候为了防止ID冲突可以使用36位的UUID，但是UUID有一些缺点，首先他相对比较长，另外UUID一般是无序的。 有些时候我们希望能使用一种简单一些的ID，并且希望ID能够按照时间有序生成。 而twitter的snowflake解决了这种需求，最初Twitter把存储系统从MySQL迁移到Cassandra，因为Cassandra没有顺序ID生成机制，所以开发了这样一套全局唯一ID生成服务。 结构snowflake的结构如下(每部分用-分开): 0 - 0000000000 0000000000 0000000000 0000000000 0 - 00000 - 00000 - 000000000000 第一位为未使用，接下来的41位为毫秒级时间(41位的长度可以使用69年)，然后是5位datacenterId和5位workerId(10位的长度最多支持部署1024个节点） ，最后12位是毫秒内的计数（12位的计数顺序号支持每个节点每毫秒产生4096个ID序号） 一共加起来刚好64位，为一个Long型。(转换成字符串后长度最多19) snowflake生成的ID整体上按照时间自增排序，并且整个分布式系统内不会产生ID碰撞（由datacenter和workerId作区分），并且效率较高。经测试snowflake每秒能够产生26万个ID。 源码(JAVA版本的源码) ;) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144/** * Twitter_Snowflake&lt;br&gt; * SnowFlake的结构如下(每部分用-分开):&lt;br&gt; * 0 - 0000000000 0000000000 0000000000 0000000000 0 - 00000 - 00000 - 000000000000 &lt;br&gt; * 1位标识，由于long基本类型在Java中是带符号的，最高位是符号位，正数是0，负数是1，所以id一般是正数，最高位是0&lt;br&gt; * 41位时间截(毫秒级)，注意，41位时间截不是存储当前时间的时间截，而是存储时间截的差值（当前时间截 - 开始时间截) * 得到的值），这里的的开始时间截，一般是我们的id生成器开始使用的时间，由我们程序来指定的（如下下面程序IdWorker类的startTime属性）。41位的时间截，可以使用69年，年T = (1L &lt;&lt; 41) / (1000L * 60 * 60 * 24 * 365) = 69&lt;br&gt; * 10位的数据机器位，可以部署在1024个节点，包括5位datacenterId和5位workerId&lt;br&gt; * 12位序列，毫秒内的计数，12位的计数顺序号支持每个节点每毫秒(同一机器，同一时间截)产生4096个ID序号&lt;br&gt; * 加起来刚好64位，为一个Long型。&lt;br&gt; * SnowFlake的优点是，整体上按照时间自增排序，并且整个分布式系统内不会产生ID碰撞(由数据中心ID和机器ID作区分)，并且效率较高，经测试，SnowFlake每秒能够产生26万ID左右。 */public class SnowflakeIdWorker &#123; // ==============================Fields=========================================== /** 开始时间截 (2015-01-01) */ private final long twepoch = 1420041600000L; /** 机器id所占的位数 */ private final long workerIdBits = 5L; /** 数据标识id所占的位数 */ private final long datacenterIdBits = 5L; /** 支持的最大机器id，结果是31 (这个移位算法可以很快的计算出几位二进制数所能表示的最大十进制数) */ private final long maxWorkerId = -1L ^ (-1L &lt;&lt; workerIdBits); /** 支持的最大数据标识id，结果是31 */ private final long maxDatacenterId = -1L ^ (-1L &lt;&lt; datacenterIdBits); /** 序列在id中占的位数 */ private final long sequenceBits = 12L; /** 机器ID向左移12位 */ private final long workerIdShift = sequenceBits; /** 数据标识id向左移17位(12+5) */ private final long datacenterIdShift = sequenceBits + workerIdBits; /** 时间截向左移22位(5+5+12) */ private final long timestampLeftShift = sequenceBits + workerIdBits + datacenterIdBits; /** 生成序列的掩码，这里为4095 (0b111111111111=0xfff=4095) */ private final long sequenceMask = -1L ^ (-1L &lt;&lt; sequenceBits); /** 工作机器ID(0~31) */ private long workerId; /** 数据中心ID(0~31) */ private long datacenterId; /** 毫秒内序列(0~4095) */ private long sequence = 0L; /** 上次生成ID的时间截 */ private long lastTimestamp = -1L; //==============================Constructors===================================== /** * 构造函数 * @param workerId 工作ID (0~31) * @param datacenterId 数据中心ID (0~31) */ public SnowflakeIdWorker(long workerId, long datacenterId) &#123; if (workerId &gt; maxWorkerId || workerId &lt; 0) &#123; throw new IllegalArgumentException(String.format(&quot;worker Id can&apos;t be greater than %d or less than 0&quot;, maxWorkerId)); &#125; if (datacenterId &gt; maxDatacenterId || datacenterId &lt; 0) &#123; throw new IllegalArgumentException(String.format(&quot;datacenter Id can&apos;t be greater than %d or less than 0&quot;, maxDatacenterId)); &#125; this.workerId = workerId; this.datacenterId = datacenterId; &#125; // ==============================Methods========================================== /** * 获得下一个ID (该方法是线程安全的) * @return SnowflakeId */ public synchronized long nextId() &#123; long timestamp = timeGen(); //如果当前时间小于上一次ID生成的时间戳，说明系统时钟回退过这个时候应当抛出异常 if (timestamp &lt; lastTimestamp) &#123; throw new RuntimeException( String.format(&quot;Clock moved backwards. Refusing to generate id for %d milliseconds&quot;, lastTimestamp - timestamp)); &#125; //如果是同一时间生成的，则进行毫秒内序列 if (lastTimestamp == timestamp) &#123; sequence = (sequence + 1) &amp; sequenceMask; //毫秒内序列溢出 if (sequence == 0) &#123; //阻塞到下一个毫秒,获得新的时间戳 timestamp = tilNextMillis(lastTimestamp); &#125; &#125; //时间戳改变，毫秒内序列重置 else &#123; sequence = 0L; &#125; //上次生成ID的时间截 lastTimestamp = timestamp; //移位并通过或运算拼到一起组成64位的ID return ((timestamp - twepoch) &lt;&lt; timestampLeftShift) // | (datacenterId &lt;&lt; datacenterIdShift) // | (workerId &lt;&lt; workerIdShift) // | sequence; &#125; /** * 阻塞到下一个毫秒，直到获得新的时间戳 * @param lastTimestamp 上次生成ID的时间截 * @return 当前时间戳 */ protected long tilNextMillis(long lastTimestamp) &#123; long timestamp = timeGen(); while (timestamp &lt;= lastTimestamp) &#123; timestamp = timeGen(); &#125; return timestamp; &#125; /** * 返回以毫秒为单位的当前时间 * @return 当前时间(毫秒) */ protected long timeGen() &#123; return System.currentTimeMillis(); &#125; //==============================Test============================================= /** 测试 */ public static void main(String[] args) &#123; SnowflakeIdWorker idWorker = new SnowflakeIdWorker(0, 0); for (int i = 0; i &lt; 1000; i++) &#123; long id = idWorker.nextId(); System.out.println(Long.toBinaryString(id)); System.out.println(id); &#125; &#125;&#125; 参考https://github.com/twitter/snowflake]]></content>
  </entry>
  <entry>
    <title><![CDATA[科学上网]]></title>
    <url>%2F2018%2F03%2F22%2F%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91%2F</url>
    <content type="text"><![CDATA[shadowsocks配置1/usr/bin/python /usr/bin/ssserver -c /etc/shadowsocks.json 12345678910&#123; &quot;server&quot;: &quot;::&quot;, &quot;port_password&quot;:&#123; &quot;23334&quot;:&quot;xxxxxxxxx&quot;, &quot;23335&quot;:&quot;xxxxxxxxx&quot; &#125;, &quot;method&quot;:&quot;aes-256-cfb&quot;, &quot;timeout&quot;:300, &quot;fast_open&quot;: false&#125; kcptun配置1./server_linux_amd64 -l :23333 -t 45.77.199.91:23334 -key xxxxxxxxx -mtu 1400 -sndwnd 2048 -rcvwnd 2048 -mode fast2 Android手机配置]]></content>
  </entry>
  <entry>
    <title><![CDATA[Redis学习笔记—— Redis中各种数据类型对应的jedis操作命令及使用场景]]></title>
    <url>%2F2018%2F03%2F22%2FRedis%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E2%80%94%E2%80%94Redis%E4%B8%AD%E5%90%84%E7%A7%8D%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E5%AF%B9%E5%BA%94%E7%9A%84jedis%E6%93%8D%E4%BD%9C%E5%91%BD%E4%BB%A4%E5%8F%8A%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF%2F</url>
    <content type="text"><![CDATA[一、常用数据类型简介：​ redis常用五种数据类型:string,hash,list,set,zset(sorted set). 二、jedis操作命令： 对value操作的命令 ​ exists(key)：确认一个key是否存在 ​ del(key)：删除一个key ​ type(key)：返回值的类型 ​ keys(pattern)：返回满足给定pattern的所有key ​ randomkey：随机返回key空间的一个key ​ rename(oldname, newname)：将key由oldname重命名为newname，若newname存在则删除newname表示的key ​ dbsize：返回当前数据库中key的数目 ​ expire：设定一个key的活动时间（s） ​ ttl：获得一个key的活动时间 ​ select(index)：按索引查询 ​ move(key, dbindex)：将当前数据库中的key转移到有dbindex索引的数据库 ​ flushdb：删除当前选择数据库中的所有key ​ flushall：删除所有数据库中的所有key 对String操作的命令 ​ set(key, value)：给数据库中名称为key的string赋予值value ​ get(key)：返回数据库中名称为key的string的value ​ getset(key, value)：给名称为key的string赋予上一次的value ​ mget(key1, key2,…, key N)：返回库中多个string（它们的名称为key1，key2…）的value ​ setnx(key, value)：如果不存在名称为key的string，则向库中添加string，名称为key，值为value ​ setex(key, time, value)：向库中添加string（名称为key，值为value）同时，设定过期时间time ​ mset(key1, value1, key2, value2,…key N, value N)：同时给多个string赋值，名称为key i的string赋值value i ​ msetnx(key1, value1, key2, value2,…key N, value N)：如果所有名称为key i的string都不存在，则向库中添加string，名称 key i赋值为value i ​ incr(key)：名称为key的string增1操作 ​ incrby(key, integer)：名称为key的string增加integer ​ decr(key)：名称为key的string减1操作 ​ decrby(key, integer)：名称为key的string减少integer ​ append(key, value)：名称为key的string的值附加value ​ substr(key, start, end)：返回名称为key的string的value的子串 对List操作的命令 ​ rpush(key, value)：在名称为key的list尾添加一个值为value的元素 ​ lpush(key, value)：在名称为key的list头添加一个值为value的 元素 ​ llen(key)：返回名称为key的list的长度 ​ lrange(key, start, end)：返回名称为key的list中start至end之间的元素（下标从0开始，下同） ​ ltrim(key, start, end)：截取名称为key的list，保留start至end之间的元素 ​ lindex(key, index)：返回名称为key的list中index位置的元素 ​ lset(key, index, value)：给名称为key的list中index位置的元素赋值为value ​ lrem(key, count, value)：删除count个名称为key的list中值为value的元素。count为0，删除所有值为value的元素，count&gt;0 从头至尾删除count个值为value的元素，count&lt;0从尾到头删除|count|个值为value的元素。 ​ lpop(key)：返回并删除名称为key的list中的首元素 ​ rpop(key)：返回并删除名称为key的list中的尾元素 ​ blpop(key1, key2,… key N, timeout)：lpop 命令的block版本。即当timeout为0时，若遇到名称为key i的list不存在或该list为空，则命令结束。如果 timeout&gt;0，则遇到上述情况时，等待timeout秒，如果问题没有解决，则对key i+1开始的list执行pop操作。 ​ brpop(key1, key2,… key N, timeout)：rpop的block版本。参考上一命令。 ​ rpoplpush(srckey, dstkey)：返回并删除名称为srckey的list的尾元素，并将该元素添加到名称为dstkey的list的头部 对Set操作的命令 ​ sadd(key, member)：向名称为key的set中添加元素member ​ srem(key, member) ：删除名称为key的set中的元素member ​ spop(key) ：随机返回并删除名称为key的set中一个元素 ​ smove(srckey, dstkey, member) ：将member元素从名称为srckey的集合移到名称为dstkey的集合 ​ scard(key) ：返回名称为key的set的基数 ​ sismember(key, member) ：测试member是否是名称为key的set的元素 ​ sinter(key1, key2,…key N) ：求交集 ​ sinterstore(dstkey, key1, key2,…key N) ：求交集并将交集保存到dstkey的集合 ​ sunion(key1, key2,…key N) ：求并集 ​ sunionstore(dstkey, key1, key2,…key N) ：求并集并将并集保存到dstkey的集合 ​ sdiff(key1, key2,…key N) ：求差集 ​ sdiffstore(dstkey, key1, key2,…key N) ：求差集并将差集保存到dstkey的集合 ​ smembers(key) ：返回名称为key的set的所有元素 ​ srandmember(key) ：随机返回名称为key的set的一个元素 对zset（sorted set）操作的命令 ​ zadd(key, score, member)：向名称为key的zset中添加元素member，score用于排序。如果该元素已经存在，则根据score更新该元素的顺序。 ​ zrem(key, member) ：删除名称为key的zset中的元素member ​ zincrby(key, increment, member) ：如果在名称为key的zset中已经存在元素member，则该元素的score增加increment；否则向集合中添加该元素，其score的值为increment ​ zrank(key, member) ：返回名称为key的zset（元素已按score从小到大排序）中member元素的rank（即index，从0开始），若没有member元素，返回“nil” ​ zrevrank(key, member) ：返回名称为key的zset（元素已按score从大到小排序）中member元素的rank（即index，从0开始），若没有member元素，返回“nil” ​ zrange(key, start, end)：返回名称为key的zset（元素已按score从小到大排序）中的index从start到end的所有元素 ​ zrevrange(key, start, end)：返回名称为key的zset（元素已按score从大到小排序）中的index从start到end的所有元素 ​ zrangebyscore(key, min, max)：返回名称为key的zset中score &gt;= min且score &lt;= max的所有元素 ​ zcard(key)：返回名称为key的zset的基数 ​ zscore(key, element)：返回名称为key的zset中元素element的score ​ zremrangebyrank(key, min, max)：删除名称为key的zset中rank &gt;= min且rank &lt;= max的所有元素 ​ zremrangebyscore(key, min, max) ：删除名称为key的zset中score &gt;= min且score &lt;= max的所有元素 ​ zunionstore / zinterstore(dstkeyN, key1,…,keyN, WEIGHTS w1,…wN, AGGREGATE SUM|MIN|MAX)：对N个zset求并集和交集，并将最后的集合保存在dstkeyN中。对于集合中每一个元素的score，在进行AGGREGATE运算前，都要乘以对于的WEIGHT参数。如果没有提供WEIGHT，默认为1。默认的AGGREGATE是SUM，即结果集合中元素的score是所有集合对应元素进行 SUM运算的值，而MIN和MAX是指，结果集合中元素的score是所有集合对应元素中最小值和最大值。 对Hash操作的命令 ​ hset(key, field, value)：向名称为key的hash中添加元素field&lt;—&gt;value ​ hget(key, field)：返回名称为key的hash中field对应的value ​ hmget(key, field1, …,field N)：返回名称为key的hash中field i对应的value ​ hmset(key, field1, value1,…,field N, value N)：向名称为key的hash中添加元素field i&lt;—&gt;value i ​ hincrby(key, field, integer)：将名称为key的hash中field的value增加integer ​ hexists(key, field)：名称为key的hash中是否存在键为field的域 ​ hdel(key, field)：删除名称为key的hash中键为field的域 ​ hlen(key)：返回名称为key的hash中元素个数 ​ hkeys(key)：返回名称为key的hash中所有键 ​ hvals(key)：返回名称为key的hash中所有键对应的value ​ hgetall(key)：返回名称为key的hash中所有的键（field）及其对应的value 三、各种数据类型所对应的应用场景1.String类型的应用场景 String是最常用的一种数据类型,普通的key/value存储. 2.list类型的应用场景 比较适用于列表式存储且顺序相对比较固定，例如：省份、城市列表、品牌、厂商、车系、车型等列表、专题列表… 3.set类型的应用场景 Set对外提供的功能与list类似,当需要存储一个列表数据,又不希望出现重复数据时,可选用set 4.zset(sorted set)类型的应用场景 zset的使用场景与set类似,区别是set不是自动有序的,而zset可以通过用户额外提供一个优先级(score)的参数来为成员排序,并且是插入有序的,即自动排序.当你需要一个有序的并且不重复的集合列表,那么可以选择zset数据结构。例如:根据PV排序的热门车系车型列表，根据时间排序的新闻列表 5.hash类型的应用场景 类似于表记录的存储，页面视图所需数据的存储 四、具体使用参考示例：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151private void testKey() &#123; System.out.println(&quot;=============key==========================&quot;); // 清空数据 System.out.println(jedis.flushDB()); System.out.println(jedis.echo(&quot;foo&quot;)); // 判断key否存在 System.out.println(shardedJedis.exists(&quot;foo&quot;)); shardedJedis.set(&quot;key&quot;, &quot;values&quot;); System.out.println(shardedJedis.exists(&quot;key&quot;)); &#125; private void testString() &#123; System.out.println(&quot;=============String==========================&quot;); // 清空数据 System.out.println(jedis.flushDB()); // 存储数据 shardedJedis.set(&quot;foo&quot;, &quot;bar&quot;); System.out.println(shardedJedis.get(&quot;foo&quot;)); // 若key不存在，则存储 shardedJedis.setnx(&quot;foo&quot;, &quot;foo not exits&quot;); System.out.println(shardedJedis.get(&quot;foo&quot;)); // 覆盖数据 shardedJedis.set(&quot;foo&quot;, &quot;foo update&quot;); System.out.println(shardedJedis.get(&quot;foo&quot;)); // 追加数据 shardedJedis.append(&quot;foo&quot;, &quot; hello, world&quot;); System.out.println(shardedJedis.get(&quot;foo&quot;)); // 设置key的有效期，并存储数据 shardedJedis.setex(&quot;foo&quot;, 2, &quot;foo not exits&quot;); System.out.println(shardedJedis.get(&quot;foo&quot;)); try &#123; Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; &#125; System.out.println(shardedJedis.get(&quot;foo&quot;)); // 获取并更改数据 shardedJedis.set(&quot;foo&quot;, &quot;foo update&quot;); System.out.println(shardedJedis.getSet(&quot;foo&quot;, &quot;foo modify&quot;)); // 截取value的值 System.out.println(shardedJedis.getrange(&quot;foo&quot;, 1, 3)); System.out.println(jedis.mset(&quot;mset1&quot;, &quot;mvalue1&quot;, &quot;mset2&quot;, &quot;mvalue2&quot;, &quot;mset3&quot;, &quot;mvalue3&quot;, &quot;mset4&quot;, &quot;mvalue4&quot;)); System.out.println(jedis.mget(&quot;mset1&quot;, &quot;mset2&quot;, &quot;mset3&quot;, &quot;mset4&quot;)); System.out.println(jedis.del(new String[] &#123; &quot;foo&quot;, &quot;foo1&quot;, &quot;foo3&quot; &#125;)); &#125; private void testList() &#123; System.out.println(&quot;=============list==========================&quot;); // 清空数据 System.out.println(jedis.flushDB()); // 添加数据 shardedJedis.lpush(&quot;lists&quot;, &quot;vector&quot;); shardedJedis.lpush(&quot;lists&quot;, &quot;ArrayList&quot;); shardedJedis.lpush(&quot;lists&quot;, &quot;LinkedList&quot;); // 数组长度 System.out.println(shardedJedis.llen(&quot;lists&quot;)); // 排序 System.out.println(shardedJedis.sort(&quot;lists&quot;)); // 字串 System.out.println(shardedJedis.lrange(&quot;lists&quot;, 0, 3)); // 修改列表中单个值 shardedJedis.lset(&quot;lists&quot;, 0, &quot;hello list!&quot;); // 获取列表指定下标的值 System.out.println(shardedJedis.lindex(&quot;lists&quot;, 1)); // 删除列表指定下标的值 System.out.println(shardedJedis.lrem(&quot;lists&quot;, 1, &quot;vector&quot;)); // 删除区间以外的数据 System.out.println(shardedJedis.ltrim(&quot;lists&quot;, 0, 1)); // 列表出栈 System.out.println(shardedJedis.lpop(&quot;lists&quot;)); // 整个列表值 System.out.println(shardedJedis.lrange(&quot;lists&quot;, 0, -1)); &#125; private void testSet() &#123; System.out.println(&quot;=============set==========================&quot;); // 清空数据 System.out.println(jedis.flushDB()); // 添加数据 shardedJedis.sadd(&quot;sets&quot;, &quot;HashSet&quot;); shardedJedis.sadd(&quot;sets&quot;, &quot;SortedSet&quot;); shardedJedis.sadd(&quot;sets&quot;, &quot;TreeSet&quot;); // 判断value是否在列表中 System.out.println(shardedJedis.sismember(&quot;sets&quot;, &quot;TreeSet&quot;)); ; // 整个列表值 System.out.println(shardedJedis.smembers(&quot;sets&quot;)); // 删除指定元素 System.out.println(shardedJedis.srem(&quot;sets&quot;, &quot;SortedSet&quot;)); // 出栈 System.out.println(shardedJedis.spop(&quot;sets&quot;)); System.out.println(shardedJedis.smembers(&quot;sets&quot;)); // shardedJedis.sadd(&quot;sets1&quot;, &quot;HashSet1&quot;); shardedJedis.sadd(&quot;sets1&quot;, &quot;SortedSet1&quot;); shardedJedis.sadd(&quot;sets1&quot;, &quot;TreeSet&quot;); shardedJedis.sadd(&quot;sets2&quot;, &quot;HashSet2&quot;); shardedJedis.sadd(&quot;sets2&quot;, &quot;SortedSet1&quot;); shardedJedis.sadd(&quot;sets2&quot;, &quot;TreeSet1&quot;); // 交集 System.out.println(jedis.sinter(&quot;sets1&quot;, &quot;sets2&quot;)); // 并集 System.out.println(jedis.sunion(&quot;sets1&quot;, &quot;sets2&quot;)); // 差集 System.out.println(jedis.sdiff(&quot;sets1&quot;, &quot;sets2&quot;)); &#125; private void testSortedSet() &#123; System.out.println(&quot;=============zset==========================&quot;); // 清空数据 System.out.println(jedis.flushDB()); // 添加数据 shardedJedis.zadd(&quot;zset&quot;, 10.1, &quot;hello&quot;); shardedJedis.zadd(&quot;zset&quot;, 10.0, &quot;:&quot;); shardedJedis.zadd(&quot;zset&quot;, 9.0, &quot;zset&quot;); shardedJedis.zadd(&quot;zset&quot;, 11.0, &quot;zset!&quot;); // 元素个数 System.out.println(shardedJedis.zcard(&quot;zset&quot;)); // 元素下标 System.out.println(shardedJedis.zscore(&quot;zset&quot;, &quot;zset&quot;)); // 集合子集 System.out.println(shardedJedis.zrange(&quot;zset&quot;, 0, -1)); // 删除元素 System.out.println(shardedJedis.zrem(&quot;zset&quot;, &quot;zset!&quot;)); System.out.println(shardedJedis.zcount(&quot;zset&quot;, 9.5, 10.5)); // 整个集合值 System.out.println(shardedJedis.zrange(&quot;zset&quot;, 0, -1)); &#125; private void testHash() &#123; System.out.println(&quot;=============hash==========================&quot;); // 清空数据 System.out.println(jedis.flushDB()); // 添加数据 shardedJedis.hset(&quot;hashs&quot;, &quot;entryKey&quot;, &quot;entryValue&quot;); shardedJedis.hset(&quot;hashs&quot;, &quot;entryKey1&quot;, &quot;entryValue1&quot;); shardedJedis.hset(&quot;hashs&quot;, &quot;entryKey2&quot;, &quot;entryValue2&quot;); // 判断某个值是否存在 System.out.println(shardedJedis.hexists(&quot;hashs&quot;, &quot;entryKey&quot;)); // 获取指定的值 System.out.println(shardedJedis.hget(&quot;hashs&quot;, &quot;entryKey&quot;)); // 批量获取指定的值 System.out.println(shardedJedis.hmget(&quot;hashs&quot;, &quot;entryKey&quot;, &quot;entryKey1&quot;)); // 删除指定的值 System.out.println(shardedJedis.hdel(&quot;hashs&quot;, &quot;entryKey&quot;)); // 为key中的域 field 的值加上增量 increment System.out.println(shardedJedis.hincrBy(&quot;hashs&quot;, &quot;entryKey&quot;, 123l)); // 获取所有的keys System.out.println(shardedJedis.hkeys(&quot;hashs&quot;)); // 获取所有的values System.out.println(shardedJedis.hvals(&quot;hashs&quot;)); &#125; 源博客地址：http://blog.csdn.net/a183400826/article/details/52605560]]></content>
  </entry>
  <entry>
    <title><![CDATA[Redis学习笔记——数据过期策略]]></title>
    <url>%2F2018%2F03%2F13%2FRedis%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E2%80%94%E2%80%94%E6%95%B0%E6%8D%AE%E8%BF%87%E6%9C%9F%E7%AD%96%E7%95%A5%2F</url>
    <content type="text"><![CDATA[一、设置过期时间 Redis对存储值的过期处理实际上是针对该值的键（key）处理的，即时间的设置也是设置key的有效时间。Expires字典保存了所有键的过期时间，Expires也被称为过期字段。 expire key time(以秒为单位)–这是最常用的方式 setex(String key, int seconds, String value)–字符串独有的方式 注： 1、除了字符串自己独有设置过期时间的方法外，其他方法都需要依靠expire方法来设置时间 2、如果没有设置时间，那缓存就是永不过期 3、如果设置了过期时间，之后又想让缓存永不过期，使用persist key 二、Redis采用的过期策略惰性删除+定期删除 惰性删除流程 在进行get或setnx等操作时，先检查key是否过期， 若过期，删除key，然后执行相应操作； 若没过期，直接执行相应操作 定期删除流程（简单而言，对指定个数个库的每一个库随机删除小于等于指定个数个过期key） 遍历每个数据库（就是redis.conf中配置的”database”数量，默认为16） 检查当前库中的指定个数个key（默认是每个库检查20个key，注意相当于该循环执行20次，循环体时下边的描述） 如果当前库中没有一个key设置了过期时间，直接执行下一个库的遍历 随机获取一个设置了过期时间的key，检查该key是否过期，如果过期，删除key 判断定期删除操作是否已经达到指定时长，若已经达到，直接退出定期删除。 三、RDB对过期key的处理过期key对RDB没有任何影响 从内存数据库持久化数据到RDB文件 持久化key之前，会检查是否过期，过期的key不进入RDB文件 从RDB文件恢复数据到内存数据库 数据载入数据库之前，会对key先进行过期检查，如果过期，不导入数据库（主库情况） 四、AOF对过期key的处理过期key对AOF没有任何影响 从内存数据库持久化数据到AOF文件： 当key过期后，还没有被删除，此时进行执行持久化操作（该key是不会进入aof文件的，因为没有发生修改命令） 当key过期后，在发生删除操作时，程序会向aof文件追加一条del命令（在将来的以aof文件恢复数据的时候该过期的键就会被删掉） AOF重写 重写时，会先判断key是否过期，已过期的key不会重写到aof文件 转载于：http://www.cnblogs.com/xuliangxing/p/7151812.html]]></content>
  </entry>
  <entry>
    <title><![CDATA[Redis学习笔记——五种存储类型的具体用法]]></title>
    <url>%2F2018%2F03%2F13%2FRedis%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E2%80%94%E2%80%94%E4%BA%94%E7%A7%8D%E5%AD%98%E5%82%A8%E7%B1%BB%E5%9E%8B%E7%9A%84%E5%85%B7%E4%BD%93%E7%94%A8%E6%B3%95%2F</url>
    <content type="text"><![CDATA[一、stringString是redis最基本的类型，而且string类型是二进制安全的。意思是redis的string可以包含任何数据。比如jpg图片或者序列化的对象 1$redis-&gt;set(&apos;key&apos;,&apos;TK&apos;); 1$redis-&gt;set(&apos;number&apos;,&apos;1&apos;); 1$redis-&gt;setex(&apos;key&apos;,5,&apos;TK&apos;); //设置有效期为5秒的键值 1$redis-&gt;psetex(&apos;key&apos;,5000,&apos;TK&apos;); //设置有效期为5000毫秒(同5秒)的键值 1$redis-&gt;setnx(&apos;key&apos;,&apos;XK&apos;); //若键值存在返回false 不存在返回true 1$redis-&gt;delete(&apos;key&apos;); 删除键值 可以传入数组 array(&apos;key1&apos;,&apos;key2&apos;)删除多个键 1$redis-&gt;getSet(&apos;key&apos;,&apos;XK&apos;); //将键key的值设置为XK， 并返回这个键值原来的值TK 123456$ret = $redis-&gt;multi() //批量事务处理,不保证处理数据的原子性 -&gt;set(&apos;key1&apos;, &apos;val1&apos;) -&gt;get(&apos;key1&apos;) -&gt;setnx(&apos;key&apos;, &apos;val2&apos;) -&gt;get(&apos;key2&apos;) -&gt;exec(); 12$redis-&gt;watch(&apos;key&apos;); // 监控键key 是否被其他客户端修改 如果KEY在调用watch()和exec()之间被修改，exec失败 12345678910111213141516171819function f($redis, $chan, $msg) &#123; //频道订阅 switch($chan) &#123; case &apos;chan-1&apos;: echo $msg; break; case &apos;chan-2&apos;: echo $msg; break; case &apos;chan-2&apos;: echo $msg; break; &#125;&#125;$redis-&gt;subscribe(array(&apos;chan-1&apos;, &apos;chan-2&apos;, &apos;chan-3&apos;), &apos;f&apos;); // subscribe to 3 chans$redis-&gt;publish(&apos;chan-1&apos;, &apos;hello, world!&apos;); // send message. 1$redis-&gt;exists(&apos;key&apos;); //验证键是否存在，存在返回true 1$redis-&gt;incr(&apos;number&apos;); //键值加1 1$redis-&gt;incrby(&apos;number&apos;,-10); //键值加减10 1$redis-&gt;incrByFloat(&apos;number&apos;, +/- 1.5); //键值加减小数 1$redis-&gt;decr(&apos;number&apos;); // 键值减1 1$redis-&gt;decrBy(&apos;number&apos;,10); // 键值减10 1$mget = $redis-&gt;mget(array(&apos;number&apos;,&apos;key&apos;)); // 批量获取键值,返回一个数组 1$redis-&gt;mset(array(&apos;key0&apos; =&gt; &apos;value0&apos;, &apos;key1&apos; =&gt; &apos;value1&apos;)); // 批量设置键值 12$redis-&gt;msetnx(array(&apos;key0&apos; =&gt; &apos;value0&apos;, &apos;key1&apos; =&gt; &apos;value1&apos;)); // 批量设置键值，类似将setnx()方法批量操作 1$redis-&gt;append(&apos;key&apos;, &apos;-Smudge&apos;); //原键值TK，将值追加到键值后面，键值为TK-Smudge 1$redis-&gt;getRange(&apos;key&apos;, 0, 5); // 键值截取从0位置开始到5位置结束 1$redis-&gt;getRange(&apos;key&apos;, -6, -1); // 字符串截取从-6(倒数第6位置)开始到-1(倒数第1位置)结束 123$redis-&gt;setRange(&apos;key&apos;, 0, &apos;Smudge&apos;); // 键值中替换字符串，0表示从0位置开始 有多少个字符替换多少位置，其中汉字占2个位置 1$redis-&gt;strlen(&apos;key&apos;); //键值长度 1$redis-&gt;getBit(&apos;key&apos;); 1$redis-&gt;setBit(&apos;key&apos;); 二、list链表1$redis-&gt;delete(&apos;list-key&apos;); // 删除链表 1$redis-&gt;lPush(&apos;list-key&apos;, &apos;A&apos;); //插入链表头部/左侧，返回链表长度 1$redis-&gt;rPush(&apos;list-key&apos;, &apos;B&apos;); //插入链表尾部/右侧，返回链表长度 12$redis-&gt;lPushx(&apos;list-key&apos;, &apos;C&apos;); // 插入链表头部/左侧,链表不存在返回0，存在即插入成功，返回当前链表长度 12$redis-&gt;rPushx(&apos;list-key&apos;, &apos;C&apos;); // 插入链表尾部/右侧,链表不存在返回0，存在即插入成功，返回当前链表长度 1$redis-&gt;lPop(&apos;list-key&apos;); //返回LIST顶部（左侧）的VALUE ,后入先出(栈) 1$redis-&gt;rPop(&apos;list-key&apos;); //返回LIST尾部（右侧）的VALUE ,先入先出（队列） 1$redis-&gt;blPop(); 1$redis-&gt;brPop(); 123$redis-&gt;lSize(&apos;list-key&apos;); // 如果是链表则返回链表长度，空链表返回0 若不是链表或者不为空，则返回false ,判断非链表 &quot; === false &quot; 1$redis-&gt;lGet(&apos;list-key&apos;,-1); // 通过索引获取链表元素 0获取左侧一个 -1获取最后一个 1$redis-&gt;lSet(&apos;list-key&apos;, 0, &apos;X&apos;); //0位置元素替换为 X 12$redis-&gt;lRange(&apos;list-key&apos;, 0, 3); //链表截取 从0开始 3位置结束 ，结束位置为-1 获取开始位置之后的全部 1$redis-&gt;lTrim(&apos;list-key&apos;, 0, 1); // 截取链表(不可逆) 从0索引开始 1索引结束 1$redis-&gt;lRem(&apos;list-key&apos;, &apos;C&apos;, 2); //链表从左开始删除元素2个C 123$redis-&gt;lInsert(&apos;list-key&apos;, Redis::BEFORE, &apos;C&apos;, &apos;X&apos;); // 在C元素前面插入X , Redis::AfTER(表示后面插入) 链表不存在则插入失败 返回0 若元素不存在返回-1 123$redis-&gt;rpoplpush(&apos;list-key&apos;, &apos;list-key2&apos;); //从源LIST的最后弹出一个元素 并且把这个元素从目标LIST的顶部（左侧）压入目标LIST。 123$redis-&gt;brpoplpush(); //rpoplpush的阻塞版本，这个版本有第三个参数用于设置阻塞时间 即如果源LIST为空，那么可以阻塞监听timeout的时间，如果有元素了则执行操作。 三、Set集合1set无序集合 不允许出现重复的元素 服务端可以实现多个 集合操作 1$redis-&gt;sMembers(&apos;key&apos;); //获取容器key中所有元素 123$redis-&gt;sAdd(&apos;key&apos; , &apos;TK&apos;); // (从左侧插入,最后插入的元素在0位置),集合中已经存在TK 则返回false 不存在添加成功 返回true 1$redis-&gt;sRem(&apos;key&apos; , &apos;TK&apos;); // 移除容器中的TK 1$redis-&gt;sMove(&apos;key&apos;,&apos;key1&apos;,&apos;TK&apos;); //将容易key中的元素TK 移动到容器key1 操作成功返回TRUE 1$redis-&gt;sIsMember(&apos;key&apos;,&apos;TK&apos;); //检查VALUE是否是SET容器中的成员 1$redis-&gt;sCard(&apos;key&apos;); //返回SET容器的成员数 1$redis-&gt;sPop(&apos;key&apos;); //随机返回容器中一个元素，并移除该元素 1$redis-&gt;sRandMember(&apos;key&apos;);//随机返回容器中一个元素，不移除该元素 12$redis-&gt;sInter(&apos;key&apos;,&apos;key1&apos;); // 返回两个集合的交集 没有交集返回一个空数组，若参数只有一个集合，则返回集合对应的完整的数组 1$redis-&gt;sInterStore(&apos;store&apos;,&apos;key&apos;,&apos;key1&apos;); //将集合key和集合key1的交集 存入容器store 成功返回1 1234$redis-&gt;sUnion(&apos;key&apos;,&apos;key1&apos;); //集合key和集合key1的并集 注意即使多个集合有相同元素 只保留一个$redis-&gt;sUnionStore(&apos;store&apos;,&apos;key&apos;,&apos;key1&apos;); //集合key和集合key1的并集保存在集合store中, 注意即使多个集合有相同元素 只保留一个 1$redis-&gt;sDiff(&apos;key&apos;,&apos;key1&apos;,&apos;key2&apos;); //返回数组，该数组元素是存在于key集合而不存在于集合key1 key2 四、Zset数据类型(stored set) 和 set 一样是字符串的集合，不同的是每个元素都会关联一个 double 类型的 scoreredis的list类型其实就是一个每个子元素都是string类型的双向链表。 123$redis-&gt;zAdd(&apos;tkey&apos;, 1, &apos;A&apos;); // 插入集合tkey中，A元素关联一个分数，插入成功返回1 同时集合元素不可以重复, 如果元素已经存在返回 0 1$redis-&gt;zRange(&apos;tkey&apos;,0,-1); // 获取集合元素，从0位置 到 -1 位置 123$redis-&gt;zRange(&apos;tkey&apos;,0,-1, true); // 获取集合元素，从0位置 到 -1 位置, 返回一个关联数组 带分数 array([A] =&gt; 0.01,[B] =&gt; 0.02,[D] =&gt; 0.03) 其中小数来自zAdd方法第二个参数 1$redis-&gt;zDelete(&apos;tkey&apos;, &apos;B&apos;); // 移除集合tkey中元素B 成功返回1 失败返回 0 1234$redis-&gt;zRevRange(&apos;tkey&apos;, 0, -1); // 获取集合元素，从0位置 到 -1 位置，数组按照score降序处理$redis-&gt;zRevRange(&apos;tkey&apos;, 0, -1,true); // 获取集合元素，从0位置 到 -1 位置，数组按照score降序处理 返回score关联数组 123$redis-&gt;zRangeByScore(&apos;tkey&apos;, 0, 0.2,array(&apos;withscores&apos; =&gt; true)); //获取几个tkey中score在区间[0,0.2]元素 ,score由低到高排序, 元素具有相同的score，那么会按照字典顺序排列 , withscores 控制返回关联数组 12$redis-&gt;zRangeByScore(&apos;tkey&apos;, 0.1, 0.36, array(&apos;withscores&apos; =&gt; TRUE, &apos;limit&apos; =&gt; array(0, 1))); //其中limit中 0和1 表示取符合条件集合中 从0位置开始，向后扫描1个 返回关联数组 1$redis-&gt;zCount(&apos;tkey&apos;, 2, 10); // 获取tkey中score在区间[2, 10]元素的个数 1$redis-&gt;zRemRangeByScore(&apos;tkey&apos;, 1, 3); // 移除tkey中score在区间[1, 3](含边界)的元素 12$redis-&gt;zRemRangeByRank(&apos;tkey&apos;, 0, 1); //默认元素score是递增的，移除tkey中元素 从0开始到-1位置结束 1$redis-&gt;zSize(&apos;tkey&apos;); //返回存储在key对应的有序集合中的元素的个数 1$redis-&gt;zScore(&apos;tkey&apos;, &apos;A&apos;); // 返回集合tkey中元素A的score值 123$redis-&gt;zRank(&apos;tkey&apos;, &apos;A&apos;); // 返回集合tkey中元素A的索引值 z集合中元素按照score从低到高进行排列 ，即最低的score index索引为0 1$redis-&gt;zIncrBy(&apos;tkey&apos;, 2.5, &apos;A&apos;); // 将集合tkey中元素A的score值 加 2.5 123$redis-&gt;zUnion(&apos;union&apos;, array(&apos;tkey&apos;, &apos;tkey1&apos;)); // 将集合tkey和集合tkey1元素合并于集合union , 并且新集合中元素不能重复 返回新集合的元素个数， 如果元素A在tkey和tkey1都存在，则合并后的元素A的score相加 1234$redis-&gt;zUnion(&apos;ko2&apos;, array(&apos;k1&apos;, &apos;k2&apos;), array(5, 2)); // 集合k1和集合k2并集于k02 ，array(5,1)中元素的个数与子集合对应，然后 5 对应k1 k1每个元素score都要乘以5 ，同理1对应k2，k2每个元素score乘以1 然后元素按照递增排序，默认相同的元素score(SUM)相加 123$redis-&gt;zUnion(&apos;ko2&apos;, array(&apos;k1&apos;, &apos;k2&apos;), array(10, 2),&apos;MAX&apos;); // 各个子集乘以因子之后，元素按照递增排序，相同的元素的score取最大值(MAX) 也可以设置MIN 取最小值 123$redis-&gt;zInter(&apos;ko1&apos;, array(&apos;k1&apos;, &apos;k2&apos;)); // 集合k1和集合k2取交集于k01 ，且按照score值递增排序 如果集合元素相同，则新集合中的元素的score值相加 1234$redis-&gt;zInter(&apos;ko1&apos;, array(&apos;k1&apos;, &apos;k2&apos;), array(5, 1)); //集合k1和集合k2取交集于k01 ，array(5,1)中元素的个数与子集合对应，然后 5 对应k1 k1每个元素score都要乘以5 ，同理1对应k2，k2每个元素score乘以1 ，然后元素score按照递增排序，默认相同的元素score(SUM)相加 123$redis-&gt;zInter(&apos;ko1&apos;, array(&apos;k1&apos;, &apos;k2&apos;), array(5, 1),&apos;MAX&apos;); // 各个子集乘以因子之后，元素score按照递增排序，相同的元素score取最大值(MAX) 也可以设置MIN 取最小值 五、Hash数据类型redis hash是一个string类型的field和value的映射表.它的添加，删除操作都是O(1)（平均）.hash特别适合用于存储对象。 1$redis-&gt;hSet(&apos;h&apos;, &apos;name&apos;, &apos;TK&apos;); // 在h表中 添加name字段 value为TK 12$redis-&gt;hSetNx(&apos;h&apos;, &apos;name&apos;, &apos;TK&apos;); // 在h表中 添加name字段 value为TK 如果字段name的value存在返回false 否则返回 true 1$redis-&gt;hGet(&apos;h&apos;, &apos;name&apos;); // 获取h表中name字段value 1$redis-&gt;hLen(&apos;h&apos;); // 获取h表长度即字段的个数 1$redis-&gt;hDel(&apos;h&apos;,&apos;email&apos;); // 删除h表中email 字段 1$redis-&gt;hKeys(&apos;h&apos;); // 获取h表中所有字段 1$redis-&gt;hVals(&apos;h&apos;); // 获取h表中所有字段value 1$redis-&gt;hGetAll(&apos;h&apos;); // 获取h表中所有字段和value 返回一个关联数组(字段为键值) 1$redis-&gt;hExists(&apos;h&apos;, &apos;email&apos;); //判断email 字段是否存在与表h 不存在返回false 1$redis-&gt;hSet(&apos;h&apos;, &apos;age&apos;, 28); 12$redis-&gt;hIncrBy(&apos;h&apos;, &apos;age&apos;, -2); // 设置h表中age字段value加(-2) 如果value是个非数值 则返回false 否则，返回操作后的value 123$redis-&gt;hIncrByFloat(&apos;h&apos;, &apos;age&apos;, -0.33); // 设置h表中age字段value加(-2.6) 如果value是个非数值 则返回false 否则 返回操作后的value(小数点保留15位) 1$redis-&gt;hMset(&apos;h&apos;, array(&apos;score&apos; =&gt; &apos;80&apos;, &apos;salary&apos; =&gt; 2000)); // 表h 批量设置字段和value 1$redis-&gt;hMGet(&apos;h&apos;, array(&apos;score&apos;,&apos;salary&apos;)); // 表h 批量获取字段的value 转载于http://www.cnblogs.com/liangzia/p/5731403.html]]></content>
  </entry>
  <entry>
    <title><![CDATA[Hello]]></title>
    <url>%2F2018%2F03%2F13%2Fhello-world%2F</url>
    <content type="text"><![CDATA[这个博客用于记录自己在入职之后的成长之旅,不定期更新。 公司后端的技术栈主要包括 grpc protobuf netty zookeeper kafka mysql redis memcache等，之后的博客也会围绕这些方面进行 。 本博客只要是自己创作的会标有原创标题，不是自己的会尽量给出链接 如果有想联系我或者投递简历的请发邮件至 duhaitao1121@foxmail.com]]></content>
  </entry>
</search>
